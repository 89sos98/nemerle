/*
 * Copyright (c) 2003 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

using Nemerle.Compiler;
using Nemerle.Collections;
using Nemerle.Compiler.Parsetree;

namespace Nemerle.Compiler {

public module Parser {
  class ParenCallback {
    public opening_paren : string;
    public closing_paren : string;
    public parsing_function : void -> Expr;
  }

  public class KeywordCallback {
    public name : string;
    public parsing_function : void -> Expr;
  }

  public class CTX {
    public mutable lexer : ILexer;
    public mutable last_token1 : Token; // most recent token
    public mutable last_token2 : Token; // one token before
    public mutable push_back : int; // position in last_token{1,2} or 0
    public mutable in_pattern : bool;
    public parens : Hashtable (string, ParenCallback);
    public closing_parens : Hashtable (string, int);
    public keywords : Hashtable (string, KeywordCallback);
  }

  public mutable ctx : CTX;

  this () 
  {
    ctx <- CTX (lexer = null,
                last_token1 = null, 
                last_token2 = null, 
                push_back = 0,
                in_pattern = false,
                keywords = Hashtable (),
                parens = Hashtable (),
                closing_parens = Hashtable ());
    init_parens ();
  }

  'a where 'a :> Located 
  opt_locate (f : void -> option ('a)) : option ('a) {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    match (ret) {
      | Some (x) => x.loc <- loc
      | None => ()
    };
    ret
  }

  /** executes given function and returns its result enriched
      by location at the beginning of parsing */
  'a where 'a :> Located 
  locate (f : void -> 'a) : 'a {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    ret.loc <- loc;
    ret
  }

  get_token () : Token {
    match (ctx.push_back) {
      | 1 =>
        ctx.push_back <- 0;
        ctx.last_token1
      | 2 =>
        ctx.push_back <- 1;
        ctx.last_token2
      | _ =>
        def get_token () {
          try
            ctx.lexer.get_token ()
          catch { e : Lexer.Error =>
            Message.error ("lexing problem: " + e.name);
            get_token ()
          }
        };
        ctx.last_token2 <- ctx.last_token1;
        ctx.last_token1 <- get_token ();
        ctx.last_token1
    }
  }

  peek_token () : Token {
    def tok = get_token ();
    push_back ();
    tok
  }
  
  push_back () : void {
    match (ctx.push_back) {
      | 1 => ctx.push_back <- 2
      | 2 => Util.ice ()
      | _ => ctx.push_back <- 1
    }
  }
  
  shift () : void {
    ignore (get_token ()) 
  }

  location_here () : Location {
    ignore (peek_token ());
    location ()
  }

  location () : Location {
    ctx.lexer.get_location ()
  }

  public token_name (t : Token) : string {
    match (t) {
      | Tok_keyword (x) => "keyword `" + x + "'"
      | Tok_identifier (x) => "identifier `" + x + "'"
      | Tok_operator (x, _) => "operator `" + x + "'"
      | Tok_tyvar (x) => "type variable `" + x + "'"
      | Tok_string_literal => "string literal"
      | Tok_number_literal => "number literal"
      | Tok_char_literal => "character literal"
      | Tok_EOF => "end of file"
    }
  }

  describe () : string {
    when (ctx.push_back != 2) {
      push_back ()
    };
    def name = token_name (peek_token ());
    "parse error near " + name + ": "
  }

  'a fatal_error (msg : string) : 'a {
    Message.fatal_error (location (), describe () + msg)
  }

  error (msg : string) : void {
    Message.error (location (), describe () + msg)
  }

  get_qid () : string {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (".", _) =>
          match (get_token ()) {
            | Tok_identifier (x) => loop (acc + "." + x)
            | _ => fatal_error ("expecting identifier after dot in qualified ID")
          }
        | _ =>
          push_back ();
          acc
      }
    };

    match (get_token ()) {
      | Tok_identifier (x) =>
        loop (x)
      | _ =>
        fatal_error ("expecting qualified identifier")
    }
  }
  
  get_id () : string {
    match (get_token ()) {
      | Tok_identifier (x) => x
      | _ =>
        fatal_error ("expecting identifier")
    }
  }
  
  get_id_or_dummy () : string {
    match (get_token ()) {
      | Tok_identifier (x) => x
      | Tok_keyword ("_") => Util.tmpname ("u")
      | _ =>
        fatal_error ("expecting identifier")
    }
  }
  
  get_splicable_id () : Splicable_string {
    def loc = location_here ();
    match (get_token ()) {
      | Tok_identifier (n) => SS_string (loc, n)
      | Tok_operator ("$", _) =>
        match (get_token ()) {
          | Tok_identifier (id) =>
            SS_spliced_expr (loc, E_ref (location (), id))
          | Tok_operator ("(", _) =>
            def expr = parse_expr ();
            match (peek_token ()) {
              | Tok_operator (":", _) =>
                shift();
                match (get_token ()) {
                  | Tok_identifier (ty) =>
                    match (ty) {
                      | "var" | "int" | "string" | "bool" | "float" 
                      | "char" =>
                        expect_operator (")");
                        SS_spliced_expr (loc, E_spliced_special (ty, expr))
                      | _ =>
                        fatal_error ("wrong splicing type after ':'")
                    }
                  | _ =>
                    fatal_error ("expecting splicing type (var) after ':'")
                }
              | _ =>
                expect_operator (")");
                SS_spliced_expr (loc, expr)
            }
          | _ =>
            fatal_error ("expecting identifier or '(' after '$'")
        }
      | Tok_keyword ("_") => 
        SS_string (loc, Util.tmpname ("u"))
      | _ => fatal_error ("expecting identifier")
    }
  }

  get_tyvar () : string {
    match (get_token ()) {
      | Tok_tyvar (tv) => tv
      | _ => fatal_error ("expecting type variable")
    }
  }

  expect_operator (op : string) : void {
    match (get_token ()) {
      | Tok_operator (o, _) when op == o => ()
      | Tok_operator (o, _) =>
        match (peek_token ()) {
          | Tok_operator (o', _) when op == o + o' => shift (); ()
          | _ => fatal_error ("expecting operator `" + op + "'");
        }
      | _ =>
        fatal_error ("expecting operator `" + op + "'");
    }
  }

  expect_keyword (op : string) : void {
    match (get_token ()) {
      | Tok_keyword (o) when op == o => ()
      | _ =>
        fatal_error ("expecting keyword `" + op + "'");
    }
  }

  flag_keyword (kw : string) : bool {
    match (get_token ()) {
      | Tok_keyword (n) when n == kw => true
      | _ => push_back (); false
    }
  }

  parse_funparm (allow_inference : bool) : Fun_parm {
    def is_params = 
      match (peek_token ()) {
        | Tok_keyword ("params") => shift (); true
        | _ => false
      };
    def id = get_splicable_id ();
    def loc = location ();
    def t =
      match (get_token ()) {
        | Tok_operator (":", _) => parse_type ()
        | _ when allow_inference => push_back (); T_infer ()
        | _ => fatal_error ("expecting typing constraint after parameter name")
      };
    def defl = 
      match (peek_token ()) {
        | Tok_operator ("=", _) => 
          shift (); 
          if (is_params) 
            fatal_error ("variable number of arguments and default value")
          else
            FP_default (parse_expr ())
        | _ => if (is_params) FP_params () else FP_normal ()
      };
    Fun_parm (loc = loc, name = id, ty = t, att = defl)
  }

  /** eats exactly header with [name], [(parameters)] and inferencable [: type] */
  parse_fun_header (allow_inference : bool, 
                    allow_ctor : bool,
                    is_lambda : bool, 
                    knownname : option (Splicable_string)) : Fun_header
  {
    locate (fun () {
      mutable is_ctor <- false;
      def (typarms, name) = 
        match (knownname) {
          | None =>
            def tparms =
              match (peek_token ()) {
                | Tok_tyvar =>
                  def tyvars = operator_separated_list (",", get_tyvar);
                  parse_where_constraints (tyvars);
                | _ => 
                  Typarms ([], [])
              };
            def nam =
              match (peek_token ()) {
                | Tok_keyword ("this") when allow_ctor => 
                  shift ();
                  is_ctor <- true; SS_string (".ctor")
                | Tok_keyword ("fun") when is_lambda => shift (); SS_string ("")
                | _ when is_lambda => fatal_error ("expecting `fun'")
                | Tok_identifier  
                | Tok_operator ("$", _) => get_splicable_id ()
                | _ => fatal_error ("expecting function name")
              };
            (tparms, nam)
          | Some (n) => (Typarms ([], []), n)
        };
      expect_operator ("(");
      def parse_parm () { parse_funparm (allow_inference) };
      def parms =
        match (peek_token ()) {
          | Tok_operator (")", _) => []
          | Tok_operator (".", _) =>
            shift ();
            expect_operator (".");
            def loc = location ();
            [Fun_parm (loc, SS_string (""), <[ type: void ]>, 
             FP_default (parse_expr ()))]
          | _ => operator_separated_list (",", parse_parm)
        };
      expect_operator (")");
      def ret_type =
        match (get_token ()) {
          | _ when is_ctor => push_back (); T_void ()
          | Tok_operator (":", _) => parse_type ()
          | _ when allow_inference => push_back (); T_infer ()
          | _ => fatal_error ("expecting typing constraint on function return value")
        };
      Fun_header (name = name,
                  ret_type = ret_type, 
                  parms = parms, 
                  typarms = typarms)
    })
  }

  parse_literal () : option (Literal) {
    match (get_token ()) {
      | Tok_keyword ("null") => Some (L_null ())
      | Tok_keyword ("true") => Some (L_bool (true))        
      | Tok_keyword ("false") => Some (L_bool (false))
      | Tok_operator ("(", _) =>
        match (get_token ()) {
          | Tok_operator (")", _) => Some (L_void ())
          | _ => push_back (); push_back (); None ()
        }
      | Tok_string_literal (s) => Some (L_string (s))
      | Tok_number_literal (n) => Some (L_int (n))
      | Tok_char_literal (c) => Some (L_char (c))
      | _ => push_back (); None ()
    }
  }

  parse_closed_prim_expr () : Expr {
    def loc = location_here ();
    match (parse_literal ()) {
      | Some (l) => E_literal (loc, l)
      | None =>
        def is_id (tok) { 
          match (tok) { 
            | Tok_identifier => true 
            | _ => false
          }
        };

        def problem () {
          Message.fatal_error (loc, describe () + "expecting primary expression")
        };
        
        match (get_token ()) {
          | Tok_keyword ("this") => E_this (loc)
          | Tok_keyword ("base") => E_base (loc)
          | Tok_keyword ("typeof") => 
            expect_operator ("(");
            def type_expr = parse_type ();
            expect_operator (")");
            E_typeof (loc, type_expr)
            
          | Tok_identifier (n) => E_ref (loc, n)
          | Tok_operator ("(", _) =>
            def expr = parse_expr ();
            match (get_token ()) {
              | Tok_operator (":>", _) =>
                def t = parse_type ();
                expect_operator (")");
                E_type_conversion (loc, expr, t)

              | Tok_operator (":", _) =>
                def t = parse_type ();
                expect_operator (")");
                E_type_enforcement (loc, expr, t)

              | Tok_operator (",", _) =>
                def exprs = expr :: operator_separated_list (",", parse_expr);
                expect_operator (")");
                E_tuple (loc, exprs)
                
              | Tok_operator (")", _) => 
                match (expr) {
                  | E_expr_list => E_tuple (loc, [expr])
                  | _ => expr
                }

              | _ => Message.fatal_error (loc, "unbalanced `('")
            }

          | Tok_operator ("$", _) when is_id (peek_token ()) =>
            match (get_token ()) {
              | Tok_identifier (n) =>
                if (ctx.in_pattern)
                  E_spliced_patt (loc, P_variable (location (), n))
                else
                  E_spliced (loc, E_ref (location (), n))
              | _ => Util.ice ()
            }

          | Tok_operator (o, _) =>
            def parse_paren (p : ParenCallback) {
              def problem () {
                Message.error (loc, "unbalanced `" + p.opening_paren + "'");
                fatal_error ("expecting `" + p.closing_paren + "' here")
              };
              def expr = p.parsing_function ();
              match (get_token ()) {
                | Tok_operator (o, _) =>
                  if (p.closing_paren == o)
                    expr
                  else
                    match (get_token ()) {
                      | Tok_operator (o', _) when p.closing_paren == o + o' => expr
                      | _ => push_back (); problem ()
                    }
                | _ => problem ()
              } 
            };
            
            match (ctx.parens.Get (o)) {
              | Some (p) => parse_paren (p)
              | None =>
                match (get_token ()) {
                  | Tok_operator (o', _) =>
                    match (ctx.parens.Get (o + o')) {
                      | Some (p) => parse_paren (p)
                      | None => push_back (); problem ()
                    }
                  | _ => push_back (); problem ()
                }
            }
            
          | _ => problem ()
        }
    }
  }

  parse_call_parm () : Parm {
    def is_ref = flag_keyword ("ref");
    def maybe_name_expr = parse_expr ();
    match (peek_token ()) {
      | Tok_operator ("=", _) =>
        def name = 
          match (maybe_name_expr) {
            | E_spliced (e) => SS_spliced_expr (e)
            | E_ref (n) => SS_string (n)
            | E_spliced_special
            | E_spliced_patt => SS_spliced_expr (maybe_name_expr)
            | _ =>
              fatal_error ("expected parameter name before '=' in call parm")
          };
        shift ();
        Parm (is_ref, parse_expr (), name)
      | _ =>
        Parm (is_ref, maybe_name_expr, SS_string (""))
    }
  }
    
  parse_prim_expr () : Expr {
    def loop (expr : Expr) {
      match (get_token ()) {
        | Tok_operator ("[", _) =>
          def exprs = operator_separated_list (",", parse_expr);
          expect_operator ("]");
          loop (E_indexer (expr.loc, expr, exprs))
          
        | Tok_operator (".", _) => 
          def id = get_splicable_id ();
          loop (E_member (expr.loc, expr, id))
          
        | Tok_operator ("(", _) =>
          def parms =
            match (peek_token ()) {
              | Tok_operator (")", _) => shift (); []
              | _ => 
                def parms = operator_separated_list (",", parse_call_parm);
                expect_operator (")");
                parms
            };
          loop (E_call (expr.loc, expr, parms))

        | _ => push_back (); expr
      }
    };

    loop (parse_closed_prim_expr ())
  }

  parse_unary_expr () : Expr {
    match (peek_token ()) {
      | Tok_operator ("(", _)
      | Tok_operator ("$", _) => parse_prim_expr ()

      | Tok_operator (".", _) =>
        shift ();
        match (get_token ()) {
          | Tok_operator (".", _) => 
            def loc = location ();
            E_expr_list (loc, parse_expr ())
          | _ => fatal_error ("expecting second dot (in unary expression context)")
        }

      | Tok_operator (o, pri) =>
        def loc = location ();
        def unary () {
          when (pri == 0) {
            fatal_error ("operator `" + o + "' cannot be used in unary context")
          };
          shift ();
          E_call (loc, E_ref (loc, o), [Parm (parse_unary_expr ())])
        };
        
        if (ctx.parens.Contains (o))
          parse_prim_expr ()
        else {
          shift ();
          def tok = peek_token ();
          push_back ();
          match (tok) {
            | Tok_operator (o', _) =>
              if (ctx.parens.Contains (o + o'))
                parse_prim_expr ()
              else unary ()
            | _ => unary ()
          }
        }
      | _ => parse_prim_expr ()
    }
  }

  parse_pattern () : Pattern {
    def loop () {
      def loc = location_here ();
      def pat = parse_closed_pattern ();
      match (peek_token ()) {
        | Tok_operator ("::", _) => 
          shift (); 
          P_cons (loc, SS_string ("Cons"), P_tuple (loc, [pat, loop ()]))
        | _ => pat
      }
    };

    loop ()
  }

  parse_pattern_after_id (id : Splicable_string) : Pattern {
    def id = 
      match (peek_token ()) {
        | Tok_operator (".", _) =>
          shift ();
          def qid = get_qid ();
          match (id) {
            | SS_string (n) => 
              SS_string (n + "." + qid)
            | _ =>
              fatal_error ("mixing spliced names with regular ids isn't allowed")
          }
        | _ => id;
      };
    def loc = location ();
    match (peek_token ()) {
      | Tok_operator ("{", _)
      | Tok_operator ("(", _) => 
        P_cons (loc, id, tuple_or_record ()) 
      | Tok_keyword ("_") => 
        shift ();
        P_cons (loc, id, P_underscore (loc))
      | _ =>
        match (id) {
          | SS_string => P_cons (loc, id, P_underscore (loc))
          | SS_spliced_expr (E_spliced_special (ty, expr)) =>
            match (ty) {
              | "var" | "int" | "string" | "bool" | "float" 
              | "char" =>
                P_spliced_special (loc, ty, expr)
              | _ =>
                fatal_error ("wrong splicing type after ':'")
            }
          | SS_spliced_expr (expr) =>
            P_spliced (loc, expr)
        }
    }
  }

  /** this function expects first '{' to be already shifted, starting
      its scanning routine from inside of record;
      but it shifts the ending '}'
   */
  parse_record () : Pattern {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator ("}", _) => List.Rev (acc)
        | Tok_identifier (n) =>
          expect_operator ("=");
          def pat = parse_pattern ();
          def res = (n, pat);
          match (get_token ()) {
            | Tok_operator (";", _) => ()
            | Tok_operator ("}", _) => push_back ()
            | _ => fatal_error ("found junk after pattern in record")
          };
          loop (res :: acc)
        | _ => fatal_error ("expecting named pattern")
      }
    };
    def loc = location ();
    match (peek_token ()) {
      | Tok_operator (".", _) =>
        shift ();
        match (get_token ()) {
          | Tok_operator (".", _) => 
            def res = P_record ([("", P_patt_list (loc, parse_pattern ()))]);
            expect_operator ("}");
            res
          | _ => fatal_error ("expecting second dot in pattern context")              
        }
      | _ =>
        P_record (loc, loop ([]))
    }
  }

  tuple_or_record () : Pattern {
    match (get_token ()) {
      | Tok_operator ("(", _) =>
        def pats = operator_separated_list (",", parse_pattern);
        expect_operator (")");
        P_tuple (location_here (), pats)
      | Tok_operator ("{", _) => parse_record ()
      | _ => fatal_error ("expecting tuple or record pattern")
    }
  }
    
  parse_closed_pattern () : Pattern {
    def loc = location_here ();
  
    match (parse_literal ()) {
      | Some (l) => P_literal (loc, l)
      | None =>
        match (get_token ()) {
          | Tok_operator ("-", _) =>
            match (parse_literal ()) {
              | Some (L_int (v)) => P_literal (loc, L_int (-v))
              | _ => 
                fatal_error ("expecting integer literal")
            }
            
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            push_back ();
            def id = get_splicable_id ();
            parse_pattern_after_id (id)
            
          | Tok_operator ("{", _) =>
            parse_record ()

          | Tok_operator (".", _) =>
            match (get_token ()) {
              | Tok_operator (".", _) => P_patt_list (loc, parse_pattern ())
              | _ => fatal_error ("expecting second dot in pattern context")
            }
            
          | Tok_operator ("(", _) =>
            def pat = parse_pattern ();
            match (get_token ()) {
              | Tok_operator (",", _) =>
                def pats = pat :: operator_separated_list (",", parse_pattern);
                expect_operator (")");
                P_tuple (loc, pats)
              | Tok_operator (")", _) =>
                match (peek_token ()) {
                  | Tok_keyword ("as") =>
                    shift ();
                    def id = get_splicable_id ();
                    P_as (loc, pat, id)
                    
                  | _ =>
                    P_tuple (loc, [pat])
                }
              | _ =>
                fatal_error ("expecting `,' or ')' in tuple pattern")
            }

          | Tok_keyword ("_") =>
            P_underscore (loc)

          | Tok_operator ("[", _) =>
            def loop () {
              match (get_token ()) {
                | Tok_operator (",", _) =>
                  match (peek_token ()) {
                    | Tok_operator ("]", _) => 
                      P_cons (SS_string ("Nil"), P_underscore ())
                    | _ => 
                      def p = parse_pattern ();
                      P_cons (p.loc, SS_string ("Cons"), P_tuple (p.loc, [p, loop ()]))
                  }
                | Tok_operator ("]", _) =>
                  P_cons (SS_string ("Nil"), P_underscore ())
                | _ => fatal_error ("expecting pattern in list")
              }
            };

            match (peek_token ()) {
              | Tok_operator ("]", _) => shift (); 
                P_cons (SS_string ("Nil"), P_underscore ())
              | _ =>
                def p = parse_pattern ();
                P_cons (p.loc, SS_string ("Cons"), P_tuple (p.loc, [p, loop ()]))
            }
            
          | Tok_operator ("<[", _) =>
            def back = ctx.in_pattern;
            ctx.in_pattern <- true;
            def expr = parse_quotation ();
            expect_operator ("]>");
            ctx.in_pattern <- back;
            match (expr) {
              | E_quoted (el) => P_quoted (loc, el)
              | _ => Util.ice ("parse_quoted returned sth strange")
            }
            
          | _ => fatal_error ("expecting pattern")
        }
    }
  }

  parse_case_guard () : Pattern * option (Expr) {
    def pat = parse_pattern ();
    if (flag_keyword ("when"))
      (pat, Some (parse_expr ()))
    else (pat, None ());
  }

  parse_match_case () : Match_case {
    def loop2 (acc) {
      def res = parse_case_guard ();
      match (get_token ()) {
        | Tok_operator ("=>", _) => List.Rev (res :: acc)
        | Tok_operator ("|", _) => loop2 (res :: acc)
        | _ => fatal_error ("found junk after pattern")
      }
    };
    
    // eat pattern part and '=>'
    def pats = 
      match (peek_token ()) {
        | Tok_operator ("|", _) => 
          shift ();
          match (peek_token ()) {
            | Tok_operator (".", _) =>
              shift ();
              expect_operator (".");
              def loc = location_here ();
              def pat = parse_pattern ();
              expect_operator ("=>");
              [(P_patt_list (loc, pat), None ())]
            | _ => loop2 ([])
          }
        | _ => loop2 ([])
      };

    def loc' = location_here ();
    def expr =
      match (parse_expr_sequence ()) {
        | [x] => x
        | l => E_sequence (loc', l)
      };

    Match_case (pats, expr)
  }

  parse_semiclosed_expr () : Expr {
    def loc = location_here ();
    def tok = get_token ();
    //Message.debug ("pse " + token_name (tok));
    match (tok) {
      | Tok_keyword (k) when ctx.keywords.Contains (k) =>
        def k = Option.unsome (ctx.keywords.Get (k));
        k.parsing_function ()
        
      | Tok_keyword ("match") =>
        expect_operator ("(");
        def expr = parse_expr ();
        expect_operator (")");
        match (get_token ()) {
          | Tok_operator ("{", _) =>
            match (peek_token ()) {
              | Tok_operator (".", _) =>
                shift ();
                match (get_token ()) {
                  | Tok_operator (".", _) => 
                    def res = 
                      E_match (loc, expr, 
                               [Match_case ([], E_expr_list (loc, parse_expr ()))]);
                    expect_operator ("}");
                    res
                  | _ => fatal_error ("expecting second dot in match context")
                }
              | _ =>
                push_back ();
                def cases = collect_braced_list (parse_match_case);
                E_match (loc, expr, cases)
            }
          | _ =>
            fatal_error ("expecting '{' after 'match (e)'")
        }
      | Tok_keyword ("throw") =>
        E_raise (loc, parse_expr ())

      | Tok_keyword ("try") =>
        def body = parse_expr ();
        match (get_token ()) {
          | Tok_keyword ("catch") =>
            def parse_with () {
              match (peek_token ()) {
                | Tok_operator ("|", _) => shift ()
                | _ => ()
              };
              def id = get_splicable_id ();
              expect_operator (":");
              def t = parse_type ();
              expect_operator ("=>");
              match (parse_expr_sequence ()) {
                | [x] => (id, t, x)
                | l => (id, t, E_sequence (loc, l))
              }
            };

            def mktry (body, h) {
              def (id, t, handler) = h;
              E_try_with (loc, body, id, t, handler)
            };
            
            List.FoldLeft (mktry, body, collect_braced_list (parse_with))
            
          | Tok_keyword ("finally") =>
            def handler = parse_expr ();
            E_try_finally (loc, body, handler)

          | _ => fatal_error ("expecting `with' or `finally'")
        }

      | Tok_keyword ("mkarray") =>
        match (get_token ()) {
          | Tok_operator ("[", _) =>
            def exprs = parse_maybe_null_expr_sequence ();
            expect_operator ("]");
            E_mkarray (loc, exprs)

          | Tok_operator ("(", _) =>
            def exprs = operator_separated_list (",", parse_expr);
            expect_operator (")");
            E_empty_array (loc, exprs)

          | _ => fatal_error ("expected [ ... ] after `mkarray'")
        }

      | Tok_keyword ("fun") 
      | Tok_tyvar (_) =>
        push_back ();
        def h = parse_fun_header (allow_ctor = false,
                                       allow_inference = true, 
                                       is_lambda = true, knownname = None ());
        def expr = parse_block (h.parms);
        E_lambda (loc, Function_decl (h, expr))

      | Tok_keyword ("mutable") =>
        def id = get_splicable_id ();
        expect_operator ("<-");
        E_let (loc, true, id, parse_expr ())

      | Tok_keyword ("def") =>
        def parse_val (id) {
          expect_operator ("=");
          E_let (loc, false, id, parse_expr ())
        };
        def parse_pat (idopt) {
          def pat =
            match (idopt) {
              | None => parse_pattern ()
              | Some (id) =>
                parse_pattern_after_id (id);
            };
          expect_operator ("=");
          def expr = parse_expr ();
          E_letpat (loc, pat, expr)
        };
        def parse_funs (acc, idopt) {
          def h = parse_fun_header (allow_ctor = false, 
                                    allow_inference = true, 
                                    is_lambda = false, knownname = idopt);
          def fd = Function_decl (h, parse_block (h.parms));
          match (peek_token ()) {
            | Tok_keyword ("and") =>
              shift ();
              parse_funs (fd :: acc, None ())
            | _ => E_letfun (loc, List.Rev (fd :: acc))
          }
        };
        
        match (peek_token ()) {
          | Tok_tyvar => parse_funs ([], None ())

          | Tok_keyword ("_")
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            def id = get_splicable_id ();
            match (peek_token ()) {
              | Tok_operator ("(", _) => 
                parse_funs ([], Some (id))
                
              | Tok_operator ("=", _) =>
                parse_val (id)
              
              | _ => parse_pat (Some (id))
            }

          | Tok_operator (".", _) =>
            shift ();
            expect_operator (".");
            E_letfun (loc, [Function_decl (Fun_header (), 
                                           E_expr_list (parse_expr ()))])

          | _ => parse_pat (None ())
        }
      
      | _ => push_back (); parse_unary_expr ()
    }
  }

  parse_expr () : Expr {
    def is_paren (s) {
      ctx.parens.Contains (s) || ctx.closing_parens.Contains (s)
    };

    def make_bin (loc, op, e1, e2) {
      match (op) {
        | "<-" =>
          E_assign (loc, e1, e2)
        | "::" =>
          E_call (loc, E_ref (loc, "Cons"), [Parm (e1), Parm (e2)])
        | _ =>
          E_call (loc, E_ref (loc, op), [Parm (e1), Parm (e2)])
      }
    };
    
    def parse_pri (pri) : Expr {
      def loop_left (expr) {
        def loc = location_here ();
        match (get_token ()) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            def expr' = parse_pri (pri - 1);
            loop_left (make_bin (loc, s, expr, expr'))
          | _ => 
            push_back (); 
            expr
        }
      };

      def loop_right () {
        def loc = location_here ();
        def expr = parse_pri (pri - 1);
        match (get_token ()) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            make_bin (loc, s, expr, loop_right ())
          | _ => push_back (); expr
        }
      };
     
      match (pri) {
        | 0 => parse_semiclosed_expr ()
        | 1 | 8 => loop_right ()
        | _ => loop_left (parse_pri (pri - 1))
      }
    };

    parse_pri (9)
  }

  parse_expr_sequence () : list (Expr) {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (";", _) =>
          match (peek_token ()) {
            | Tok_operator ("}", _) 
            | Tok_operator ("|", _) 
            | Tok_operator ("]", _) 
              => List.Rev (acc)
            | _ => loop (parse_expr () :: acc)
          }
        | Tok_operator ("}", _) 
        | Tok_operator ("|", _) 
        | Tok_operator ("]", _) 
          => push_back (); List.Rev (acc)
        | _ => fatal_error ("expecting expression in sequence")
      }
    };

    loop ([parse_expr ()])
  }

  parse_maybe_null_expr_sequence () : list (Expr) {
    match (peek_token ()) {
      | Tok_operator ("}", _) 
      | Tok_operator ("]", _) => []
      | _ => parse_expr_sequence ()
    }
  }

  parse_block (parms : list (Fun_parm)) : Expr {
    def parms_to_tupl (prs : list (Fun_parm), acc) {
      match (prs) {
        | [] => E_tuple (List.Rev (acc))
        | {name = SS_string (x)} :: xs => parms_to_tupl (xs, E_ref (x) :: acc)
        | _ => fatal_error ("illegal spliced parameter?")
      }
    };

    expect_operator ("{");
    def loc = location ();
    match (peek_token ()) {
      | Tok_operator ("}", _) => shift (); E_sequence (location (), [])
      | Tok_operator ("|", _) =>
        push_back ();
        def cases = collect_braced_list (parse_match_case);
        match (parms) {
          | [{name = SS_string (x)}] => E_match (loc, E_ref (x), cases)
          | _::_::_ => E_match (loc, parms_to_tupl (parms, []), cases)
          | [] =>             
            fatal_error ("functions with direct matching must have parameters")
          | _ => fatal_error ("illegal spliced parameter?")
        }
      | _ => 
        def loc = location ();
        def r = E_sequence (loc, parse_expr_sequence ());
        expect_operator ("}");
        r
    }
  }
  
  parse_type () : Type {
    def prim_type () {
      def get_args () {
        match (get_token ()) {
          | Tok_operator ("(", _) =>
            def args = operator_separated_list (",", parse_type);
            expect_operator (")");
            args
          | _ =>
            push_back ();
            []
        }
      };
      match (get_token ()) {
        | Tok_identifier
        | Tok_operator ("$", _) =>
          push_back ();
          def id = get_splicable_id ();
          def id = 
            match (peek_token ()) {
              | Tok_operator (".", _) =>
                shift ();
                def qid = get_qid ();
                match (id) {
                  | SS_string (n) => 
                    SS_string (n + "." + qid)
                  | _ =>
                    fatal_error ("mixing spliced names with regular ids isn't allowed")
                }
              | _ => id;
            };
          match (peek_token ()) {
            | Tok_operator ("(", _) => 
              T_app (id, get_args ())
            | _ =>
              match (id) {
                | SS_string => T_app (id, [])
                | SS_spliced_expr (E_spliced_special (ty, expr)) =>
                  match (ty) {
                    | "var" =>
                      T_spliced_special (ty, expr)
                    | _ =>
                      fatal_error ("wrong splicing type after ':'")
                  }
                | SS_spliced_expr (expr) =>
                  T_spliced (expr)
              }
          }

        | Tok_operator (".", _) =>
          match (get_token ()) {
            | Tok_operator (".", _) => T_type_list (prod_type ())
            | _ => fatal_error ("expecting second dot")
          }
          
        | Tok_keyword ("array") => T_array (prim_type ())
        
        | Tok_keyword ("ref") => T_ref (prim_type ())
        
        | Tok_keyword ("out") => T_out (prim_type ())

        | Tok_keyword ("void") => T_void ()

        | Tok_tyvar (tv) => T_var (tv)

        | Tok_operator ("(", _) =>
          def t = parse_type ();
          expect_operator (")");
          t

        | _ =>
          fatal_error ("expecting type expression")
      }
    }

    and prod_type () {
      def loop (acc) {
        match (get_token ()) {
          | Tok_operator ("*", _) =>
            loop (prim_type () :: acc)
          | _ => 
            push_back ();
            match (acc) {
              | [x] => x
              | acc => T_prod (List.Rev (acc))
            }
        }
      };

      loop ([prim_type ()])
    };

    def fun_type () {
      def t = prod_type ();
      match (get_token ()) {
        | Tok_operator ("->", _) =>
          T_fun (t, fun_type ())
        | _ => 
          push_back ();
          t
      }
    };

    fun_type ()
  }

  get_attrs () : list (Modifier) {
    def loop (acc) {
      match (get_token ()) {
        | Tok_keyword ("new") => loop (Mod_new () :: acc)
        | Tok_keyword ("public") => loop (Mod_public () :: acc)
        | Tok_keyword ("protected") => loop (Mod_protected () :: acc)
        | Tok_keyword ("internal") => loop (Mod_internal () :: acc)
        | Tok_keyword ("private") => loop (Mod_private () :: acc)
        | Tok_keyword ("abstract") => loop (Mod_abstract () :: acc)
        | Tok_keyword ("sealed") => loop (Mod_sealed () :: acc)
        | Tok_keyword ("override") => loop (Mod_override () :: acc)
        | Tok_keyword ("static") => loop (Mod_static () :: acc)
        | Tok_keyword ("virtual") => loop (Mod_virtual () :: acc)
        | Tok_operator ("[", _) => 
          def exps = operator_separated_list (",", parse_expr);
          expect_operator ("]");
          loop (Mod_attribute (exps) :: acc)          
        | _ =>
          push_back ();
          List.Rev (acc)
      }
    };
    loop ([])
  }
  
  'a operator_separated_list (op : string, f : void -> 'a) : list ('a) {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (o, _) when o == op => loop (f () :: acc)
        | _ => push_back (); List.Rev (acc)
      }
    };

    loop ([f ()])
  }

  parse_tyvars () : list (string) {
    operator_separated_list (",", get_tyvar)
  }

  parse_where_constraints (tyvars : list (string)) : Typarms {
    def constraints =
      if (flag_keyword ("where")) {
        def parse_constraint () {
          def tv = get_tyvar ();
          expect_operator (":>");
          def t = parse_type ();
          Constraint (tv, t)
        };
        operator_separated_list (",", parse_constraint)
      } else [];
    Typarms (tyvars, constraints)
  }

  parse_type_member () : Class_member {
    def loc = location_here ();
    def attrs = get_attrs ();

    def parse_extern () {
      match (get_token ()) {
        | Tok_keyword ("extern") =>
          match (get_token ()) {
            | Tok_string_literal (s) => 
              expect_operator (";");
              s
            | _ => fatal_error ("found some junk after extern (expecting string)")
          }
        | _ => fatal_error ("found some junk after `=' (expecting extern)")
      }
    };

    def parse_fun (h : Fun_header) {
      def hname = Macros.unsstring (h.name);
      def impl =
        match (get_token ()) {
          | Tok_keyword ("implements") when hname != ".ctor" =>
            operator_separated_list (",", get_qid)
          | _ => push_back (); []
        };
      def body =
        match (peek_token ()) {
          | Tok_operator ("=", _) =>
            shift ();
            FB_extern (parse_extern ())
          | Tok_operator ("{", _) =>
            FB_parsed_expr (parse_block (h.parms))
          | Tok_operator (";", _) =>
            shift ();
            FB_abstract ()
          | _ => fatal_error ("expecting method body")
        };
      
      M_function (header = h, 
                  name = hname, 
                  modifiers = attrs, 
                  loc = loc, 
                  body = body, 
                  kind = if (hname == ".ctor") FK_ctor () else FK_method (impl))
    };
    
    def parse_field (is_ref, name) {
      expect_operator (":");
      def t = parse_type ();
      def valkind = 
        match (get_token ()) {
          | Tok_operator (";", _) => Val_normal ()
          | Tok_operator ("=", _) => Val_extern (parse_extern ())
          | _ => fatal_error ("found some junk after field")
        };
      
      M_field (loc = loc,
               name = name, 
               modifiers = attrs, 
               ty = t, 
               is_ref = is_ref, 
               kind = valkind);
    };

    match (get_token ()) {
      | Tok_tyvar =>
        push_back ();
        def h = parse_fun_header (
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false, knownname = None ());
        parse_fun (h)
        
      | Tok_keyword ("mutable") =>
        match (get_token ()) {
          | Tok_identifier (name) => parse_field (true, name)
          | _ => fatal_error ("expecting field name")
        }
        
      | Tok_identifier (name) =>
        match (peek_token ()) {
          | Tok_operator ("(", _) => 
            push_back ();
            def h = parse_fun_header (
                                      allow_ctor = false, 
                                      allow_inference = false,
                                      is_lambda = false, knownname = None ());
            parse_fun (h)
          | _ => parse_field (false, name)
        }
        
      | Tok_keyword ("this") =>
        push_back ();
        def h = parse_fun_header (
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false, knownname = None ());
        parse_fun (h)

      | _ =>
        push_back ();
        def td = parse_type_decl ();
        td.modifiers <- List.Append (td.modifiers, attrs);
        M_type (loc = loc, 
                name = td.name, 
                modifiers = td.modifiers, 
                td = td)
    }
  }
  
  parse_type_decl () : Type_decl {
    def parse_header () {
      match (get_token ()) {
        | Tok_identifier (name) =>
          def typarms =
            match (get_token ()) {
              | Tok_operator ("(", _) =>
                def tyvars = parse_tyvars ();
                expect_operator (")");
                parse_where_constraints (tyvars);
              | _ => 
                push_back (); 
                Typarms ([], [])
            };
            
          def t_extends =
            match (get_token ()) {
              | Tok_keyword ("extends") =>
                Some (parse_type ())
              | _ => 
                push_back (); 
                None ()
            };
            
          def t_implements =
            match (get_token ()) {
              | Tok_keyword ("implements") =>
                operator_separated_list (",", parse_type)
              | _ => 
                push_back (); 
                []
            };
          
          (name, typarms, t_extends, t_implements)
          
        | _ => fatal_error ("expecting type name")
      }
    };
    
    def parse_variant_member () {
      def tok = get_token ();
      locate (fun () {
        match (tok) {
          | Tok_operator ("|", _) =>
            def id = get_id ();
            def members =
              match (peek_token ()) {
                | Tok_operator ("{", _) =>
                  def parse_field () {
                    ignore (peek_token ());
                    locate (fun () {
                      def attrs = get_attrs ();
                      def is_ref = flag_keyword ("mutable");
                      def id = get_id ();
                      expect_operator (":");
                      def ty = parse_type ();
                      expect_operator (";");
                      M_field (name = id,
                               modifiers = attrs,
                               ty = ty, 
                               is_ref = is_ref, 
                               kind = Val_normal ())
                    })
                  };
                  collect_braced_list (parse_field)
                | _ => []
              };
            TD_variant_option (name = id, 
                               modifiers = [], 
                               t_extends = None (),
                               t_implements = [],
                               typarms = Typarms ([], []),
                               decls = members)
          | _ => fatal_error ("expecting variant option")
        }
      })
    };
    
    def parse_iface_member () {
      ignore (peek_token ());
      locate (fun () {
        def is_new = flag_keyword ("new");
        def h = parse_fun_header (allow_ctor = false, allow_inference = false,
                                  is_lambda = false, knownname = None ());
        expect_operator (";");
        M_function (name = Macros.unsstring (h.name), 
                    modifiers = Mod_public () :: if (is_new) [Mod_new ()] else [],
                    header = h, 
                    kind = FK_iface_method (is_new), 
                    body = FB_abstract ())
      })
    };
    
    def parse_members () {
      collect_braced_list (parse_type_member)
    };
    
    def attrs = get_attrs ();
    def tok = get_token ();
    locate (fun () {
      match (tok) {
        | Tok_keyword ("type")
        | Tok_keyword ("class")
        | Tok_keyword ("struct")
        | Tok_keyword ("module")
        | Tok_keyword ("interface")
        | Tok_keyword ("variant") =>
          def (name, typarms, t_extends, t_implements) = parse_header ();
          def (attrs, td) =
            match (tok) {
              | Tok_keyword ("class") =>
                (attrs, TD_class (parse_members ()))
              | Tok_keyword ("struct") =>
                (Mod_struct () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("module") =>
                (Mod_module () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("type") =>
                expect_operator ("=");
                def t = parse_type ();
                expect_operator (";");
                (attrs, TD_alias (t))
                
              | Tok_keyword ("interface") =>
                def decls = collect_braced_list (parse_iface_member);
                (attrs, TD_interface (decls))
                
              | Tok_keyword ("variant") =>
                expect_operator ("{");
                def decls = collect_list (parse_variant_member);
                expect_operator ("}");
                (attrs, TD_variant (decls))
             
              | _ => Util.ice ()
            };
            
          td.modifiers <- attrs;
          
          td.name <- name;
          td.typarms <- typarms;
          td.t_extends <- t_extends;
          td.t_implements <- t_implements;
          
          td
          
        | Tok_keyword ("macro") => 
          def header = parse_fun_header (true, false, false, None ());
          def synt = 
            match (peek_token ()) {
              | Tok_keyword ("syntax") =>
                shift ();
                expect_operator ("(");
                def parse_elems (acc) {
                  match (peek_token ()) {
                    | Tok_operator (")", _) =>
                      shift ();
                      List.Rev (acc)
                    | Tok_operator (",", _) =>
                      shift ();
                      parse_elems (parse_closed_prim_expr () :: acc)
                    | _ =>
                      fatal_error ("expected comma separated expressions in "
                                   + "syntax description")
                  }
                };
                parse_elems ([parse_closed_prim_expr ()])
              | _ => []
            };
          def expr = parse_block ([]);
          Macros.GenerateMacroClass (attrs, header, synt, expr)
        
        | _ => fatal_error ("expecting type declaration")
      }
    })
  }
  
  parse_topdecl () : Top_decl {
    def tok = get_token ();
    locate (fun () {
      match (tok) {
        | Tok_keyword ("using") =>
          def id = get_qid ();
          expect_operator (";");
          TD_open (id)
          
        | Tok_keyword ("namespace") =>
          def id = get_qid ();
          match (get_token ()) {
            | Tok_operator ("=", _) =>
              when (id.IndexOf ('.') != -1) {
                Message.error ("namespace alias cannot contain dots")
              };
              def id' = get_qid ();
              expect_operator (";");
              TD_namespace_alias (id, id')
              
            | Tok_operator ("{", _) =>
              push_back ();
              def decls = collect_braced_list (parse_topdecl);
              TD_namespace (id, decls)

            | _ =>
              fatal_error ("expecting '}' or '='")
          }

        | _ =>
          push_back ();
          TD_type (parse_type_decl ())
      }
    })
  }

  parse_quotation () : Expr {
    def tok = get_token ();
    def loc = location ();
    
    E_quoted (loc,
      match (get_token ()) {
        | Tok_operator (":", _) =>
          match (tok) {
            | Tok_keyword ("type") =>
              SyntaxType (parse_type ())

            | Tok_identifier ("ttype") =>
              SyntaxTType (parse_type ())
            
            | Tok_identifier ("pattern") =>
              SyntaxPattern (parse_pattern ())

            | Tok_identifier ("parameter") =>
              SyntaxParm (parse_call_parm ())

            | Tok_identifier ("case") =>
              SyntaxCase (parse_match_case ())

            | Tok_identifier ("caseguard") =>
//              SyntaxCaseGuard (parse_case_guard ())
// workaround for compiler bug
              def (a,b) = parse_case_guard ();
              SyntaxCaseGuard (a,b)

            | Tok_identifier ("fundecl") =>
              def h = parse_fun_header (allow_ctor = false, 
                                        allow_inference = true, 
                                        is_lambda = false, knownname = None ());
              SyntaxFunDecl (Function_decl (h, parse_block (h.parms)))

            | Tok_identifier ("funparm") =>
              SyntaxFunParm (parse_funparm (allow_inference = true))

            | _ =>
              fatal_error ("bad quotation type")
          }
        | _ =>
          push_back (); 
          push_back ();
          def expr =
            match (parse_expr_sequence ()) {
              | [x] => x
              | l => E_sequence (loc, l)
            };
          SyntaxExpr (expr)
      }
    )
  }
  
  parse_spliced () : Expr {
    def loc = location_here ();
    def expr = if (ctx.in_pattern)
      E_spliced_patt (loc, parse_pattern ())
    else
      E_spliced (loc, parse_expr ());

    match (peek_token ()) {
      | Tok_operator (":", _) =>
        shift();
        match (get_token ()) {
          | Tok_identifier (ty) =>
            match (ty) {
              | "var" | "int" | "string" | "bool" | "float" | "char" | "typed" 
              | "name" =>
                match (expr) {
                  | E_spliced_patt => E_spliced_special (loc, ty, expr)
                  | E_spliced (e) => E_spliced_special (loc, ty, e)
                  | _ => Util.ice ("not possible")
                }
              | _ =>
                fatal_error ("wrong splicing type after ':'")
            }
          | _ =>
            fatal_error ("expecting splicing type (var, int, string...) after ':'")
        }
      | _ =>
        expr
    }
  }

  'a collect_braced_list (f : void -> 'a) : list ('a) {
    expect_operator ("{");
    def r = collect_list (f);
    expect_operator ("}");
    r
  }
  
  'a collect_list (f : void -> 'a) : list ('a) {
    def loop (acc) {
      match (peek_token ()) {
        | Tok_operator ("}", _) | Tok_EOF => List.Rev (acc)
        | _ =>
          loop (f () :: acc)
      }
    };
    loop ([])
  }

  public variant GrammarElement {
    | GE_operator { name : string; }
    | GE_keyword { name : string; }
    | GE_expression
    | GE_block
    | GE_expression_list { sep : string; }
    | GE_parm_list { sep : string; }
    | GE_funparm
    | GE_parm
  }

  parse_wrt_rule (rule : list (GrammarElement)) : list (SyntaxElement) {
    def loop (acc, lst) {
      match (lst) {
        | GE_operator (n) :: xs =>
          expect_operator (n);
          loop (acc, xs)

        | GE_keyword (n) :: xs =>
          expect_keyword (n);
          loop (acc, xs)

        | GE_expression :: xs =>
          def expr = parse_expr ();
          loop (SyntaxExpr (expr) :: acc, xs)

        | GE_block :: xs =>
          def expr = parse_block ([]);
          loop (SyntaxExpr (expr) :: acc, xs)

        | GE_expression_list (sep) :: xs =>
          def exprs = operator_separated_list (sep, parse_expr);
          loop (List.RevAppend (List.Map (fun (e) { SyntaxExpr (e) }, exprs), 
                                 acc), xs)

        | GE_parm_list (sep) :: xs =>
          def exprs = operator_separated_list (sep, parse_call_parm);
          loop (List.RevAppend (List.Map (fun (e) { SyntaxParm (e) }, exprs), 
                                 acc), xs)

        | GE_parm :: xs =>
          def p = parse_call_parm ();
          loop (SyntaxParm (p) :: acc, xs)

        | GE_funparm :: xs =>
          def p = parse_funparm (allow_inference = true);
          loop (SyntaxFunParm (p) :: acc, xs)

        | [] => List.Rev (acc)
      }
    };

    loop ([], rule)
  }

  public make_parsing_function (macro_name : string, rule : list (GrammarElement), 
                                perm : list (SyntaxElement) -> list (SyntaxElement)) 
                                : void -> Expr 
  {
    fun () {
      def loc = location ();
      def parms = parse_wrt_rule (rule);
      E_macrocall (loc, macro_name, perm (parms))
    }
  }

  init_parens () : void {
    def add (o, c, f) {
      ctx.parens.Add (o, ParenCallback (o, c, f));
      ctx.closing_parens.Add (c, 0);
    };
    add ("<[", "]>", parse_quotation);
    add ("$(", ")", parse_spliced);
    
    add ("[", "]", fun () {
      def loc = location ();
      def make_list (exps : list (Expr)) {
        match (exps) {
          | [] => E_call (loc, E_ref (loc, "Nil"), [])
          | x :: xs => E_call (x.loc, E_ref (x.loc, "Cons"), 
                               [Parm (x), Parm (make_list (xs))])
        }
      };
      def parse_list () {
        match (peek_token ()) {
          | Tok_operator ("]", _) => []
          | Tok_operator (",", _) =>
            shift ();
            parse_expr () :: parse_list ()
          | _ =>
            fatal_error ("expecting expression in list literal")
        }
      };
      match (peek_token ()) {
        | Tok_operator ("]", _) => make_list ([])
        | _ =>
          def expr = parse_expr ();
          make_list (expr :: parse_list ())
      }
    });
    
    add ("{", "}", fun () {
      def loc = location ();
      E_sequence (loc, parse_maybe_null_expr_sequence ())
    });
  }

  public parse (lexer : Lexer) : list (Top_decl)
  {
    ctx.lexer <- lexer;
    ctx.last_token1 <- null;
    ctx.last_token2 <- null;
    ctx.push_back <- 0;
    ctx.in_pattern <- false;
    def r = collect_list (parse_topdecl);
    match (peek_token ()) {
      | Tok_EOF => r
      | _ => fatal_error ("expecting EOF")
    }
  }

} // end module
} // end namespace
