/*
 * Copyright (c) 2003, 2004 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

using Nemerle.Compiler;
using Nemerle.Collections;
using Nemerle.Compiler.Parsetree;

namespace Nemerle.Compiler {

public module Parser {
  public class ParenCallback {
    public opening_paren : string;
    public closing_paren : string;
    public parsing_function : void -> Expr;
  }

  public class KeywordCallback {
    public name : string;
    public parsing_function : void -> Expr;
  }

  public class CTX {
    public mutable lexer : ILexer;
    public mutable last_token1 : Token; // most recent token
    public mutable last_token2 : Token; // one token before
    public mutable push_back : int; // position in last_token{1,2} or 0
    public mutable in_pattern : bool;
    public parens : Hashtable <string, ParenCallback>;
    public closing_parens : Hashtable <string, int>;
    public keywords : Hashtable <string, KeywordCallback>;
  }

  public mutable ctx : CTX;

  this () 
  {
    ctx <- CTX (lexer = null,
                last_token1 = null, 
                last_token2 = null, 
                push_back = 0,
                in_pattern = false,
                keywords = Hashtable (),
                parens = Hashtable (),
                closing_parens = Hashtable ());
    init_parens ();
  }

  opt_locate<'a> (f : void -> option <'a>) : option <'a> 
    where 'a : Located 
  {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    match (ret) {
      | Some (x) => x.loc <- loc
      | None => ()
    };
    ret
  }

  /** executes given function and returns its result enriched
      by location at the beginning of parsing */
  locate<'a> (f : void -> 'a) : 'a 
    where 'a : Located 
  {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    when (ret != null)
      ret.loc <- loc;
    ret
  }

  get_token () : Token {
    match (ctx.push_back) {
      | 1 =>
        ctx.push_back <- 0;
        ctx.last_token1
      | 2 =>
        ctx.push_back <- 1;
        ctx.last_token2
      | _ =>
        def get_token () {
          match (
          try
            ctx.lexer.get_token ()
          catch { e : Lexer.Error =>
            Message.error (ctx.lexer.get_location (), "lexing problem: " + e.name);
            get_token ()
          }
          ) {
            | Tok_comment => get_token ()
            | t => t
          }
        };
        ctx.last_token2 <- ctx.last_token1;
        ctx.last_token1 <- get_token ();
        ctx.last_token1
    }
  }

  peek_token () : Token {
    def tok = get_token ();
    push_back ();
    tok
  }
  
  push_back () : void {
    match (ctx.push_back) {
      | 1 => ctx.push_back <- 2
      | 2 => Util.ice ()
      | _ => ctx.push_back <- 1
    }
  }

  push_back (tok : Token) : void {
    match (ctx.push_back) {
      | 1 => ctx.push_back <- 2; ctx.last_token2 <- tok
      | 2 => Util.ice ()
      | _ => ctx.push_back <- 1; ctx.last_token1 <- tok
    }
  }
  
  shift () : void {
    ignore (get_token ()) 
  }

  location_here () : Location {
    ignore (peek_token ());
    location ()
  }

  location () : Location {
    ctx.lexer.get_location ()
  }

  public token_name (t : Token) : string {
    match (t) {
      | Tok_keyword (x) => "keyword `" + x + "'"
      | Tok_identifier (x) => "identifier `" + x + "'"
      | Tok_operator (x, _) => "operator `" + x + "'"
      | Tok_string_literal => "string literal"
      | Tok_byte_literal => "byte literal"
      | Tok_sbyte_literal => "signed byte literal"        
      | Tok_short_literal => "short literal"
      | Tok_ushort_literal => "unsigned short literal"        
      | Tok_integer_literal => "integer literal"
      | Tok_uinteger_literal => "unsigned integer literal"        
      | Tok_long_literal => "long literal"
      | Tok_ulong_literal => "unsigned long literal"        
      | Tok_float_literal => "float literal"
      | Tok_double_literal => "double literal"
      | Tok_decimal_literal => "decimal literal"        
      | Tok_char_literal => "character literal"
      | Tok_EOF => "end of file"
      | Tok_comment => "documentation comment"
    }
  }

  describe () : string {
    when (ctx.push_back != 2) {
      push_back ()
    };
    def name = token_name (peek_token ());
    "parse error near " + name + ": "
  }

  fatal_error<'a> (msg : string) : 'a {
    Message.fatal_error (location (), describe () + msg)
  }

  error (msg : string) : void {
    Message.error (location (), describe () + msg)
  }

  get_qid () : string {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (".", _) =>
          match (get_token ()) {
            | Tok_identifier (x) => loop (acc + "." + x)
            | _ => fatal_error ("expecting identifier after dot in qualified ID")
          }
        | _ =>
          push_back ();
          acc
      }
    };

    match (get_token ()) {
      | Tok_identifier (x) =>
        loop (x)
      | _ =>
        fatal_error ("expecting qualified identifier")
    }
  }

  get_splicable_qid () : Splicable_string {
    match (peek_token ()) {
      | Tok_identifier =>
        SS_string (Name (get_qid ()))
      | Tok_operator ("$", _) =>
        get_splicable_id ()
      | _ =>
        fatal_error ("expecting qualified identifier")
    }
  }
  
  get_id () : string {
    match (get_token ()) {
      | Tok_identifier (x) => x
      | _ =>
        fatal_error ("expecting identifier")
    }
  }
  
  get_id_or_dummy () : string {
    match (get_token ()) {
      | Tok_identifier (x) => x
      | Tok_keyword ("_") => Util.tmpname ("u")
      | _ =>
        fatal_error ("expecting identifier")
    }
  }
  
  get_splicable_id () : Splicable_string {
    def loc = location_here ();
    match (get_token ()) {
      | Tok_identifier (n) => SS_string (loc, Name (n))
      | Tok_operator ("$", _) =>
        match (get_token ()) {
          | Tok_identifier (id) =>
            if (ctx.in_pattern)
              SS_spliced_expr (loc, E_spliced_patt (P_variable (location (),
                                                                Name (id))))
            else
              SS_spliced_expr (loc, E_ref (location (), Name (id)))
          | Tok_operator ("(", _) =>
            def expr =
              if (ctx.in_pattern)
                E_spliced_patt (parse_pattern ())
              else
                parse_expr ();
            match (peek_token ()) {
              | Tok_operator (":", _) =>
                shift();
                match (get_token ()) {
                  | Tok_identifier (ty) =>
                    match (ty) {
                      | "int" | "string" | "bool" | "float" | "double"
                      | "uint" | "byte" | "sbyte" | "short" | "ushort" | "long"
                      | "char"  | "decimal" | "ulong"
                      | "dyn" | "name" | "typed" =>
                        expect_operator (")");
                        SS_spliced_expr (loc, E_spliced_special (ty, expr))
                      | _ =>
                        fatal_error ("wrong splicing type after ':'")
                    }
                  | _ =>
                    fatal_error ("expecting splicing type after ':'")
                }
              | _ =>
                expect_operator (")");
                SS_spliced_expr (loc, expr);
            }
          | Tok_keyword ("_") =>
            SS_spliced_expr (loc, E_spliced_patt (P_underscore (location ())))
          | _ =>
            fatal_error ("expecting identifier or '(' after '$'")
        }
      | Tok_keyword ("_") => 
        SS_string (loc, Name (Util.tmpname ("u")))
      | _ => fatal_error ("expecting identifier")
    }
  }

  get_tyvar () : string {
    match (get_token ()) {
      | Tok_identifier (tv) => tv
      | _ => fatal_error ("expecting type variable")
    }
  }

  expect_operator (op : string) : void {
    match (get_token ()) {
      | Tok_operator (o, _) when op == o => ()
      | Tok_operator (o, _) when op == ">" && o[0] == '>' =>
        push_back (Tok_operator (o.Substring (1), 0))
      | Tok_operator (o, _) =>
        match (peek_token ()) {
          | Tok_operator (o', _) when op == o + o' => shift (); ()
          | _ => fatal_error ("expecting operator `" + op + "'");
        }
      | _ =>
        fatal_error ("expecting operator `" + op + "'");
    }
  }

  expect_keyword (op : string) : void {
    match (get_token ()) {
      | Tok_keyword (o) when op == o => ()
      | _ =>
        fatal_error ("expecting keyword `" + op + "'");
    }
  }

  flag_keyword (kw : string) : bool {
    match (get_token ()) {
      | Tok_keyword (n) when n == kw => true
      | _ => push_back (); false
    }
  }

  parse_funparm (allow_inference : bool) : Fun_parm {
    def is_params = 
      match (peek_token ()) {
        | Tok_keyword ("params") => shift (); true
        | _ => false
      };
    def id = get_splicable_id ();
    def loc = location ();
    def t =
      match (get_token ()) {
        | Tok_operator (":", _) => parse_type ()
        | _ when allow_inference => push_back (); T_infer ()
        | _ => fatal_error ("expecting typing constraint after parameter name")
      };
    def defl = 
      match (peek_token ()) {
        | Tok_operator ("=", _) => 
          shift (); 
          if (is_params) 
            fatal_error ("variable number of arguments and default value")
          else
            FP_default (parse_expr ())
        | _ => if (is_params) FP_params () else FP_normal ()
      };
    Fun_parm (loc = loc, name = id, ty = t, att = defl)
  }

  /** eats exactly header with [name], [(parameters)] and inferencable [: type] */
  parse_fun_header (allow_inference : bool, 
                    allow_ctor : bool,
                    is_lambda : bool, 
                    knownname : option <Splicable_string>) : Fun_header
  {
    locate (fun () {
      mutable is_ctor <- false;
      
      def name = 
        match (knownname) {
          | None =>
            match (peek_token ()) {
              | Tok_keyword ("this") when allow_ctor => 
                shift ();
                is_ctor <- true; SS_string (Name (".ctor"))
              | Tok_keyword ("fun") when is_lambda =>
                shift (); SS_string (Name (""))
              | _ when is_lambda => fatal_error ("expecting `fun'")
              | Tok_identifier  
              | Tok_operator ("$", _) => get_splicable_id ()
              | _ => fatal_error ("expecting function name")
            }
          | Some (n) => n
        };

      // `splicing_type' is for noting, that there are spliced tyvars
      // if yes, it's T_spliced with expression describing their list
      // else it's T_void ()
      def (tyvars, splicing_type ) = 
        match (get_token ()) {
          | Tok_operator ("<", _) =>
            match (peek_token ()) {
              | Tok_operator (".", _) =>
                expect_operator ("..");
                match (get_splicable_id ()) {
                  | SS_string =>
                    fatal_error ("expected spliced expression")
                  | SS_spliced_expr (e) =>
                    expect_operator (">");                    
                    ([], T_spliced (e))
                }
              | _ =>
                def tyvars = operator_separated_list (",", get_tyvar);
                expect_operator (">");
                (tyvars, T_void ())
            }
          | _ => push_back (); ([], T_void ())
        };
        
      expect_operator ("(");
      def parse_parm () { parse_funparm (allow_inference) };
      def parms =
        match (peek_token ()) {
          | Tok_operator (")", _) => []
          | Tok_operator (".", _) =>
            shift ();
            expect_operator (".");
            match (get_splicable_id ()) {
              | SS_spliced_expr (e) =>
                  [Fun_parm (e.loc, SS_string (Name ("")), <[ type: void ]>, 
                             FP_default (E_spliced (e)))]
              | SS_string =>
                fatal_error ("expected spliced expression")
              }
          | _ => operator_separated_list (",", parse_parm)
        };
      expect_operator (")");
      
      def ret_type =
        match (get_token ()) {
          | _ when is_ctor => push_back (); T_void ()
          | Tok_operator (":", _) => parse_type ()
          | _ when allow_inference => push_back (); T_infer ()
          | _ => fatal_error ("expecting typing constraint on function return value")
        };

      def typarms = parse_where_constraints (tyvars, splicing_type);

      Fun_header (name = name,
                  ret_type = ret_type, 
                  parms = parms, 
                  typarms = typarms)
    })
  }

  parse_literal () : option <Literal> {
    match (get_token ()) {
      | Tok_keyword ("null") => Some (L_null ())
      | Tok_keyword ("true") => Some (L_bool (true))        
      | Tok_keyword ("false") => Some (L_bool (false))
      | Tok_operator ("(", _) =>
        match (get_token ()) {
          | Tok_operator (")", _) => Some (L_void ())
          | _ => push_back (); push_back (); None ()
        }
      | Tok_string_literal (s) => Some (L_string (s))
      | Tok_byte_literal (n) => Some (L_byte (n))
      | Tok_sbyte_literal (n) => Some (L_sbyte (n))
      | Tok_short_literal (n) => Some (L_short (n))
      | Tok_ushort_literal (n) => Some (L_ushort (n))
      | Tok_integer_literal (n) => Some (L_int (n))
      | Tok_uinteger_literal (n) => Some (L_uint (n))
      | Tok_long_literal (n) => Some (L_long (n))
      | Tok_ulong_literal (n) => Some (L_ulong (n))
      | Tok_float_literal (n) => Some (L_float (n))
      | Tok_double_literal (n) => Some (L_double (n))
      | Tok_decimal_literal (n) => Some (L_decimal (n))                
      | Tok_char_literal (c) => Some (L_char (c))
      | _ => push_back (); None ()
    }
  }

  parse_closed_prim_expr () : Expr {
    def loc = location_here ();
    match (parse_literal ()) {
      | Some (l) => E_literal (loc, l)
      | None =>
        def problem () {
          Message.fatal_error (loc, describe () + "expecting primary expression")
        };
        
        match (get_token ()) {
          | Tok_keyword ("this") => E_this (loc)
          | Tok_keyword ("base") => E_base (loc)
          | Tok_keyword ("typeof") => 
            expect_operator ("(");
            def type_expr = parse_type ();
            expect_operator (")");
            E_typeof (loc, type_expr)
            
          | Tok_identifier (n) => E_ref (loc, Name (n))
          | Tok_operator ("(", _) =>
            def expr = parse_expr ();
            match (get_token ()) {
              | Tok_operator (":>", _) =>
                def t = parse_type ();
                expect_operator (")");
                E_type_conversion (loc, expr, t)

              | Tok_operator (":", _) =>
                def t = parse_type ();
                expect_operator (")");
                E_type_enforcement (loc, expr, t)

              | Tok_operator (",", _) =>
                def exprs = expr :: operator_separated_list (",", parse_expr);
                expect_operator (")");
                E_tuple (loc, exprs)
                
              | Tok_operator (")", _) => 
                match (expr) {
                  | E_expr_list => E_tuple (loc, [expr])
                  | _ => expr
                }

              | _ => Message.fatal_error (loc, "unbalanced `('")
            }

          | Tok_operator ("$", _) =>
            push_back ();
            match (get_splicable_id ()) {
              | SS_spliced_expr ((E_spliced_special) as e) =>
                e
              | SS_spliced_expr (e) =>
                if (ctx.in_pattern)
                  e
                else
                  E_spliced (e)
              | SS_string =>
                Util.ice ("expected spliced expression")
            }

          | Tok_operator (o, _) =>
            def parse_paren (p : ParenCallback) {
              def problem () {
                Message.error (loc, "unbalanced `" + p.opening_paren + "'");
                fatal_error ("expecting `" + p.closing_paren + "' here")
              };
              def expr = p.parsing_function ();
              match (get_token ()) {
                | Tok_operator (o, _) =>
                  if (p.closing_paren == o)
                    expr
                  else
                    match (get_token ()) {
                      | Tok_operator (o', _) when p.closing_paren == o + o' => expr
                      | _ => push_back (); problem ()
                    }
                | _ => problem ()
              } 
            };
            
            match (ctx.parens.Get (o)) {
              | Some (p) => parse_paren (p)
              | None =>
                match (get_token ()) {
                  | Tok_operator (o', _) =>
                    match (ctx.parens.Get (o + o')) {
                      | Some (p) => parse_paren (p)
                      | None => push_back (); problem ()
                    }
                  | _ => push_back (); problem ()
                }
            }
            
          | _ => problem ()
        }
    }
  }

  parse_call_parm () : Parm {
    def is_ref = flag_keyword ("ref");
    def maybe_name_expr = parse_expr ();
    match (peek_token ()) {
      | Tok_operator ("=", _) =>
        def name = 
          match (maybe_name_expr) {
            | E_spliced (e) => SS_spliced_expr (e)
            | E_ref (n) => SS_string (n)
            | E_spliced_special
            | E_spliced_patt => SS_spliced_expr (maybe_name_expr)
            | _ =>
              fatal_error ("expected parameter name before '=' in call parm")
          };
        shift ();
        Parm (is_ref, parse_expr (), name)
      | _ =>
        Parm (is_ref, maybe_name_expr, SS_string (Name ("")))
    }
  }
    
  parse_prim_expr () : Expr {
    def loop (expr : Expr) {
      match (get_token ()) {
        | Tok_operator ("[", _) =>
          def exprs = operator_separated_list (",", parse_expr);
          expect_operator ("]");
          loop (E_indexer (expr.loc, expr, exprs))
          
        | Tok_operator (".", _) => 
          def id = get_splicable_id ();
          loop (E_member (expr.loc, expr, id))
          
        | Tok_operator ("(", _) =>
          def parms =
            match (peek_token ()) {
              | Tok_operator (")", _) => shift (); []
              | _ => 
                def parms = operator_separated_list (",", parse_call_parm);
                expect_operator (")");
                parms
            };
          loop (E_call (expr.loc, expr, parms))

        | _ => push_back (); expr
      }
    };

    loop (parse_closed_prim_expr ())
  }

  parse_unary_expr () : Expr {
    match (peek_token ()) {
      | Tok_operator ("(", _)
      | Tok_operator ("$", _) => parse_prim_expr ()

      | Tok_operator (".", _) =>
        expect_operator ("..");
        match (get_splicable_id ()) {
          | SS_spliced_expr (e) =>
            E_expr_list (e.loc, E_spliced (e))                
          | SS_string =>
            fatal_error ("expected spliced expression")
        }

      | Tok_operator (o, pri) =>
        def loc = location ();
        def unary () {
          when (pri == 0) {
            fatal_error ("operator `" + o + "' cannot be used in unary context")
          };
          shift ();
          E_call (loc, E_ref (loc, Name (o)), [Parm (parse_unary_expr ())])
        };
        
        if (ctx.parens.Contains (o))
          parse_prim_expr ()
        else {
          shift ();
          def tok = peek_token ();
          push_back ();
          match (tok) {
            | Tok_operator (o', _) =>
              if (ctx.parens.Contains (o + o'))
                parse_prim_expr ()
              else unary ()
            | _ => unary ()
          }
        }
      | _ => parse_prim_expr ()
    }
  }

  parse_pattern () : Pattern {
    def loop () {
      def loc = location_here ();
      def pat = parse_closed_pattern ();
      match (peek_token ()) {
        | Tok_operator ("::", _) => 
          shift (); 
          P_cons (loc, SS_string (Name ("Cons")), P_tuple (loc, [pat, loop ()]))
        | _ => pat
      }
    };

    loop ()
  }

  parse_pattern_after_id (id : Splicable_string) : Pattern {
    def id = 
      match (peek_token ()) {
        | Tok_operator (".", _) =>
          shift ();
          def qid = get_qid ();
          match (id) {
            | SS_string ({ id = n }) => 
              SS_string (Name (n + "." + qid))
            | _ =>
              fatal_error ("mixing spliced names with regular ids isn't allowed")
          }
        | _ => id;
      };
    def loc = location ();
    match (peek_token ()) {
      | Tok_operator ("{", _)
      | Tok_operator ("(", _) => 
        P_cons (loc, id, tuple_or_record ()) 
      | Tok_keyword ("_") => 
        shift ();
        P_cons (loc, id, P_underscore (loc))
      | _ =>
        match (id) {
          | SS_string => P_cons (loc, id, P_underscore (loc))
          | SS_spliced_expr (E_spliced_special (ty, expr)) =>
            P_spliced_special (loc, ty, expr)
          | SS_spliced_expr (expr) =>
            P_spliced (loc, expr)
        }
    }
  }

  /** this function expects first '{' to be already shifted, starting
      its scanning routine from inside of record;
      but it shifts the ending '}'
   */
  parse_record () : Pattern {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator ("}", _) => List.Rev (acc)
        | Tok_identifier (n) =>
          expect_operator ("=");
          def pat = parse_pattern ();
          def res = (n, pat);
          match (get_token ()) {
            | Tok_operator (";", _) => ()
            | Tok_operator ("}", _) => push_back ()
            | _ => fatal_error ("found junk after pattern in record")
          };
          loop (res :: acc)
        | _ => fatal_error ("expecting named pattern")
      }
    };
    def loc = location ();
    match (peek_token ()) {
      | Tok_operator (".", _) =>
        shift ();
        expect_operator (".");
        match (get_splicable_id ()) {
          | SS_spliced_expr (e) =>
            expect_operator ("}");
            P_record ([("", P_patt_list (loc, P_spliced (e)))]);
          | SS_string =>
            fatal_error ("expected spliced expression")
        }
      | _ =>
        P_record (loc, loop ([]))
    }
  }

  tuple_or_record () : Pattern {
    match (get_token ()) {
      | Tok_operator ("(", _) =>
        def pats = operator_separated_list (",", parse_pattern);
        expect_operator (")");
        P_tuple (location_here (), pats)
      | Tok_operator ("{", _) => parse_record ()
      | _ => fatal_error ("expecting tuple or record pattern")
    }
  }
    
  parse_closed_pattern () : Pattern {
    def loc = location_here ();
  
    match (parse_literal ()) {
      | Some (l) => P_literal (loc, l)
      | None =>
        match (get_token ()) {
          | Tok_operator ("-", _) =>
            match (parse_literal ()) {
              | Some (L_int (v)) => P_literal (loc, L_int (-v))
              | _ => 
                fatal_error ("expecting integer literal")
            }          
         
          | Tok_operator ("+", _) =>
            match (parse_literal ()) {
              | Some (L_int (v)) => P_literal (loc, L_int (v))
              | _ => 
                fatal_error ("expecting integer literal")
            }
            
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            push_back ();
            def id = get_splicable_id ();
            parse_pattern_after_id (id)
            
          | Tok_operator ("{", _) =>
            parse_record ()

          | Tok_operator (".", _) =>
            expect_operator (".");
            match (get_splicable_id ()) {
              | SS_spliced_expr (e) =>
                P_patt_list (e.loc, P_spliced (e))
              | SS_string =>
                fatal_error ("expected spliced expression")
            }
            
          | Tok_operator ("(", _) =>
            def pat = parse_pattern ();
            match (get_token ()) {
              | Tok_operator (",", _) =>
                def pats = pat :: operator_separated_list (",", parse_pattern);
                expect_operator (")");
                P_tuple (loc, pats)
              | Tok_operator (")", _) =>
                match (peek_token ()) {
                  | Tok_keyword ("as") =>
                    shift ();
                    def id = get_splicable_id ();
                    P_as (loc, pat, id)
                    
                  | _ =>
                    P_tuple (loc, [pat])
                }
              | _ =>
                fatal_error ("expecting `,' or ')' in tuple pattern")
            }

          | Tok_keyword ("_") =>
            P_underscore (loc)

          | Tok_operator ("[", _) =>
            def loop () {
              match (get_token ()) {
                | Tok_operator (",", _) =>
                  match (peek_token ()) {
                    | Tok_operator ("]", _) => 
                      P_cons (SS_string (Name ("Nil")), P_underscore ())
                    | _ => 
                      def p = parse_pattern ();
                      P_cons (p.loc, SS_string (Name ("Cons")),
                              P_tuple (p.loc, [p, loop ()]))
                  }
                | Tok_operator ("]", _) =>
                  P_cons (SS_string (Name ("Nil")), P_underscore ())
                | _ => fatal_error ("expecting pattern in list")
              }
            };

            match (peek_token ()) {
              | Tok_operator ("]", _) => shift (); 
                P_cons (SS_string (Name ("Nil")), P_underscore ())
              | _ =>
                def p = parse_pattern ();
                P_cons (p.loc, SS_string (Name ("Cons")), P_tuple (p.loc, [p, loop ()]))
            }
            
          | Tok_operator ("<[", _) =>
            def back = ctx.in_pattern;
            ctx.in_pattern <- true;
            def expr = parse_quotation ();
            expect_operator ("]>");
            ctx.in_pattern <- back;
            match (expr) {
              | E_quoted (el) => P_quoted (loc, el)
              | _ => Util.ice ("parse_quoted returned sth strange")
            }
            
          | _ => fatal_error ("expecting pattern")
        }
    }
  }

  parse_case_guard () : Pattern * option <Expr> {
    def pat = parse_pattern ();
    if (flag_keyword ("when"))
      (pat, Some (parse_expr ()))
    else (pat, None ());
  }

  parse_match_case () : Match_case {
    def loop2 (acc) {
      def res = parse_case_guard ();
      match (get_token ()) {
        | Tok_operator ("=>", _) => List.Rev (res :: acc)
        | Tok_operator ("|", _) => loop2 (res :: acc)
        | _ => fatal_error ("found junk after pattern")
      }
    };
    
    // eat pattern part and '=>'
    def pats = 
      match (peek_token ()) {
        | Tok_operator ("|", _) => 
          shift ();
          match (peek_token ()) {
            | Tok_operator (".", _) =>
              shift ();
              expect_operator (".");
              match (get_splicable_id ()) {
                | SS_spliced_expr (e) =>
                  expect_operator ("=>");
                  [(P_patt_list (e.loc, P_spliced (e)), None ())]                  
                | SS_string =>
                  fatal_error ("expected spliced expression")
              }
            | _ => loop2 ([])
          }
        | _ => loop2 ([])
      };

    def loc' = location_here ();
    def expr =
      match (parse_expr_sequence ()) {
        | [x] => x
        | l => E_sequence (loc', l)
      };

    Match_case (pats, expr)
  }

  parse_semiclosed_expr () : Expr {
    def loc = location_here ();
    def tok = get_token ();
    //Message.debug ("pse " + token_name (tok));
    match (tok) {
      | Tok_keyword (k) when ctx.keywords.Contains (k) =>
        def k = Option.UnSome (ctx.keywords.Get (k));
        k.parsing_function ()
        
      | Tok_keyword ("match") =>
        expect_operator ("(");
        def expr = parse_expr ();
        expect_operator (")");
        match (get_token ()) {
          | Tok_operator ("{", _) =>
            match (peek_token ()) {
              | Tok_operator (".", _) =>
                shift ();
                expect_operator (".");
                match (get_splicable_id ()) {
                  | SS_spliced_expr (e) =>
                    expect_operator ("}");                  
                    E_match (loc, expr, 
                             [Match_case ([], E_expr_list (e.loc, E_spliced (e)))]);
                  | SS_string =>
                    fatal_error ("expected spliced expression")
                }
              | _ =>
                push_back ();
                def cases = collect_braced_list (parse_match_case);
                E_match (loc, expr, cases)
            }
          | _ =>
            fatal_error ("expecting '{' after 'match (e)'")
        }
      | Tok_keyword ("throw") =>
        E_raise (loc, parse_expr ())

      | Tok_keyword ("try") =>
        def body = parse_expr ();
        match (get_token ()) {
          | Tok_keyword ("catch") =>
            def parse_with () {
              match (peek_token ()) {
                | Tok_operator ("|", _) => shift ()
                | _ => ()
              };
              def id = get_splicable_id ();
              expect_operator (":");
              def t = parse_type ();
              expect_operator ("=>");
              match (parse_expr_sequence ()) {
                | [x] => (id, t, x)
                | l => (id, t, E_sequence (loc, l))
              }
            };

            def mktry (h, body) {
              def (id, t, handler) = h;
              E_try_with (loc, body, id, t, handler)
            };
            
            List.FoldLeft (collect_braced_list (parse_with), body, mktry)
            
          | Tok_keyword ("finally") =>
            def handler = parse_expr ();
            E_try_finally (loc, body, handler)

          | _ => fatal_error ("expecting `catch' or `finally'")
        }

      | Tok_keyword ("array") =>
        match (get_token ()) {
          | Tok_operator ("[", _) =>
            def exprs = parse_list ();
            expect_operator ("]");
            E_mkarray (loc, exprs)

          | Tok_operator ("(", _) =>
            def exprs = operator_separated_list (",", parse_expr);
            expect_operator (")");
            E_empty_array (loc, exprs)

          | _ => fatal_error ("expected [ ... ] after `array'")
        }

      | Tok_keyword ("fun") =>
        push_back ();
        def h = parse_fun_header (allow_ctor = false,
                                  allow_inference = true, 
                                  is_lambda = true, 
                                  knownname = None ());
        def expr = parse_block (h.parms);
        E_lambda (loc, Function_decl (h, expr))

      | Tok_keyword ("mutable") =>
        def id = get_splicable_id ();
        expect_operator ("<-");
        E_let (loc, true, id, parse_expr ())

      | Tok_keyword ("def") =>
        def parse_val (id) {
          expect_operator ("=");
          E_let (loc, false, id, parse_expr ())
        };
        def parse_pat (idopt) {
          def pat =
            match (idopt) {
              | None => parse_pattern ()
              | Some (id) =>
                parse_pattern_after_id (id);
            };
          expect_operator ("=");
          def expr = parse_expr ();
          E_letpat (loc, pat, expr)
        };
        def parse_funs (acc, idopt) {
          def h = parse_fun_header (allow_ctor = false, 
                                    allow_inference = true, 
                                    is_lambda = false, knownname = idopt);
          def fd = Function_decl (h, parse_block (h.parms));
          match (peek_token ()) {
            | Tok_keyword ("and") =>
              shift ();
              parse_funs (fd :: acc, None ())
            | _ => E_letfun (loc, List.Rev (fd :: acc))
          }
        };
        
        match (peek_token ()) {
          | Tok_keyword ("_")
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            def id = get_splicable_id ();
            match (peek_token ()) {
              | Tok_operator ("(", _) 
              | Tok_operator ("<", _) => 
                parse_funs ([], Some (id))
                
              | Tok_operator ("=", _) =>
                parse_val (id)
              
              | _ => parse_pat (Some (id))
            }

          | Tok_operator (".", _) =>
            shift ();
            expect_operator (".");
            match (get_splicable_id ()) {
              | SS_spliced_expr (e) =>
                E_letfun (loc, [Function_decl (Fun_header (), 
                                               E_expr_list (E_spliced (e)))])
              | SS_string =>
                fatal_error ("expected spliced expression")
            }
          | _ => parse_pat (None ())
        }
      
      | _ => push_back (); parse_unary_expr ()
    }
  }

  parse_expr () : Expr {
    def is_paren (s) {
      ctx.parens.Contains (s) || ctx.closing_parens.Contains (s)
    };

    def make_bin (loc, op, e1, e2) {
      match (op) {
        | "<-" =>
          E_assign (loc, e1, e2)
        | "::" =>
          E_call (loc, E_ref (loc, Name ("Cons")), [Parm (e1), Parm (e2)])
        | _ =>
          E_call (loc, E_ref (loc, Name (op)), [Parm (e1), Parm (e2)])
      }
    };
    
    def parse_pri (pri) : Expr {
      def loop_left (expr) {
        def loc = location_here ();
        match (get_token ()) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            def expr' = parse_pri (pri - 1);
            loop_left (make_bin (loc, s, expr, expr'))
          | _ => 
            push_back (); 
            expr
        }
      };

      def loop_right () {
        def loc = location_here ();
        def expr = parse_pri (pri - 1);
        match (get_token ()) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            make_bin (loc, s, expr, loop_right ())
          | _ => push_back (); expr
        }
      };
     
      match (pri) {
        | 0 => parse_semiclosed_expr ()
        | 1 | 8 => loop_right ()
        | _ => loop_left (parse_pri (pri - 1))
      }
    };

    parse_pri (9)
  }

  parse_expr_sequence () : list <Expr> {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (";", _) =>
          match (peek_token ()) {
            | Tok_operator ("}", _) 
            | Tok_operator ("|", _) 
            | Tok_operator ("]", _) 
              => List.Rev (acc)
            | _ => loop (parse_expr () :: acc)
          }
        | Tok_operator ("}", _) 
        | Tok_operator ("|", _) 
        | Tok_operator ("]", _) 
          => push_back (); List.Rev (acc)
        | _ => fatal_error ("expecting `;' separator after expression in sequence")
      }
    };

    loop ([parse_expr ()])
  }

  parse_maybe_null_expr_sequence () : list <Expr> {
    match (peek_token ()) {
      | Tok_operator ("}", _) 
      | Tok_operator ("]", _) => []
      | _ => parse_expr_sequence ()
    }
  }

  parse_block (parms : list <Fun_parm>) : Expr 
  {
    def loc = location ();
    match (peek_token ()) {
      // entire function body may be spliced
      | Tok_operator ("$", _) =>
        parse_expr ()

      // standard body enclosed by { ... }
      | Tok_operator ("{", _) =>
        shift ();
        match (peek_token ()) {
          | Tok_operator ("}", _) => 
            shift (); E_sequence (location (), [])
          | Tok_operator ("|", _) =>
            // convert function's parameters to tuple to be matched
            def parms_to_tupl (prs : list <Fun_parm>, acc) {
              match (prs) {
                | [] => E_tuple (List.Rev (acc))
                | {name = SS_string (x)} :: xs => 
                  parms_to_tupl (xs, E_ref (x) :: acc)
                | _ => fatal_error ("illegal spliced parameter?")
              }
            };
            push_back ();
            def cases = collect_braced_list (parse_match_case);
            match (parms) {
              | [{name = SS_string (x)}] => 
                E_match (loc, E_ref (x), cases)
              | _::_::_ => 
                E_match (loc, parms_to_tupl (parms, []), cases)
              | [] =>             
                fatal_error ("functions with direct matching must have parameters")
              | _ => fatal_error ("illegal spliced parameter?")
            }
          | _ => 
            def r = E_sequence (loc, parse_expr_sequence ());
            expect_operator ("}");
            r
        }
      | _ =>
        fatal_error ("expected `{' at the beginning of function body")
    }
  }
  
  parse_type () : Type {
    def prim_type () {
      def get_args () {
        match (get_token ()) {
          | Tok_operator ("<", _) =>
            def args = operator_separated_list (",", parse_type);
            expect_operator (">");
            args
          | _ =>
            push_back ();
            []
        }
      };
      match (get_token ()) {
        | Tok_identifier
        | Tok_operator ("$", _) =>
          push_back ();
          def id = get_splicable_id ();
          def id = 
            match (peek_token ()) {
              | Tok_operator (".", _) =>
                shift ();
                def qid = get_qid ();
                match (id) {
                  | SS_string ({ id = n }) => 
                    SS_string (Name (n + "." + qid))
                  | _ =>
                    fatal_error ("mixing spliced names with regular ids isn't allowed")
                }
              | _ => id;
            };
          match (peek_token ()) {
            | Tok_operator ("<", _) => 
              T_app (id, get_args ())
            | _ =>
              match (id) {
                | SS_string => T_app (id, [])
                | SS_spliced_expr (E_spliced_special (ty, expr)) =>
                  match (ty) {
                    | "name" =>
                      T_spliced_special (ty, expr)
                    | _ =>
                      fatal_error ("wrong splicing type after ':'")
                  }
                | SS_spliced_expr (expr) =>
                  T_spliced (expr)
              }
          }

        | Tok_operator (".", _) =>
          expect_operator (".");
          match (get_splicable_id ()) {
            | SS_spliced_expr (e) =>
              T_type_list (T_spliced (e))
            | SS_string =>
              fatal_error ("expected spliced expression")
          }
          
        | Tok_keyword ("array") => 
          match (get_token ()) {
            | Tok_operator ("<", _) =>
              def t = T_array (prim_type ());
              expect_operator (">");
              t
            | _ =>
              fatal_error ("expecting < after array")
          }
        
        | Tok_keyword ("ref") => T_ref (prim_type ())
        
        | Tok_keyword ("out") => T_out (prim_type ())

        | Tok_keyword ("void") => T_void ()

        | Tok_operator ("(", _) =>
          def t = parse_type ();
          expect_operator (")");
          t

        | _ =>
          fatal_error ("expecting type expression")
      }
    }

    and prod_type () {
      def loop (acc) {
        match (get_token ()) {
          | Tok_operator ("*", _) =>
            loop (prim_type () :: acc)
          | _ => 
            push_back ();
            match (acc) {
              | [x] => x
              | acc => T_prod (List.Rev (acc))
            }
        }
      };

      loop ([prim_type ()])
    };

    def fun_type () {
      def t = prod_type ();
      match (get_token ()) {
        | Tok_operator ("->", _) =>
          T_fun (t, fun_type ())
        | _ => 
          push_back ();
          t
      }
    };

    fun_type ()
  }

  get_attrs () : list <Modifier> {
    def loop (acc) {
      match (get_token ()) {
        | Tok_keyword ("mutable") => loop (Mod_mutable () :: acc)
        | Tok_keyword ("public") => loop (Mod_public () :: acc)
        | Tok_keyword ("private") => loop (Mod_private () :: acc)
        | Tok_keyword ("static") => loop (Mod_static () :: acc)
        | Tok_keyword ("new") => loop (Mod_new () :: acc)
        | Tok_keyword ("private") => loop (Mod_private () :: acc)
        | Tok_keyword ("static") => loop (Mod_static () :: acc)
        | Tok_keyword ("new") => loop (Mod_new () :: acc)
        | Tok_keyword ("protected") => loop (Mod_protected () :: acc)
        | Tok_keyword ("internal") => loop (Mod_internal () :: acc)
        | Tok_keyword ("abstract") => loop (Mod_abstract () :: acc)
        | Tok_keyword ("sealed") => loop (Mod_sealed () :: acc)
        | Tok_keyword ("override") => loop (Mod_override () :: acc)
        | Tok_keyword ("virtual") => loop (Mod_virtual () :: acc)
        | Tok_operator ("[", _) => 
          def exps = operator_separated_list (",", parse_expr);
          expect_operator ("]");
          loop (Mod_attribute (exps) :: acc)          
        | _ =>
          push_back ();
          List.Rev (acc)
      }
    };
    match (peek_token ()) {
      | Tok_operator (".", _) =>
        expect_operator ("..");
        match (get_splicable_id ()) {
          | SS_spliced_expr (e) =>
            [Mod_attribute ([E_expr_list (E_spliced (e))])]
          | SS_string =>
            fatal_error ("expected spliced expression")
        }
      | _ =>
        loop ([])
    }
  }
  
  operator_separated_list<'a> (op : string, f : void -> 'a) : list <'a> {
    def loop (acc) {
      match (get_token ()) {
        | Tok_operator (o, _) when o == op => loop (f () :: acc)
        | _ => push_back (); List.Rev (acc)
      }
    };

    loop ([f ()])
  }

  parse_tyvars () : list <string> {
    operator_separated_list (",", get_tyvar)
  }

  parse_where_constraints (tyvars : list <string>, splicing_type : Type) 
  : Typarms 
  {
    def loop (acc) {
      if (flag_keyword ("where")) {
        match (peek_token ()) {
          | Tok_operator (".", _) =>
            shift ();
            expect_operator (".");
            match (get_splicable_id ()) {
              | SS_spliced_expr (e) =>
                (List.Rev (acc), T_spliced (e))
              | _ =>
                fatal_error ("expected spliced expression")
            }
          | _ =>
            def tv = get_tyvar ();
            expect_operator (":");
            def types = operator_separated_list (",", parse_type);
            def acc = List.FoldLeft (types, acc, fun (t, acc) { 
              Constraint (tv, t) :: acc 
            });
            loop (acc)
        }
      } else (List.Rev (acc), T_void ())
    };
    def (where_cts, where_spl_t) = loop ([]);
    match ((splicing_type, where_spl_t)) {
      | (T_void, T_void) =>
        Typarms (tyvars, where_cts)
      | _ =>
        Typarms (tyvars, Constraint ("", T_prod ([splicing_type, where_spl_t])) 
                 :: where_cts)
    }
  }

  parse_field (loc : Location, attrs : list<Modifier>) : Class_member {
    match (peek_token ()) {
      | Tok_identifier | Tok_operator ("$", _) =>
        def name = get_splicable_id ();
        expect_operator (":");
        def t = parse_type ();
        expect_operator (";");
        
        M_field (loc = loc, name = name, modifiers = attrs, ty = t)
      | _ => fatal_error ("name missing during parsing of field")
    }
  }

  parse_method (loc : Location, attrs : list<Modifier>) : Class_member {
    def parse_extern () {
      match (get_token ()) {
        | Tok_keyword ("extern") =>
          match (get_token ()) {
            | Tok_string_literal (s) => 
              expect_operator (";");
              s
            | _ => fatal_error ("found some junk after extern (expecting string)")
          }
        | _ => fatal_error ("found some junk after `=' (expecting extern)")
      }
    };
    
    def ctr = 
      match (peek_token ()) {
        | Tok_operator ("$", _) 
        | Tok_identifier => false
        | Tok_keyword ("this") => true
        | _ =>
          fatal_error ("name of method expected")
      };
    def h = parse_fun_header (allow_ctor = ctr, 
                              allow_inference = false,
                              is_lambda = false,
                              knownname = None ());
    def impl =
      match (get_token ()) {
        | Tok_keyword ("implements") =>
          match (peek_token ()) {
            | Tok_operator (".", _) =>
              expect_operator ("..");
              match (get_splicable_id ()) {
                | SS_spliced_expr (e) =>
                  [SS_spliced_expr (E_expr_list (E_spliced (e)))]
                | _ =>
                  fatal_error ("expected spliced expression after `..'")
              }
            | _ =>
              operator_separated_list (",", get_splicable_qid)
          }
        | _ => push_back (); []
      };
    def body =
      match (peek_token ()) {
        | Tok_operator ("=", _) =>
          shift ();
          FB_extern (parse_extern ())
        | Tok_operator ("{", _) =>
          FB_parsed_expr (parse_block (h.parms))
        | Tok_operator (";", _) =>
          shift ();
          FB_abstract ()
        | Tok_operator ("$", _) =>
          match (get_splicable_id ()) {
            | SS_spliced_expr (e) =>
              FB_parsed_expr (E_spliced (e))
            | _ => Util.ice ("get_splicable_id returned impossible value")
          }
        | _ => fatal_error ("expecting method body")
      };

    M_function (header = h, 
                name = h.name, 
                modifiers = attrs, 
                loc = loc, 
                body = body, 
                kind = FK_method (impl))
  }
  
  parse_type_member () : Class_member {
    def loc = location_here ();
    def attrs = get_attrs ();
    
    match (get_token ()) {
      | Tok_identifier =>
        match (peek_token ()) {
          | Tok_operator ("(", _)
          | Tok_operator ("<", _) => 
            push_back ();
            parse_method (loc, attrs)
          | _ =>
            push_back ();
            parse_field (loc, attrs)
        }
        
      | Tok_keyword ("this") =>
        push_back ();
        parse_method (loc, attrs)

      | _ =>
        push_back ();
        def td = parse_type_decl ();
        td.modifiers <- List.Append (td.modifiers, attrs);
        M_type (loc = loc, 
                name = td.name, 
                modifiers = td.modifiers, 
                td = td)
    }
  }
  
  parse_type_decl () : Type_decl {
    def parse_header () {
      match (get_token ()) {
        | Tok_identifier (name) =>
          def tyvars =
            match (get_token ()) {
              | Tok_operator ("<", _) =>
                def tyvars = parse_tyvars ();
                expect_operator (">");
                tyvars
              | _ => 
                push_back (); 
                []
            };
            
          def t_extends =
            match (get_token ()) {
              | Tok_operator (":", _) =>
                operator_separated_list (",", parse_type)
              | _ => 
                push_back ();
                []
            };

          def typarms = parse_where_constraints (tyvars, T_void ());
            
          (name, typarms, t_extends)
          
        | _ => fatal_error ("expecting type name")
      }
    };
    
    def parse_variant_member () {
      def tok = get_token ();
      locate (fun () {
        match (tok) {
          | Tok_operator ("|", _) =>
            def id = get_splicable_id ();
            def members =
              match (peek_token ()) {
                | Tok_operator ("{", _) =>
                  def parse_field () {
                    ignore (peek_token ());
                    locate (fun () {
                      def attrs = get_attrs ();
                      def id = get_splicable_id ();
                      expect_operator (":");
                      def ty = parse_type ();
                      expect_operator (";");
                      M_field (name = id,
                               modifiers = attrs,
                               ty = ty)
                    })
                  };
                  collect_braced_list (parse_field)
                | _ => []
              };
            TD_variant_option (name = id, 
                               modifiers = [], 
                               t_extends = [],
                               typarms = Typarms ([], []),
                               decls = members)
          | _ => fatal_error ("expecting variant option")
        }
      })
    };
    
    def parse_iface_member () {
      ignore (peek_token ());
      locate (fun () {
        def is_new = flag_keyword ("new");
        def h = parse_fun_header (allow_ctor = false, allow_inference = false,
                                  is_lambda = false, knownname = None ());
        expect_operator (";");
        M_function (name = h.name, 
                    modifiers = Mod_public () :: if (is_new) [Mod_new ()] else [],
                    header = h, 
                    kind = FK_iface_method (is_new), 
                    body = FB_abstract ())
      })
    };
    
    def parse_members () {
      collect_braced_list (parse_type_member)
    };
    
    def attrs = get_attrs ();
    def tok = get_token ();
    locate (fun () {
      match (tok) {
        | Tok_keyword ("type")
        | Tok_keyword ("class")
        | Tok_keyword ("struct")
        | Tok_keyword ("module")
        | Tok_keyword ("interface")
        | Tok_keyword ("variant") =>
          def (name, typarms, t_extends) = parse_header ();
          def (attrs, td) =
            match (tok) {
              | Tok_keyword ("class") =>
                (attrs, TD_class (parse_members ()))
              | Tok_keyword ("struct") =>
                (Mod_struct () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("module") =>
                (Mod_module () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("type") =>
                expect_operator ("=");
                def t = parse_type ();
                expect_operator (";");
                (attrs, TD_alias (t))
                
              | Tok_keyword ("interface") =>
                def decls = collect_braced_list (parse_iface_member);
                (attrs, TD_interface (decls))
                
              | Tok_keyword ("variant") =>
                expect_operator ("{");
                def decls = collect_list (parse_variant_member);
                expect_operator ("}");
                (attrs, TD_variant (decls))
             
              | _ => Util.ice ()
            };
            
          td.modifiers <- attrs;
          
          td.name <- SS_string (Name (name));
          td.typarms <- typarms;
          td.t_extends <- t_extends;
          
          td
          
        | Tok_keyword ("macro") => 
          def header = parse_fun_header (true, false, false, None ());
          def synt = 
            match (peek_token ()) {
              | Tok_keyword ("syntax") =>
                shift ();
                expect_operator ("(");
                def parse_elems (acc) {
                  match (peek_token ()) {
                    | Tok_operator (")", _) =>
                      shift ();
                      List.Rev (acc)
                    | Tok_operator (",", _) =>
                      shift ();
                      parse_elems (parse_closed_prim_expr () :: acc)
                    | _ =>
                      fatal_error ("expected comma separated expressions in "
                                   + "syntax description")
                  }
                };
                parse_elems ([parse_closed_prim_expr ()])
              | _ => []
            };
          def expr = parse_block ([]);
          TD_macro (attrs, header, synt, expr)
       
        | _ => fatal_error ("expecting type declaration")
      }
    })
  }
  
  parse_topdecl () : Top_decl {
    def tok = get_token ();
    locate (fun () {
      match (tok) {
        | Tok_keyword ("using") =>
          def id = get_qid ();
          expect_operator (";");
          MacroRegistry.LoadSyntaxExtensions (id);
          TD_open (id)
          
        | Tok_keyword ("namespace") =>
          def id = get_qid ();
          match (get_token ()) {
            | Tok_operator ("=", _) =>
              when (id.IndexOf ('.') != -1) {
                Message.error ("namespace alias cannot contain dots")
              };
              def id' = get_qid ();
              expect_operator (";");
              TD_namespace_alias (id, id')
              
            | Tok_operator ("{", _) =>
              push_back ();
              def decls = collect_braced_list (parse_topdecl);
              TD_namespace (id, decls)

            | _ =>
              fatal_error ("expecting '}' or '='")
          }

        | _ =>
          push_back ();
          TD_type (parse_type_decl ())
      }
    })
  }

  parse_quotation () : Expr {
    def tok = get_token ();
    def loc = location ();
    
    E_quoted (loc,
      match (get_token ()) {
        | Tok_operator (":", _) =>
          match (tok) {
            | Tok_keyword ("type") =>
              SyntaxType (parse_type ())

            | Tok_identifier ("ttype") =>
              SyntaxTType (parse_type ())
            
            | Tok_identifier ("pattern") =>
              SyntaxPattern (parse_pattern ())

            | Tok_identifier ("parameter") =>
              SyntaxParm (parse_call_parm ())

            | Tok_identifier ("case") =>
              SyntaxCase (parse_match_case ())

            | Tok_identifier ("caseguard") =>
              SyntaxCaseGuard (parse_case_guard ())

            | Tok_identifier ("fundecl") =>
              def h = parse_fun_header (allow_ctor = false, 
                                        allow_inference = true, 
                                        is_lambda = false, knownname = None ());
              SyntaxFunDecl (Function_decl (h, parse_block (h.parms)))

            | Tok_identifier ("funparm") =>
              SyntaxFunParm (parse_funparm (allow_inference = true))

            | Tok_identifier ("field") =>
              def loc = location ();
              def attrs = get_attrs ();
              SyntaxField (parse_field (loc, attrs))

            | Tok_identifier ("method") =>
              def loc = location ();
              def attrs = get_attrs ();
              SyntaxMethod (parse_method (loc, attrs))
              
            | _ =>
              fatal_error ("bad quotation type")
          }
        | _ =>
          push_back (); 
          push_back ();
          def expr =
            match (parse_expr_sequence ()) {
              | [x] => x
              | l => E_sequence (loc, l)
            };
          SyntaxExpr (expr)
      }
    )
  }
  
  collect_braced_list<'a> (f : void -> 'a) : list <'a> {
    expect_operator ("{");
    def r = collect_list (f);
    expect_operator ("}");
    r
  }
  
  collect_list<'a> (f : void -> 'a) : list <'a> {
    def loop (acc) {
      match (peek_token ()) {
        | Tok_operator ("}", _) | Tok_EOF => List.Rev (acc)
        | _ =>
          loop (f () :: acc)
      }
    };
    loop ([])
  }

  public variant GrammarElement {
    | GE_operator { name : string; }
    | GE_keyword { name : string; }
    | GE_expression
    | GE_block
    | GE_expression_list { sep : string; }
    | GE_parm_list { sep : string; }
    | GE_funparm
    | GE_parm
  }

  parse_wrt_rule (rule : list <GrammarElement>) : list <SyntaxElement> {
    def loop (acc, lst) {
      match (lst) {
        | GE_operator (n) :: xs =>
          expect_operator (n);
          loop (acc, xs)

        | GE_keyword (n) :: xs =>
          expect_keyword (n);
          loop (acc, xs)

        | GE_expression :: xs =>
          def expr = parse_expr ();
          loop (SyntaxExpr (expr) :: acc, xs)

        | GE_block :: xs =>
          def expr = parse_block ([]);
          loop (SyntaxExpr (expr) :: acc, xs)

        | GE_expression_list (sep) :: xs =>
          def exprs = operator_separated_list (sep, parse_expr);
          loop (List.RevAppend (List.Map (exprs, fun (e) { SyntaxExpr (e) }), 
                                 acc), xs)

        | GE_parm_list (sep) :: xs =>
          def exprs = operator_separated_list (sep, parse_call_parm);
          loop (List.RevAppend (List.Map (exprs, fun (e) { SyntaxParm (e) }), 
                                 acc), xs)

        | GE_parm :: xs =>
          def p = parse_call_parm ();
          loop (SyntaxParm (p) :: acc, xs)

        | GE_funparm :: xs =>
          def p = parse_funparm (allow_inference = true);
          loop (SyntaxFunParm (p) :: acc, xs)

        | [] => List.Rev (acc)
      }
    };

    loop ([], rule)
  }

  public make_parsing_function (macro_name : string, rule : list <GrammarElement>, 
                                perm : list <SyntaxElement> -> list <SyntaxElement>) 
                                : void -> Expr 
  {
    fun () {
      def loc = location ();
      def parms = parse_wrt_rule (rule);
      E_macrocall (loc, Name (macro_name), perm (parms))
    }
  }

  parse_list () : list <Expr>
  {
    def parse_list () {
      match (peek_token ()) {
        | Tok_operator ("]", _) => []
        | Tok_operator (",", _) =>
          shift ();
          parse_expr () :: parse_list ()
        | _ =>
          fatal_error ("expecting expression in list literal")
      }
    };
    match (peek_token ()) {
      | Tok_operator ("]", _) => []
      | _ =>
        def expr = parse_expr ();
        expr :: parse_list ()
    }
  }

  init_parens () : void {
    def add (o, c, f) {
      ctx.parens.Add (o, ParenCallback (o, c, f));
      ctx.closing_parens.Add (c, 0);
    };
    add ("<[", "]>", parse_quotation);
    
    add ("[", "]", fun () {
      def loc = location ();
      def make_list (exps : list <Expr>) {
        match (exps) {
          | [] => E_call (loc, E_ref (loc, Name ("Nil")), [])
          | x :: xs => E_call (x.loc, E_ref (x.loc, Name ("Cons")), 
                               [Parm (x), Parm (make_list (xs))])
        }
      };
      make_list (parse_list ())
    });
    
    add ("{", "}", fun () {
      def loc = location ();
      E_sequence (loc, parse_maybe_null_expr_sequence ())
    });
  }

  public parse (lexer : Lexer) : list <Top_decl>
  {
    ctx.lexer <- lexer;
    ctx.last_token1 <- null;
    ctx.last_token2 <- null;
    ctx.push_back <- 0;
    ctx.in_pattern <- false;
    MacroRegistry.RemoveSyntaxExtensions ();
    def r = collect_list (parse_topdecl);
    match (peek_token ()) {
      | Tok_EOF => r
      | _ => fatal_error ("expecting EOF")
    }
  }

} // end module
} // end namespace
