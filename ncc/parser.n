(*
 * Copyright (c) 2003 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *)

open Nemerle.Compiler;
open Nemerle.Collections;
open Nemerle.Compiler.Parsetree;

namespace Nemerle.Compiler {

module Parser {
  class ParenCallback {
    public opening_paren : string;
    public closing_paren : string;
    public parsing_function : CTX -> Expr;
  }

  class KeywordCallback {
    public name : string;
    public parsing_function : CTX -> Expr;
  }

  class CTX {
    public lexer : ILexer;
    public mutable last_token1 : Token; // most recent token
    public mutable last_token2 : Token; // one token before
    public mutable push_back : int; // position in last_token{1,2} or 0
    public mutable in_pattern : bool;
    public parens : Hashtable (string, ParenCallback);
    public closing_parens : Hashtable (string, int);
    public keywords : Hashtable (string, KeywordCallback);
  }

  'a where 'a :> Located 
  opt_locate (ctx : CTX, f : void -> option ('a)) : option ('a) {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    match (ret) {
      | Some (x) => x.loc <- loc
      | None => ()
    };
    ret
  }

  'a where 'a :> Located 
  locate (ctx : CTX, f : void -> 'a) : 'a {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    ret.loc <- loc;
    ret
  }

  get_token (ctx : CTX) : Token {
    match (ctx.push_back) {
      | 1 =>
        ctx.push_back <- 0;
        ctx.last_token1
      | 2 =>
        ctx.push_back <- 1;
        ctx.last_token2
      | _ => 
        ctx.last_token2 <- ctx.last_token1;
        ctx.last_token1 <- ctx.lexer.get_token ();
        ctx.last_token1
    }
  }

  peek_token (ctx : CTX) : Token {
    def tok = get_token (ctx);
    push_back (ctx);
    tok
  }
  
  push_back (ctx : CTX) : void {
    match (ctx.push_back) {
      | 1 => ctx.push_back <- 2
      | 2 => Util.ice ()
      | _ => ctx.push_back <- 1
    }
  }
  
  shift (ctx : CTX) : void {
    ignore (get_token (ctx)) 
  }

  location_here (ctx : CTX) : Location {
    ignore (peek_token (ctx));
    location (ctx)
  }

  location (ctx : CTX) : Location {
    ctx.lexer.get_location ()
  }

  public token_name (t : Token) : string {
    match (t) {
      | Tok_keyword (x) => "keyword `" + x + "'"
      | Tok_identifier (x) => "identifier `" + x + "'"
      | Tok_operator (x, _) => "operator `" + x + "'"
      | Tok_tyvar (x) => "type variable `" + x + "'"
      | Tok_string_literal => "string literal"
      | Tok_number_literal => "number literal"
      | Tok_char_literal => "character literal"
      | Tok_EOF => "end of file"
    }
  }

  describe (ctx : CTX) : string {
    when (ctx.push_back != 2) {
      push_back (ctx)
    };
    def name = token_name (peek_token (ctx));
    "parse error near " + name + ": "
  }

  'a fatal_error (ctx : CTX, msg : string) : 'a {
    Message.fatal_error (location (ctx), describe (ctx) + msg)
  }

  error (ctx : CTX, msg : string) : void {
    Message.error (location (ctx), describe (ctx) + msg)
  }

  get_qid (ctx : CTX) : string {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (".", _) =>
          match (get_token (ctx)) {
            | Tok_identifier (x) => loop (acc + "." + x)
            | _ => fatal_error (ctx, "expecting identifier after dot in qualified ID")
          }
        | _ =>
          push_back (ctx);
          acc
      }
    };

    match (get_token (ctx)) {
      | Tok_identifier (x) =>
        loop (x)
      | _ =>
        fatal_error (ctx, "expecting qualified identifier")
    }
  }
  
  get_id (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_identifier (x) => x
      | _ =>
        fatal_error (ctx, "expecting identifier")
    }
  }
  
  get_id_or_dummy (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_identifier (x) => x
      | Tok_keyword ("_") => "_N_d" + string_of_int (Util.next_id ())
      | _ =>
        fatal_error (ctx, "expecting identifier")
    }
  }
  
  get_splicable_id (ctx : CTX) : Splicable_string {
    def loc = location_here (ctx);
    match (get_token (ctx)) {
      | Tok_identifier (n) => SS_string (loc, n)
      | Tok_operator ("$", _) =>
        match (get_token (ctx)) {
          | Tok_identifier (n) => SS_spliced_expr (loc, E_ref (location (ctx), n))
          | _ => fatal_error (ctx, "expecting identifier after `$' in spliced string")
        }
      | Tok_keyword ("_") => 
        SS_string (loc, "_N_d" + string_of_int (Util.next_id ()))
      | _ => fatal_error (ctx, "expecting identifier")
    }
  }

  get_tyvar (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_tyvar (tv) => tv
      | _ => fatal_error (ctx, "expecting type variable")
    }
  }

  expect_operator (ctx : CTX, op : string) : void {
    match (get_token (ctx)) {
      | Tok_operator (o, _) when op == o => ()
      | Tok_operator (o, _) =>
        match (peek_token (ctx)) {
          | Tok_operator (o', _) when op == o + o' => shift (ctx); ()
          | _ => fatal_error (ctx, "expecting operator `" + op + "'");
        }
      | _ =>
        fatal_error (ctx, "expecting operator `" + op + "'");
    }
  }

  expect_keyword (ctx : CTX, op : string) : void {
    match (get_token (ctx)) {
      | Tok_keyword (o) when op == o => ()
      | t =>
        fatal_error (ctx, "expecting keyword `" + op + "'");
    }
  }

  parse_fun_header (ctx : CTX, 
                    allow_inference : bool, 
                    allow_ctor : bool,
                    is_lambda : bool) : Fun_header 
  {
    def tok = get_token (ctx);
    locate (ctx, fun () {
      def typarms =
        match (tok) {
          | Tok_tyvar =>
            push_back (ctx);
            def tyvars = operator_separated_list (ctx, ",", get_tyvar);
            parse_where_constraints (ctx, tyvars);
          | _ => 
            push_back (ctx); 
            Typarms ([], [])
        };
      mutable is_ctor <- false;
      def name =
        match (get_token (ctx)) {
          | Tok_keyword ("this") when allow_ctor => is_ctor <- true; ".ctor"
          | Tok_keyword ("fun") when is_lambda => "_N_l" + string_of_int (Util.next_id ())
          | _ when is_lambda => fatal_error (ctx, "expecting `fun'")
          | Tok_identifier (n) => n
          | _ => fatal_error (ctx, "expecting function name")
        };
      expect_operator (ctx, "(");
      def parse_parm (_) {
        def id = get_id_or_dummy (ctx);
        def loc = location (ctx);
        def t =
          match (get_token (ctx)) {
            | Tok_operator (":", _) => parse_type (ctx)
            | _ when allow_inference => push_back (ctx); T_infer ()
            | _ => fatal_error (ctx, "expecting typing constraint after parameter name")
          };
        Fun_parm (loc = loc, name = id, ty = t)
      };
      def parms =
        match (peek_token (ctx)) {
          | Tok_operator (")", _) => []
          | _ => operator_separated_list (ctx, ",", parse_parm)
        };
      expect_operator (ctx, ")");
      def ret_type =
        match (get_token (ctx)) {
          | _ when is_ctor => push_back (ctx); T_void ()
          | Tok_operator (":", _) => parse_type (ctx)
          | _ when allow_inference => push_back (ctx); T_infer ()
          | _ => fatal_error (ctx, "expecting typing constraint on function return value")
        };
      Fun_header (name = name,
                  ret_type = ret_type, 
                  parms = parms, 
                  typarms = typarms)
    })
  }

  parse_literal (ctx : CTX) : option (Literal) {
    match (get_token (ctx)) {
      | Tok_keyword ("null") => Some (L_null ())
      | Tok_operator ("(", _) =>
        match (get_token (ctx)) {
          | Tok_operator (")", _) => Some (L_void ())
          | _ => push_back (ctx); push_back (ctx); None ()
        }
      | Tok_string_literal (s) => Some (L_string (s))
      | Tok_number_literal (n) => Some (L_int (n))
      | Tok_char_literal (c) => Some (L_char (c))
      | _ => push_back (ctx); None ()
    }
  }

  parse_closed_prim_expr (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    match (parse_literal (ctx)) {
      | Some (l) => E_literal (loc, l)
      | None =>
        def is_id (tok) { 
          match (tok) { 
            | Tok_identifier => true 
            | _ => false
          }
        };

        def problem () {
          Message.fatal_error (loc, describe (ctx) + "expecting primary expression")
        };
        
        match (get_token (ctx)) {
          | Tok_keyword ("this") => E_this (loc)
          | Tok_keyword ("base") => E_base (loc)
          | Tok_keyword ("typeof") => 
            expect_operator (ctx, "(");
            def type_expr = parse_type (ctx);
            expect_operator (ctx, ")");
            E_typeof (loc, type_expr)
            
          | Tok_identifier (n) => E_ref (loc, n)
          | Tok_operator ("(", _) =>
            def expr = parse_expr (ctx);
            match (get_token (ctx)) {
              | Tok_operator (":>", _) =>
                def t = parse_type (ctx);
                expect_operator (ctx, ")");
                E_type_conversion (loc, expr, t)

              | Tok_operator (":", _) =>
                def t = parse_type (ctx);
                expect_operator (ctx, ")");
                E_type_enforcement (loc, expr, t)

              | Tok_operator (",", _) =>
                def exprs = expr :: operator_separated_list (ctx, ",", parse_expr);
                expect_operator (ctx, ")");
                E_tuple (loc, exprs)
                
              | Tok_operator (")", _) => 
                match (expr) {
                  | E_expr_list => E_tuple (loc, [expr])
                  | _ => expr
                }

              | _ => Message.fatal_error (loc, "unbalanced `('")
            }

          | Tok_operator ("$", _) when is_id (peek_token (ctx)) =>
            match (get_token (ctx)) {
              | Tok_identifier (n) =>
                if (ctx.in_pattern)
                  E_spliced_patt (loc, P_variable (location (ctx), n))
                else
                  E_spliced (loc, E_ref (location (ctx), n))
              | _ => Util.ice ()
            }

          | Tok_operator (o, _) =>
            def parse_paren (p : ParenCallback) {
              def problem () {
                Message.error (loc, "unbalanced `" + p.opening_paren + "'");
                fatal_error (ctx, "expecting `" + p.closing_paren + "' here")
              };
              def expr = p.parsing_function (ctx);
              match (get_token (ctx)) {
                | Tok_operator (o, _) =>
                  if (p.closing_paren == o)
                    expr
                  else
                    match (get_token (ctx)) {
                      | Tok_operator (o', _) when p.closing_paren == o + o' => expr
                      | _ => push_back (ctx); problem ()
                    }
                | _ => problem ()
              } 
            };

            
            match (ctx.parens.Get (o)) {
              | Some (p) => parse_paren (p)
              | None =>
                match (get_token (ctx)) {
                  | Tok_operator (o', _) =>
                    match (ctx.parens.Get (o + o')) {
                      | Some (p) => parse_paren (p)
                      | None => push_back (ctx); problem ()
                    }
                  | _ => push_back (ctx); problem ()
                }
            }
            
          | _ => problem ()
        }
    }
  }

  parse_call_parm (ctx : CTX) : Parm {
    def is_ref = flag_keyword (ctx, "ref");
    def tok = get_token (ctx);
    def name =
      match ((tok, get_token (ctx))) {
        | (Tok_identifier (n), Tok_operator ("=", _)) => n
        | _ => push_back (ctx); push_back (ctx); ""
      };
    Parm (is_ref, parse_expr (ctx), name)
  }
    
  parse_prim_expr (ctx : CTX) : Expr {
    def loop (expr : Expr) {
      match (get_token (ctx)) {
        | Tok_operator ("[", _) =>
          def exprs = operator_separated_list (ctx, ",", parse_expr);
          expect_operator (ctx, "]");
          loop (E_indexer (expr.loc, expr, exprs))
          
        | Tok_operator (".", _) => 
          match (get_token (ctx)) {
            | Tok_operator ("$", _) =>
              def id = get_id (ctx);
              def loc = location (ctx);
              loop (E_member (expr.loc, expr, SS_spliced_expr (loc, E_ref (loc, id))))
            | Tok_identifier (id) =>
              loop (E_member (expr.loc, expr, SS_string (location (ctx), id)))
            | _ =>
              fatal_error (ctx, "expecting field name after dot")
          }
          
        | Tok_operator ("(", _) =>
          def parms =
            match (peek_token (ctx)) {
              | Tok_operator (")", _) => shift (ctx); []
              | _ => 
                def parms = operator_separated_list (ctx, ",", parse_call_parm);
                expect_operator (ctx, ")");
                parms
            };
          loop (E_call (expr.loc, expr, parms))

        | _ => push_back (ctx); expr
      }
    };

    loop (parse_closed_prim_expr (ctx))
  }

  parse_unary_expr (ctx : CTX) : Expr {
    match (peek_token (ctx)) {
      | Tok_operator ("(", _)
      | Tok_operator ("$", _) => parse_prim_expr (ctx)

      | Tok_operator (".", _) =>
        shift (ctx);
        match (get_token (ctx)) {
          | Tok_operator (".", _) => 
            def loc = location (ctx);
            E_expr_list (loc, parse_expr (ctx))
          | _ => fatal_error (ctx, "expecting second dot (in unary expression context)")
        }

      | Tok_operator (o, pri) =>
        def loc = location (ctx);
        def unary () {
          when (pri == 0) {
            fatal_error (ctx, "operator `" + o + "' cannot be used in unary context")
          };
          shift (ctx);
          E_call (loc, E_ref (loc, o), [Parm (parse_unary_expr (ctx))])
        };
        
        if (ctx.parens.Contains (o))
          parse_prim_expr (ctx)
        else {
          shift (ctx);
          def tok = peek_token (ctx);
          push_back (ctx);
          match (tok) {
            | Tok_operator (o', _) =>
              if (ctx.parens.Contains (o + o'))
                parse_prim_expr (ctx)
              else unary ()
            | _ => unary ()
          }
        }
      | _ => parse_prim_expr (ctx)
    }
  }

  parse_pattern (ctx : CTX) : Pattern {
    def loop () {
      def loc = location_here (ctx);
      def pat = parse_closed_pattern (ctx);
      match (peek_token (ctx)) {
        | Tok_operator ("::", _) => 
          shift (ctx); 
          P_list_cons (loc, pat, loop ())
        | _ => pat
      }
    };

    loop ()
  }
  
  parse_closed_pattern (ctx : CTX) : Pattern {
    def loc = location_here (ctx);

    def parse_record () {
      def loop (acc) {
        match (get_token (ctx)) {
          | Tok_operator ("}", _) => List.rev (acc)
          | Tok_identifier (n) =>
            expect_operator (ctx, "=");
            def pat = parse_pattern (ctx);
            def res = Named_pattern (n, pat);
            match (get_token (ctx)) {
              | Tok_operator (";", _) => ()
              | Tok_operator ("}", _) => push_back (ctx)
              | _ => fatal_error (ctx, "found junk after pattern in record")
            };
            loop (res :: acc)
          | _ => fatal_error (ctx, "expecting named pattern")
        }
      };
      
      P_record (loc, loop ([]))
    };

    def tuple_or_record () {
      match (get_token (ctx)) {
        | Tok_operator ("(", _) =>
          def pats = operator_separated_list (ctx, ",", parse_pattern);
          expect_operator (ctx, ")");
          P_tuple (loc, pats)
        | Tok_operator ("{", _) => parse_record ()
        | _ => fatal_error (ctx, "expecting tuple or record pattern")
      }
    };
    
    match (parse_literal (ctx)) {
      | Some (l) => P_literal (loc, l)
      | None =>
        match (get_token (ctx)) {
          | Tok_operator ("$", _) =>
            match (get_token (ctx)) {
              | Tok_identifier (n) =>
                match (peek_token (ctx)) {
                  | Tok_operator ("{", _)
                  | Tok_operator ("(", _) => 
                    P_cons (loc, SS_spliced_expr (loc, E_ref (loc, n)), tuple_or_record ())
                  | Tok_operator ("_", _) => 
                    shift (ctx);
                    P_cons (loc, SS_spliced_expr (loc, E_ref (loc, n)), P_underscore (loc))
                  | _ =>
                    P_spliced (loc, E_ref (loc, n))
                }
              | Tok_operator ("(", _) =>
                def expr = parse_expr (ctx);
                match (peek_token (ctx)) {
                  | Tok_operator (":", _) =>
                    shift(ctx);
                    match (get_token (ctx)) {
                      | Tok_identifier (ty) =>
                        match (ty) {
                          | "var" | "int" | "string" | "bool" | "float" | "char" =>
                            expect_operator (ctx, ")");
                            P_spliced_literal (loc, ty, expr)
                          | _ =>
                            fatal_error (ctx, "wrong splicing type after ':'")
                        }
                      | _ =>
                        fatal_error (ctx, "expecting splicing type (var, int, string...) after ':'")
                    }
                  | _ =>
                    expect_operator (ctx, ")");
                    P_spliced (loc, expr)
                }

              | _ =>
                fatal_error (ctx, "expecting an identifier or `(' after `$' in pattern")
            }
            
          | Tok_operator ("{", _) =>
            parse_record ()

          | Tok_operator (".", _) =>
            match (get_token (ctx)) {
              | Tok_operator (".", _) => P_patt_list (loc, parse_pattern (ctx))
              | _ => fatal_error (ctx, "expecting second dot in pattern context")
            }
            
          | Tok_operator ("(", _) =>
            def pat = parse_pattern (ctx);
            match (get_token (ctx)) {
              | Tok_operator (",", _) =>
                def pats = pat :: operator_separated_list (ctx, ",", parse_pattern);
                expect_operator (ctx, ")");
                P_tuple (loc, pats)
              | Tok_operator (")", _) =>
                match (peek_token (ctx)) {
                  | Tok_keyword ("as") =>
                    shift (ctx);
                    def id = get_splicable_id (ctx);
                    P_as (loc, pat, id)
                    
                  | _ =>
                    P_tuple (loc, [pat])
                }
              | _ =>
                fatal_error (ctx, "expecting `,' or ')' in tuple pattern")
            }

          | Tok_identifier (n) =>
            push_back (ctx);
            def id = get_qid (ctx);
            def subpat =
              match (peek_token (ctx)) {
                | Tok_operator ("{", _)
                | Tok_operator ("(", _) => tuple_or_record ()
                | _ => P_underscore (loc)
              };
            P_cons (loc, SS_string (id), subpat)

          | Tok_keyword ("_") =>
            P_underscore (loc)

          | Tok_operator ("[", _) =>
            def loop (acc) {
              match (get_token (ctx)) {
                | Tok_operator (";", _) =>
                  match (peek_token (ctx)) {
                    | Tok_operator ("]", _) => List.rev (acc)
                    | _ => loop (parse_pattern (ctx) :: acc)
                  }
                | Tok_operator ("]", _) => List.rev (acc)
                | _ => fatal_error (ctx, "expecting pattern in list")
              }
            };

            match (peek_token (ctx)) {
              | Tok_operator ("]", _) => shift (ctx); P_list (loc, [])
              | _ =>
                P_list (loc, loop ([parse_pattern (ctx)]))
            }

          | Tok_operator ("<[", _) =>
            def back = ctx.in_pattern;
            ctx.in_pattern <- true;
            def expr = parse_quotation (ctx);
            expect_operator (ctx, "]>");
            ctx.in_pattern <- back;
            match (expr) {
              | E_quoted (el) => P_quoted (loc, el)
              | _ => Util.ice ("parse_quoted returned sth strange")
            }

          | _ => fatal_error (ctx, "expecting pattern")
        }
    }
  }

  parse_match_case (ctx : CTX) : Match_case {
    def loop2 (acc) {
      def pat = parse_pattern (ctx);
      def res =
        if (flag_keyword (ctx, "when"))
          (pat, Some (parse_expr (ctx)))
        else (pat, None ());
        
      match (get_token (ctx)) {
        | Tok_operator ("=>", _) => List.rev (res :: acc)
        | Tok_operator ("|", _) => loop2 (res :: acc)
        | _ => fatal_error (ctx, "found junk after pattern")
      }
    };

    match (peek_token (ctx)) {
      | Tok_operator ("|", _) => shift (ctx)
      | _ => ()
    };

    def pats = loop2 ([]);
    def loc' = location_here (ctx);
    def expr =
      match (parse_expr_sequence (ctx)) {
        | [x] => x
        | l => E_sequence (loc', l)
      };

    Match_case (pats, expr)
  }
  
  parse_semiclosed_expr (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    def tok = get_token (ctx);
    //Message.debug ("pse " + token_name (tok));
    match (tok) {
      | Tok_keyword (k) when ctx.keywords.Contains (k) =>
        def k = Option.unsome (ctx.keywords.Get (k));
        k.parsing_function (ctx)
        
      | Tok_keyword ("match") =>
        expect_operator (ctx, "(");
        def expr = parse_expr (ctx);
        expect_operator (ctx, ")");
        match (get_token (ctx)) {
          | Tok_operator ("{", _) =>
            match (peek_token (ctx)) {
              | Tok_operator (".", _) =>
                shift (ctx);
                match (get_token (ctx)) {
                  | Tok_operator (".", _) => 
                    def res = 
                      E_match (loc, expr, [Match_case ([], E_expr_list (loc, parse_expr (ctx)))]);
                    expect_operator (ctx, "}");
                    res
                  | _ => fatal_error (ctx, "expecting second dot in match context")
                }
              | _ =>
                push_back (ctx);
                def cases = collect_braced_list (ctx, parse_match_case);
                E_match (loc, expr, cases)
            }
          | _ =>
            fatal_error (ctx, "expecting '{' after 'match (e)'")
        }
      | Tok_keyword ("raise") =>
        E_raise (loc, parse_expr (ctx))

      | Tok_keyword ("try") =>
        def body = parse_expr (ctx);
        match (get_token (ctx)) {
          | Tok_keyword ("with") =>
            def id = get_splicable_id (ctx);
            expect_operator (ctx, ":");
            def t = parse_type (ctx);
            expect_operator (ctx, "=>");
            def handler = parse_expr (ctx);
            E_try_with (body, id, t, handler)

          | Tok_keyword ("finally") =>
            def handler = parse_expr (ctx);
            E_try_finally (loc, body, handler)

          | _ => fatal_error (ctx, "expecting `with' or `finally'")
        }

      | Tok_keyword ("mkarray") =>
        match (parse_prim_expr (ctx)) {
          | E_list (exprs) => E_mkarray (loc, exprs)
          | _ => fatal_error (ctx, "expected [ ... ] after `mkarray'")
        }

      | Tok_keyword ("fun") 
      | Tok_tyvar (_) =>
        push_back (ctx);
        def h = parse_fun_header (ctx, allow_ctor = false,
                                       allow_inference = true, 
                                       is_lambda = true);
        def expr = parse_block (ctx);
        E_lambda (loc, Function_decl (h, expr))

      | Tok_keyword ("mutable") =>
        def id = get_splicable_id (ctx);
        expect_operator (ctx, "<-");
        E_let (loc, true, id, parse_expr (ctx))

      | Tok_keyword ("def") =>
        def parse_val () {
          def id = get_splicable_id (ctx);
          expect_operator (ctx, "=");
          E_let (loc, false, id, parse_expr (ctx))
        };

        def parse_funs (acc) {
          def h = parse_fun_header (ctx, allow_ctor = false, 
                                         allow_inference = true, 
                                         is_lambda = false);
          def fd = Function_decl (h, parse_block (ctx));
          match (peek_token (ctx)) {
            | Tok_keyword ("and") =>
              shift (ctx);
              parse_funs (fd :: acc)
            | _ => E_letfun (loc, List.rev (fd :: acc))
          }
        };
        
        match (peek_token (ctx)) {
          | Tok_operator ("(", _) =>
            def pat = parse_pattern (ctx);
            expect_operator (ctx, "=");
            def expr = parse_expr (ctx);
            E_letpat (loc, pat, expr)

          | Tok_tyvar => parse_funs ([])
          
          | Tok_identifier (n) =>
            shift (ctx);
            match (peek_token (ctx)) {
              | Tok_operator ("(", _) => 
                push_back (ctx);
                parse_funs ([])
                
              | Tok_operator ("=", _) =>
                push_back (ctx);
                parse_val ()
              
              | _ => fatal_error (ctx, "expecting binding after `def'")
            }

          | Tok_operator ("$", _) 
          | Tok_keyword ("_") => parse_val ()

          | _ => fatal_error (ctx, "expecting binding after `def'")
        }
      
      | _ => push_back (ctx); parse_unary_expr (ctx)
    }
  }

  parse_expr (ctx : CTX) : Expr {
    def is_paren (s) {
      ctx.parens.Contains (s) || ctx.closing_parens.Contains (s)
    };

    def make_bin (loc, op, e1, e2) {
      match (op) {
        | "<-" =>
          E_assign (loc, e1, e2)
        | "::" =>
          E_list_cons (loc, e1, e2)
        | _ =>
          E_call (loc, E_ref (loc, op), [Parm (e1); Parm (e2)])
      }
    };
    
    def parse_pri (pri) : Expr {
      //Message.debug ("pp " + string_of_int (pri));
      def loop_left (expr) {
        def loc = location_here (ctx);
        match (get_token (ctx)) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            def expr' = parse_pri (pri - 1);
            loop_left (make_bin (loc, s, expr, expr'))
          | tok => 
            //Message.debug ("miss " + string_of_int (pri) + " " + token_name (tok));
            push_back (ctx); 
            expr
        }
      };

      def loop_right () {
        def loc = location_here (ctx);
        def expr = parse_pri (pri - 1);
        match (get_token (ctx)) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            make_bin (loc, s, expr, loop_right ())
          | _ => push_back (ctx); expr
        }
      };
     
      match (pri) {
        | 0 => parse_semiclosed_expr (ctx)
        | 1 | 8 => loop_right ()
        | _ => loop_left (parse_pri (pri - 1))
      }
    };

    parse_pri (9)
  }

  parse_expr_sequence (ctx : CTX) : list (Expr) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (";", _) =>
          match (peek_token (ctx)) {
            | Tok_operator ("}", _) 
            | Tok_operator ("|", _) 
            | Tok_operator ("]", _) 
              => List.rev (acc)
            | _ => loop (parse_expr (ctx) :: acc)
          }
        | Tok_operator ("}", _) 
        | Tok_operator ("|", _) 
        | Tok_operator ("]", _) 
          => push_back (ctx); List.rev (acc)
        | _ => fatal_error (ctx, "expecting expression in sequence")
      }
    };

    loop ([parse_expr (ctx)])
  }

  parse_maybe_null_expr_sequence (ctx : CTX) : list (Expr) {
    match (peek_token (ctx)) {
      | Tok_operator ("}", _) 
      | Tok_operator ("]", _) => []
      | _ => parse_expr_sequence (ctx)
    }
  }

  parse_block (ctx : CTX) : Expr {
    expect_operator (ctx, "{");
    match (peek_token (ctx)) {
      | Tok_operator ("}", _) => shift (ctx); E_sequence (location (ctx), [])
      | _ => 
        def loc = location (ctx);
        def r = E_sequence (loc, parse_expr_sequence (ctx));
        expect_operator (ctx, "}");
        r
    }
  }
  
  parse_type_member (ctx : CTX) : Class_member {
    def loc = location_here (ctx);
    def attrs = get_attrs (ctx);

    def parse_extern () {
      match (get_token (ctx)) {
        | Tok_keyword ("extern") =>
          match (get_token (ctx)) {
            | Tok_string_literal (s) => 
              expect_operator (ctx, ";");
              s
            | _ => fatal_error (ctx, "found some junk after extern (expecting string)")
          }
        | _ => fatal_error (ctx, "found some junk after `=' (expecting extern)")
      }
    };

    def parse_fun (h : Fun_header) {
      def impl =
        match (get_token (ctx)) {
          | Tok_keyword ("implements") when h.name != ".ctor" =>
            operator_separated_list (ctx, ",", get_qid)
          | _ => push_back (ctx); []
        };
      def body =
        match (peek_token (ctx)) {
          | Tok_operator ("=", _) =>
            shift (ctx);
            FB_extern (parse_extern ())
          | Tok_operator ("{", _) =>
            FB_parsed_expr (parse_block (ctx))
          | _ => fatal_error (ctx, "expecting method body")
        };
      
      M_function (header = h, 
                  name = h.name, 
                  modifiers = attrs, 
                  loc = loc, 
                  body = body, 
                  kind = if (h.name == ".ctor") FK_ctor () else FK_method (impl))
    };
    
    def parse_field (is_ref, name) {
      expect_operator (ctx, ":");
      def t = parse_type (ctx);
      def valkind = 
        match (get_token (ctx)) {
          | Tok_operator (";", _) => Val_normal ()
          | Tok_operator ("=", _) => Val_extern (parse_extern ())
          | _ => fatal_error (ctx, "found some junk after field")
        };
      
      M_field (loc = loc,
               name = name, 
               modifiers = attrs, 
               ty = t, 
               is_ref = is_ref, 
               kind = valkind);
    };

    match (get_token (ctx)) {
      | Tok_tyvar =>
        push_back (ctx);
        def h = parse_fun_header (ctx, 
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false);
        parse_fun (h)
        
      | Tok_keyword ("mutable") =>
        match (get_token (ctx)) {
          | Tok_identifier (name) => parse_field (true, name)
          | _ => fatal_error (ctx, "expecting field name")
        }
        
      | Tok_identifier (name) =>
        match (peek_token (ctx)) {
          | Tok_operator ("(", _) => 
            push_back (ctx);
            def h = parse_fun_header (ctx, 
                                      allow_ctor = false, 
                                      allow_inference = false,
                                      is_lambda = false);
            parse_fun (h)
          | _ => parse_field (false, name)
        }
        
      | Tok_keyword ("this") =>
        push_back (ctx);
        def h = parse_fun_header (ctx, 
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false);
        parse_fun (h)

      | _ =>
        push_back (ctx);
        def td = parse_type_decl (ctx);
        td.modifiers <- List.append (td.modifiers, attrs);
        M_type (loc = loc, 
                name = td.name, 
                modifiers = td.modifiers, 
                td = td)
    }
  }
  
  parse_type (ctx : CTX) : Type {
    def prim_type () {
      def get_args () {
        match (get_token (ctx)) {
          | Tok_operator ("(", _) =>
            def args = operator_separated_list (ctx, ",", parse_type);
            expect_operator (ctx, ")");
            args
          | _ =>
            push_back (ctx);
            []
        }
      };
      match (get_token (ctx)) {
          | Tok_operator ("$", _) =>
            def loc = location (ctx);
            match (get_token (ctx)) {
              | Tok_identifier (id) =>
                match (peek_token (ctx)) {
                  | Tok_operator ("(", _) =>
                    T_app (SS_spliced_expr (loc, E_ref (loc, id)), get_args ())
                  | _ =>
                    T_spliced (E_ref (loc, id))
                }
                
              | Tok_operator ("(", _) =>
                def expr = parse_expr (ctx);
                match (peek_token (ctx)) {
                  | Tok_operator (":", _) =>
                    shift(ctx);
                    match (get_token (ctx)) {
                      | Tok_identifier (ty) =>
                        match (ty) {
                          | "var" =>
                            expect_operator (ctx, ")");
                            T_spliced_special (ty, expr)
                          | _ =>
                            fatal_error (ctx, "wrong splicing type after ':'")
                        }
                      | _ =>
                        fatal_error (ctx, "expecting splicing type (var) after ':'")
                    }
                  | _ =>
                    expect_operator (ctx, ")");
                    T_spliced (expr)
                }

              | _ =>
                fatal_error (ctx, "expecting an identifier or `(' after `$' in type")
            }

        | Tok_operator (".", _) =>
          match (get_token (ctx)) {
            | Tok_operator (".", _) => T_type_list (prod_type ())
            | _ => fatal_error (ctx, "expecting second dot")
          }

        | Tok_identifier =>
          push_back (ctx);
          def id = get_qid (ctx);
          def loc = location (ctx);
          T_app (SS_string (loc, id), get_args ())

        | Tok_keyword ("array") => T_array (prim_type ())
        
        | Tok_keyword ("ref") => T_ref (prim_type ())
        
        | Tok_keyword ("out") => T_out (prim_type ())

        | Tok_keyword ("void") => T_void ()

        | Tok_tyvar (tv) => T_var (tv)

        | Tok_operator ("(", _) =>
          def t = parse_type (ctx);
          expect_operator (ctx, ")");
          t

        | _ =>
          fatal_error (ctx, "expecting type expression")
      }
    }

    and prod_type () {
      def loop (acc) {
        match (get_token (ctx)) {
          | Tok_operator ("*", _) =>
            loop (prim_type () :: acc)
          | _ => 
            push_back (ctx);
            match (acc) {
              | [x] => x
              | acc => T_prod (List.rev (acc))
            }
        }
      };

      loop ([prim_type ()])
    };

    def fun_type () {
      def t = prod_type ();
      match (get_token (ctx)) {
        | Tok_operator ("->", _) =>
          T_fun (t, fun_type ())
        | _ => 
          push_back (ctx);
          t
      }
    };

    fun_type ()
  }

  get_attrs (ctx : CTX) : list (Modifier) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_keyword ("new") => loop (Mod_new () :: acc)
        | Tok_keyword ("public") => loop (Mod_public () :: acc)
        | Tok_keyword ("protected") => loop (Mod_protected () :: acc)
        | Tok_keyword ("internal") => loop (Mod_internal () :: acc)
        | Tok_keyword ("private") => loop (Mod_private () :: acc)
        | Tok_keyword ("abstract") => loop (Mod_abstract () :: acc)
        | Tok_keyword ("sealed") => loop (Mod_sealed () :: acc)
        | Tok_keyword ("static") => loop (Mod_static () :: acc)
        | Tok_keyword ("virtual") => loop (Mod_virtual () :: acc)
        | _ =>
          push_back (ctx);
          List.rev (acc)
      }
    };
    loop ([])
  }
  
  'a operator_separated_list (ctx : CTX, op : string, f : CTX -> 'a) : list ('a) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (o, _) when o == op => loop (f (ctx) :: acc)
        | _ => push_back (ctx); List.rev (acc)
      }
    };

    loop ([f (ctx)])
  }
  
  parse_tyvars (ctx : CTX) : list (string) {
    operator_separated_list (ctx, ",", get_tyvar)
  }

  parse_where_constraints (ctx : CTX, tyvars : list (string)) : Typarms {
    def constraints =
      if (flag_keyword (ctx, "where")) {
        def parse_constraint (_) {
          def tv = get_tyvar (ctx);
          expect_operator (ctx, ":>");
          def t = parse_type (ctx);
          Constraint (tv, t)
        };
        operator_separated_list (ctx, ",", parse_constraint)
      } else [];
    Typarms (tyvars, constraints)
  }

  flag_keyword (ctx : CTX, kw : string) : bool {
    match (get_token (ctx)) {
      | Tok_keyword (n) when n == kw => true
      | _ => push_back (ctx); false
    }
  }
  
  parse_type_decl (ctx : CTX) : Type_decl {
    def parse_header () {
      match (get_token (ctx)) {
        | Tok_identifier (name) =>
          def typarms =
            match (get_token (ctx)) {
              | Tok_operator ("(", _) =>
                def tyvars = parse_tyvars (ctx);
                expect_operator (ctx, ")");
                parse_where_constraints (ctx, tyvars);
              | _ => 
                push_back (ctx); 
                Typarms ([], [])
            };
            
          def t_extends =
            match (get_token (ctx)) {
              | Tok_keyword ("extends") =>
                Some (parse_type (ctx))
              | _ => 
                push_back (ctx); 
                None ()
            };
            
          def t_implements =
            match (get_token (ctx)) {
              | Tok_keyword ("implements") =>
                operator_separated_list (ctx, ",", parse_type)
              | _ => 
                push_back (ctx); 
                []
            };
          
          (name, typarms, t_extends, t_implements)

        | _ => fatal_error (ctx, "expecting type name")
      }
    };
    
    def parse_variant_member (ctx) {
      def tok = get_token (ctx);
      locate (ctx, fun () {
        match (tok) {
          | Tok_operator ("|", _) =>
            def id = get_id (ctx);
            def members =
              match (peek_token (ctx)) {
                | Tok_operator ("{", _) =>
                  def parse_field (ctx) {
                    ignore (peek_token (ctx));
                    locate (ctx, fun () {
                      def attrs = get_attrs (ctx);
                      def is_ref = flag_keyword (ctx, "mutable");
                      def id = get_id (ctx);
                      expect_operator (ctx, ":");
                      def ty = parse_type (ctx);
                      expect_operator (ctx, ";");
                      M_field (name = id,
                               modifiers = attrs,
                               ty = ty, 
                               is_ref = is_ref, 
                               kind = Val_normal ())
                    })
                  };
                  collect_braced_list (ctx, parse_field)
                | _ => []
              };
            TD_variant_option (name = id, 
                               modifiers = [], 
                               t_extends = None (),
                               t_implements = [],
                               typarms = Typarms ([], []),
                               decls = members)
          | _ => fatal_error (ctx, "expecting variant option")
        }
      })
    };
    
    def parse_iface_member (ctx) {
      ignore (peek_token (ctx));
      locate (ctx, fun () {
        def is_new = flag_keyword (ctx, "new");
        def h = parse_fun_header (ctx, allow_ctor = false, allow_inference = false, is_lambda = false);
        expect_operator (ctx, ";");
        M_function (name = h.name, 
                    modifiers = [], 
                    header = h, 
                    kind = FK_iface_method (is_new), 
                    body = FB_abstract ())
      })
    };
    
    def parse_members () {
      collect_braced_list (ctx, parse_type_member)
    };
  
    def attrs = get_attrs (ctx);
    def tok = get_token (ctx);
    locate (ctx, fun () {
      match (tok) {
        | Tok_keyword ("type")
        | Tok_keyword ("class")
        | Tok_keyword ("struct")
        | Tok_keyword ("module")
        | Tok_keyword ("interface")
        | Tok_keyword ("variant") =>
          def (name, typarms, t_extends, t_implements) = parse_header ();
          def (attrs, td) =
            match (tok) {
              | Tok_keyword ("class") =>
                (attrs, TD_class (parse_members ()))
              | Tok_keyword ("struct") =>
                (Mod_struct () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("module") =>
                (Mod_module () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("type") =>
                expect_operator (ctx, "=");
                match (get_token (ctx)) {
                  | Tok_keyword ("extern") =>
                    match (get_token (ctx)) {
                      | Tok_string_literal (s) => 
                        expect_operator (ctx, ";");
                        (attrs, TD_external (s))
                      | _ => 
                        fatal_error (ctx, "expecting quoted type name after `extern'")
                    }
                    
                  | _ =>
                    push_back (ctx);
                    def t = parse_type (ctx);
                    expect_operator (ctx, ";");
                    (attrs, TD_alias (t))
                }
                
              | Tok_keyword ("interface") =>
                def decls = collect_braced_list (ctx, parse_iface_member);
                (attrs, TD_interface (decls))
                
              | Tok_keyword ("variant") =>
                expect_operator (ctx, "{");
                def decls = collect_list (ctx, parse_variant_member);
                expect_operator (ctx, "}");
                (attrs, TD_variant (decls))
             
              | _ => Util.ice ()
            };
            
          td.modifiers <- attrs;
          
          td.name <- name;
          td.typarms <- typarms;
          td.t_extends <- t_extends;
          td.t_implements <- t_implements;

          td
          
        | Tok_keyword ("macro") => Util.ice () // FIXME
        
        | _ => fatal_error (ctx, "expecting type declaration")
      }
    })
  }

  parse_topdecl (ctx : CTX) : Top_decl {
    def tok = get_token (ctx);
    locate (ctx, fun () {
      match (tok) {
        | Tok_keyword ("open") =>
          def id = get_qid (ctx);
          expect_operator (ctx, ";");
          TD_open (id)
          
        | Tok_keyword ("namespace") =>
          def id = get_qid (ctx);
          match (get_token (ctx)) {
            | Tok_operator ("=", _) =>
              when (id.IndexOf ('.') != -1) {
                Message.error ("namespace alias cannot contain dots")
              };
              def id' = get_qid (ctx);
              expect_operator (ctx, ";");
              TD_namespace_alias (id, id')
              
            | Tok_operator ("{", _) =>
              push_back (ctx);
              def decls = collect_braced_list (ctx, parse_topdecl);
              TD_namespace (id, decls)

            | _ =>
              fatal_error (ctx, "expecting '}' or '='")
          }

        | _ =>
          push_back (ctx);
          TD_type (parse_type_decl (ctx))
      }
    })
  }

  parse_quotation (ctx : CTX) : Expr {
    def tok = get_token (ctx);
    def loc = location (ctx);
    
    E_quoted (loc,
      match (get_token (ctx)) {
        | Tok_operator (":", _) =>
          match (tok) {
            | Tok_keyword ("type") =>
              ParseType (parse_type (ctx))
            
            | Tok_identifier ("pattern") =>
              ParsePattern (parse_pattern (ctx))

            | Tok_identifier ("parameter") =>
              ParseParam (parse_call_parm (ctx))

            | Tok_identifier ("case") =>
              ParseCase (parse_match_case (ctx))

            | _ =>
              fatal_error (ctx, "bad quotation type")
          }
        | _ =>
          push_back (ctx); 
          push_back (ctx);
          ParseExpr (parse_expr (ctx))
      }
    )
  }
  
  parse_spliced (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    def expr = if (ctx.in_pattern)
      E_spliced_patt (loc, parse_pattern (ctx))
    else
      E_spliced (loc, parse_expr (ctx));

    match (peek_token (ctx)) {
      | Tok_operator (":", _) =>
        shift(ctx);
        match (get_token (ctx)) {
          | Tok_identifier (ty) =>
            match (ty) {
              | "var" | "int" | "string" | "bool" | "float" | "char" | "typed" =>
                match (expr) {
                  | E_spliced_patt => E_spliced_literal (loc, ty, expr)
                  | E_spliced (e) => E_spliced_literal (loc, ty, e)
                  | _ => Util.ice ("not possible")
                }
              | _ =>
                fatal_error (ctx, "wrong splicing type after ':'")
            }
          | _ =>
            fatal_error (ctx, "expecting splicing type (var, int, string...) after ':'")
        }
      | _ =>
        expr
    }
  }

  'a collect_braced_list (ctx : CTX, f : CTX -> 'a) : list ('a) {
    expect_operator (ctx, "{");
    def r = collect_list (ctx, f);
    expect_operator (ctx, "}");
    r
  }
  
  'a collect_list (ctx : CTX, f : CTX -> 'a) : list ('a) {
    def loop (acc) {
      match (peek_token (ctx)) {
        | Tok_operator ("}", _) | Tok_EOF => List.rev (acc)
        | _ =>
          loop (f (ctx) :: acc)
      }
    };
    loop ([])
  }

  variant GrammarElement {
    | GE_operator { name : string; }
    | GE_keyword { name : string; }
    | GE_expression
    | GE_block
    | GE_expression_list { sep : string; }
    | GE_parm_list { sep : string; }
  }

  parse_wrt_rule (ctx : CTX, rule : list (GrammarElement)) : list (Parm) {
    def loc = location (ctx);
    
    def loop (acc, lst) {
      match (lst) {
        | GE_operator (n) :: xs =>
          expect_operator (ctx, n);
          loop (acc, xs)

        | GE_keyword (n) :: xs =>
          expect_keyword (ctx, n);
          loop (acc, xs)

        | GE_expression :: xs =>
          def expr = parse_expr (ctx);
          loop (Parm (expr) :: acc, xs)

        | GE_block :: xs =>
          def expr = parse_block (ctx);
          loop (Parm (expr) :: acc, xs)

        | GE_expression_list (sep) :: xs =>
          def exprs = operator_separated_list (ctx, sep, parse_expr);
          loop (List.rev_append (List.map (fun (e) { Parm (e) }, exprs), acc), xs)

        | GE_parm_list (sep) :: xs =>
          def exprs = operator_separated_list (ctx, sep, parse_call_parm);
          loop (List.rev_append (exprs, acc), xs)

        | [] => List.rev (acc)
      }
    };

    loop ([], rule)
  }

  make_parsing_function (macro_name : string, rule : list (GrammarElement)) : CTX -> Expr {
    fun (ctx) {
      def loc = location (ctx);
      def parms = parse_wrt_rule (ctx, rule);
//      Message.debug ("calling macro " + macro_name + " with " + string_of_int (List.length (parms)) + " parms");
      E_call (loc, E_ref (loc, macro_name), parms)
    }
  }


  init_parens (ctx : CTX) : void {
    def add (o, c, f) {
      ctx.parens.Add (o, ParenCallback (o, c, f));
      ctx.closing_parens.Add (c, 0);
    };
    add ("<[", "]>", parse_quotation);
    add ("$(", ")", parse_spliced);
    
    add ("[", "]", fun (ctx) {
      def loc = location (ctx);
      E_list (loc, parse_maybe_null_expr_sequence (ctx))
    });
    
    add ("{", "}", fun (ctx) {
      def loc = location (ctx);
      E_sequence (loc, parse_maybe_null_expr_sequence (ctx))
    });
  }

  init_keywords (ctx : CTX) : void {
    def add_macro (name, rule) {
      ctx.keywords.Add (name, KeywordCallback (name, make_parsing_function ("_N_" + name, rule)))
    };

    def while_rule = [GE_operator ("("); GE_expression (); GE_operator (")");
                        GE_expression ()];

    add_macro ("while", while_rule);
    add_macro ("when", while_rule);
    add_macro ("unless", while_rule);
    
    add_macro ("using", [GE_operator ("(");
                           GE_parm_list (",");
                         GE_operator (")");
                         GE_expression ()]);

    add_macro ("for", [GE_operator ("(");
                         GE_expression (); GE_operator (";");
                         GE_expression (); GE_operator (";");
                         GE_expression (); GE_operator (")");
                       GE_expression ()]);
                       
    add_macro ("if", [GE_operator ("("); GE_expression (); GE_operator (")");
                         GE_expression (); 
                      GE_keyword ("else");
                         GE_expression ()]);
  }

  public parse (lexer : ILexer) : list (Top_decl) {
    def ctx = CTX (lexer = lexer,
                   last_token1 = null, 
                   last_token2 = null, 
                   push_back = 0,
                   in_pattern = false,
                   keywords = Hashtable (),
                   parens = Hashtable (),
                   closing_parens = Hashtable ());
    init_parens (ctx);
    init_keywords (ctx);
    def r = collect_list (ctx, parse_topdecl);
    match (peek_token (ctx)) {
      | Tok_EOF => r
      | _ => fatal_error (ctx, "expecting EOF")
    }
  }

} // end module
} // end namespace
