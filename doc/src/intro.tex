\documentclass[draft,11pt]{article}
\usepackage[latin2]{inputenc}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{hcolor}
\usepackage{color}
\usepackage[a4paper, margin=3cm]{geometry}

\newcommand{\net}[0]{{\tt .NET}}
\newcommand{\netf}[0]{{\tt .NET} framework}
\newcommand{\nem}[0]{Nemerle}
\newcommand{\cs}[0]{C\#}
\newcommand{\oo}[0]{object-oriented}
\newcommand{\kw}[1]{{\tt \bf #1}}

\DefineVerbatimEnvironment
  {Code}{Verbatim}
  {frame=lines,numbers=left,xleftmargin=15mm,%
   xrightmargin=10mm,framesep=2mm,framerule=1mm,%
   rulecolor=\color[rgb]{0.8,0.8,0.8}}

\begin{document}

\title{{\Huge {\sc Nemerle}} \\ (Not) Yet Another Functional \net\ Language}
\author{{ Micha³ Moskal} \\ {\small University of Wroc³aw}}
\date{\today}

\maketitle

\begin{abstract}
We present \nem, a new functional language designed from the ground up
for the \net. We focus on new features absent from its parents: ML
and \cs.  In particular we describe variant inheritance, assertions and
code-generating macros.  We also give some concern for the syntax and
``spirit'' of \nem\ that makes it good transition language for programmers
with \cs\ background.
\end{abstract}

\pagestyle{fancy}
\lhead{\sc Micha³ Moskal -- \it Nemerle}
\rhead{\thepage}
\cfoot{}

\section{Reasons}

We want statically typed, functional language with nice \net\
interoperability.  While the need for the functional language is clearly
a matter of taste, putting the language in the \netf\ is a well thought
decision. \netf\ (especially now when it has generics) provides quite
good platform for high-level language implementation:

\begin{itemize}
\item automatic garbage collection
\item rich class library in the core system
\item lots of additional third party libraries
\item code generator (JIT) for free
\item development tools support
\item and so on...
\end{itemize}

Having this all for free is quite appalling. However there is some cost --
the framework is heavily \oo\ and primary targeted at the traditional \oo\
and imperative languages.  Therefore ports of the existing functional
languages to the \net\ do not fit is as well, as for example \cs.

So we need it. But when we are at it, we can think about some other thing.
We are going to make the language less ``pure'' then say Haskell or SML. 
Which means that imperative and \oo\ features are easily available. So maybe
we can make it advantage, make \nem\ good transition language for people
previously using C-like imperative and \oo\ languages. They can use imperative
features until they gradually learn how to program in functional fashion.

Easy access to imperative constructs is only one thing needed in such
a transition language. Probably the hardest thing about learning ML is
understanding compiler error messages about typing mismatches. This may
seem odd at the first glance, but this is the reality -- type inference
is very nice when it works, but when it fails, you are stuck with error
messages hundred lines from place of the real error. 

So maybe avoid constructions that produce typing errors in ML, but
syntax errors in other languages (for example function application being
just $\epsilon$).  Maybe make the typing more explicit, at least for
global functions.  It is going to be needed anyway, as we want to have
good support for overloading.

Finally we thought about our \oo\ system. While existing \oo\ extensions
to functional languages are appalling mainly because of their elegance,
they do not fit with the \netf\ at all. Therefore it is easiest to make our
\oo\ system simply mirror \net\ one.

It is important to mention that the language is still evolving and quite flexible.
Especially assertions and macros are relatively new features. We are open
to any suggestions.

There was one more reason -- designing programming languages is a lot of fun 
:-) Let put these pieces together and see how it works!

\section{Overview}

At the high level \nem\ can be characterized as a combination of \cs\
at the class level and ML at the expression level. However the syntax
of ML fragment is less ambiguous and more C- then Algol-like at the
lexical layer. The result is expression-oriented language pretending to
be \cs.

Of course we also need datatypes and functional values. But these can be
thought of as extensions to what the programmer already knows.

There are some other facts about \nem\ that are implied by the 
``not-so-ML-like \net\ language'' paradigm:

\begin{itemize}
\item Language is statically typed, but dynamic cast are available
      and can be used when needed.
\item Language combines functional, \oo, and imperative features.
\item Object system is one-to-one mapping of CLR one. So it should
      be fairly easy to understand.
\item Language interoperates nicely with other \net\ languages -- it
      is both CLS consumer and producer.
\end{itemize}

In the following sections we will show how the language looks like and
how is it different from ML and \cs. Reader is assumed to have some
basic knowledge about both ML and \cs.

\section{The language}

Top-level program structure reassembles \cs. There are namespaces, then classes
and finally methods. We also have modules (classes with all members static) and
variants (datatypes in SML, sum types in Caml). Let's look at the famous example:

\begin{Code}
class Hello {
  public static Main () : void {
    System.Console.WriteLine ("Hello cruel world.");
  }
}
\end{Code}

Another way to write it would be:

\begin{Code}
open System.Console;

module Hello {
  public Main () : void {
    WriteLine ("Hello cruel world.");
  }
}
\end{Code}

Basic building block of methods is sequence. Sequence groups local definitions
(using \kw{def} keyword), expressions computed for side effects and the final
expression returned as the value of entire sequence.

\begin{Code}
public static factorial (x : int) : int {
  def loop (acc : int, x : int) : int {
    if (x <= 1) 
      acc
    else 
      loop (acc * x, x - 1)
  }
  loop (1, x)
}
\end{Code}

As you see both global and local functions are explicitly typed. This
is limitation of current implementation. We plan to lift it, at least
for local functions.

\subsection{Variants and pattern matching}

Variants are compiled to subclassing and should be thought of as subtypes.
For example:

\begin{Code}
variant list ('a) {
  | Cons { hd : 'a; tl : list ('a); }
  | Nil
}
\end{Code}

Is compiled to:

\begin{Code}
class list<A> {}
class Cons<A> : list<A> { A hd; list<A> tl; }
class Nil<A> : list<A> {}
\end{Code}

But of course we can use regular ML-like matching:

\begin{Code}
'a head (l : list ('a)) : 'a {
  match (l) {
    | Cons (x, _) => x
    | Nil => raise Invalid_argument ("List.head")
  }
}
\end{Code}

The \verb|'a| in front of \verb|head| quantifies following occurrences of
\verb|'a|.

There is one tricky thing about 3rd line of our example. It could have
been written in any of the following ways:

\begin{Code}
  | Cons (x, _) => x
  | Cons c => c.hd
  | Cons { hd = x; } => x
  | Cons { hd = x; tl = _; } => x
\end{Code}

In fact when compiler sees tuple pattern and expects record pattern,
then tuple is transformed into the record. It is therefore not as painful
to require variant members to be named.

It is also possible to have deep patterns like \verb,Foo (Bar (Baz)),
or match real tuples.

\subsection{Variant inheritance}

The subtyping model allow variants to carry slightly more
information then their ML counterparts. In particular it is possible to
make the variant base class have some fields, methods or even derive
from some other class.  This way all variant options can have some
common part. Example (taken from \nem\ compiler, that is written in
\nem\ itself):

\begin{Code}
class Located {
  file : string;
  line : int;
}

variant Expr extends Located {
  | E_call { fn : Expr; parms : list (Expr); }
  | E_ref { name : string; }
}

public static dump (e : Expr) : void {
  print ("// " + e.file + ": " + e.line.ToString ());
  match (e) {
    | E_ref r => print (r.name)
    | E_call c =>
      dump (c.fn);
      List.iter (dump, c.parms)
  }
}
\end{Code}

\subsection{Constrained parametric types}

Types can be parametrized over other types. Type arguments can be
constrained. This is the same as generics in IL. It is also possible to 
parametrize methods.

\begin{Code}
variant tree ('a) where 'a :> IComparable ('a) {
  | Node { 
      left : tree ('a); 
      data : tree ('a); 
      right : tree ('a); 
    }
  | Tip
}
\end{Code}

This is the \nem\ way to do things that would have been done with
functors in ML-like languages. It isn't strictly as powerful, but seems
good enough in practice.

\section{Assertions}

\nem\ has several different kinds of assertions. The simplest one is much like
regular \verb,assert,\ call known from C or OCaml. It comes in two flavors:

\begin{itemize}
\item \kw{require}\ that can come anywhere within a block
\item \kw{ensure}\ that need to come at the end of a block and can
use \kw{value}\ keyword to refer to the value of given block
\end{itemize}

\begin{Code}
public static factorial (x : int) : int {
  require { x >= 1 }
  
  def loop (acc : int, x : int) : int {
    require { x >= 1 }
    if (x <= 1) 
      acc
    else 
      loop (acc * x, x - 1)
  }
  
  loop (1, x)
  ensure { value >= x;
           x >= 3 == (value % 3 == 0) }
}
\end{Code}

\subsection{Assertions for mutables}

As we have a good support for mutable values, we also have special
assertions for mutables to express invariants. These also come in two
flavors:

\begin{itemize}
\item mutable values \kw{guarded}\ with assertions -- update of this very 
      value triggers associated assertion
\item \kw{guard} assertions that are checked after update of any value 
      directly referenced from the assertion body; checks are performed 
      until the end of the current block
\end{itemize}

It is possible to attach \kw{guard}\ assertions to local values, instance
fields, and static fields (global values).

It is to be reconsidered when exactly we check assertions. Enforcing
check after each update can be hard in presence of parameters passed
by \kw{ref}.

\section{Macros}

Macros in \nem\ have much more to do with Meta Haskell, CamlP4 or Lisp
code-generating macros, then with macros in languages like C. Macros are
essentially compiler plugins -- pieces of \nem\ code that takes type or
expression abstract syntax trees (AST) and return some other expressions
or types (also as AST).

Plugins are by definition Turing-complete\footnote{It's not by accident
like in some other languages :-)}. Plugins can access external files,
can extract typing information from running database or do whatever else
you can imagine.

Macros are executed at the compile time. Code they generate is later
statically typechecked. Macros are thus safe. There is always risk that
macro will crash (or loop) during the compilation, but there is no way
to avoid that while retaining their expressive power.

As said before plugins are written in Nemerle itself. In principle it 
would be possible to use any other \net\ language, but \nem\ provides special
syntax to construct and walk its own AST. This special syntax can be
in fact implemented as a plugin, at some later time.

Example uses of macros:

\begin{itemize}
\item embedding special purpose sublanguages in \nem:
\begin{itemize}
\item binding results of SQL queries to source language variables in type safe way
\item \verb,printf,\ and \verb,scanf,\ like functions
\item \verb,$,-interpolation like in Bourne shell or Perl
\item binding named groups in regular expression to source language variables
\item special syntax for XPath or some other XML-matching constructions
\end{itemize}

\item generation of AST from external files
\begin{itemize}
\item Yacc and Burg-like tools
\item generating types from XML schema or DTD
\end{itemize}

\item generation of external files based on AST

\item generation of AST based on other AST
\begin{itemize}
\item automatic XML serialization method generation
\item specialization at the source language level
\end{itemize}
\end{itemize}

\end{document}
