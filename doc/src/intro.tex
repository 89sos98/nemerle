\documentclass[draft,11pt]{article}
\usepackage[latin2]{inputenc}
\usepackage{fancyvrb}
\usepackage{fancyhdr}
\usepackage{hcolor}
\usepackage{color}
\usepackage[a4paper, margin=3cm]{geometry}

\newcommand{\net}[0]{{\tt .NET}}
\newcommand{\netf}[0]{{\tt .NET} framework}
\newcommand{\nem}[0]{Nemerle}
\newcommand{\cs}[0]{C\#}
\newcommand{\oo}[0]{object-oriented}
\newcommand{\kw}[1]{{\tt \bf #1}}

\DefineVerbatimEnvironment
  {Code}{Verbatim}
  {frame=lines,numbers=left,xleftmargin=15mm,%
   xrightmargin=10mm,framesep=2mm,framerule=1mm,%
   rulecolor=\color[rgb]{0.8,0.8,0.8}}

\begin{document}

\title{{\Huge \sc Nemerle} \\ 
  Introduction to a Functional \net\ Language \\
  {\large \tt http://nemerle.org/}}
\author{Micha³ Moskal, Pawe³ W. Olszta, Kamil Skalski \\
{\tt \{michal.moskal,pawel.olszta,kamil.skalski\}@nemerle.org} \\
{\small University of Wroc³aw}}
\date{\today}

\maketitle

\thispagestyle{empty}

\begin{abstract}
  \nem\ is a new functional language designed from the ground up for the \net.
  We have focused on features absent in traditional ML-like and \oo\ languages:
  variant inheritance, powerful assertions and code-generating macros. We also 
  gave some concern for the syntax and the ``spirit'' of \nem\ that makes it a good
  transition language for programmers with \cs\ background.
\end{abstract}

\pagestyle{fancy}
\lhead{Moskal, Olszta, Skalski -- \it Nemerle}
\rhead{\thepage}
\cfoot{}


\section{Motivation}

Our objective was to create a statically typed functional language with well 
founded \net~\cite{CLI}\ interoperability. The \net\ environment, especially 
since the introduction of generics~\cite{Generics}, provides an excellent 
platform for high-level language implementation which:

\begin{itemize}
  \item comes with a rich class library in the core system
  \item gives access to vast cache of additional third party libraries
  \item provides automatic garbage collection and security features
  \item handles native code generation and low-level optimizations (JIT)
  \item guarantees portability of executables
  \item allows integration with existing development tools
  \item etc. etc.
\end{itemize}

Of course, the framework is heavily \oo\ and primarily focused on traditional
\oo\ and imperative languages. Therefore ports of the existing functional 
languages to the \net\ did not fit in as well, as for example, \cs~\cite{CS}
does. Addressing this issue was the main idea behind the design of \nem.

In comparison to Haskell~\cite{Haskell} or SML~\cite{SML}, \nem\ is not a pure 
language in the functional sense, allowing the programmer to create completely 
\oo\ and imperative programs. This makes \nem\ a good transition language for 
people with C-like imperative and \oo\ languages background. They can take 
advantage of the language's imperative features until they gradually learn 
how to program in the functional fashion.

Easy access to imperative constructs is only one of the requirements needed 
in such a transition language. Probably the hardest thing about learning ML 
is understanding the compiler error messages about typing mismatches. This 
may seem odd at the first glance, but this is the reality -- type inference
is very nice when it works, but when it fails, you are stuck with error
messages hundred lines from place of the real error. 

We have decided to avoid language constructions that produce typing errors in ML, 
while generating syntax errors in other languages (for example function application 
being just $\epsilon$); requiring the typing to be explicit, at least for global 
functions -- implicit typing is not really possible to achieve when aiming for
a good support for methods overloading.

It seems easy to observe that it is the quality of the design of the \oo\ system 
to determine usability of a programming language. While the existing \oo\ extensions 
to functional languages are appealing because of their elegance, they do not fit 
the \netf\ at all. We have decided to make our \oo\ system simply mirror 
the \net\ design.

Let's put these pieces together and see how it works!


\section{Overview}

At the high level \nem\ can be characterized as a combination of \cs\
at the class level and a ML-like language at the expression level. 
However the syntax of the ML fragment is much less ambiguous and 
more C-like than Algol-like. The result is an expression-oriented 
language with a feeling of \cs.

Of course we also need variants\footnote{Called datatypes in SML,
and sometimes sum types in Caml.}, pattern matching and functional
values. These can be thought of as extensions to the base 
\cs-like language.

There are some other facts about \nem\ that are implied by the 
``not-so-ML-like \net\ language'' paradigm:

\begin{itemize}
  \item The language is statically typed, but dynamic cast are available
        and can be used when needed.
  \item The language combines functional, \oo, and imperative features.
  \item The object system is a one-to-one mapping of CLR's -- making it
        fairly easy to understand.
  \item The language fully interoperates with other \net\ languages -- it
        is both a CLS consumer and producer.
\end{itemize}

In the following sections we will show how the language looks like and
how is it different from ML and \cs. Reader is assumed to have some
basic knowledge about both ML and \cs.

It is important to mention that the language is still evolving and that
its design is quite flexible. Especially the assertions and macros are 
relatively new features. We are open to any suggestions.


\section{The language}

Top-level program structure reassembles \cs. There are namespaces,
then classes and finally methods. We also have modules (classes with all
members static and public) and variants. Let us look at the famous example:

\begin{Code}
  class Hello {
    public static Main () : void {
      System.Console.WriteLine ("Hello world, " +
                       "my name is not Jan B.!");
    }
  }
\end{Code}

Another way to write it could be:

\begin{Code}
  using System.Console;

  module Hello {
    public Main () : void {
      WriteLine ("Hello cruel world.");
    }
  }
\end{Code}

The basic building block of a method is a sequence. A sequence groups local
definitions (specified with the \kw{def} keyword), expressions computed for
their side effects and the final expression returned as the value of entire
sequence\footnote{We put here value bindings and side-effect expressions
into one can. This is exactly how it works in imperative languages and 
(under the hood) in eager functional languages. It models real world
behavior better, and should be easier to understand.}.

\begin{Code}
public static factorial (x : int) : int {
  def loop (acc, x) {
    if (x <= 1) 
      acc
    else 
      loop (acc * x, x - 1)
  };
  loop (1, x)
}
\end{Code}

In this example the local function is implicitly typed -- its type is
inferred automatically by the compiler. Global functions are explicitly
typed by design of the language.


\subsection{Mutable values}

Mutable local values are defined using declarations like 
\kw{mutable}\ $x$\ {\tt <-}\ $expression${\tt ;}. The value $x$ can be 
later used as a value bound with \kw{def} without any explicit dereference 
operator\footnote{Like the {\tt !} operator in ML.}, but can only be 
assigned using the assignment operator ({\tt <-}).

\begin{Code}
public static factorial (x : int) : int {
  mutable acc <- 1;
  mutable k <- n;
  while (k > 0) {
    acc <- acc * k;
    k <- k - 1;
  };
  acc
}
\end{Code}

The \kw{while} loop should be considered just different form of tail
recursion. It is in fact implemented as a macro which generates the
following code:

\begin{Code}
public static factorial (x : int) : int {
  mutable acc <- 1;
  mutable k <- n;
  def loop () {
    if (k > 0) {
      acc <- acc * k;
      k <- k - 1;
      loop ()
    } else ()
  };
  loop ();
  acc
}
\end{Code}

The \kw{mutable} keyword can be also used as a modifier on fields. The contents
of such fields can be modified using the same assignment operator.


\subsection{Variants and pattern matching}

Variants are compiled to subclassing and should be thought of as subtypes.
For example:

\begin{Code}
variant BinaryTree ('a) {
  | Leaf { val : 'a; }
  | Node { left : BinaryTree ('a); 
	   val : 'a; 
	   right : BinaryTree ('a); }
} 
\end{Code}

Would be compiled to:

\begin{Code}
class BinaryTree<A> {}
class Node<A> : BinaryTree<A> { 
  BinaryTree<A> left; 
  A val; 
  BinaryTree<A> right; 
}
class Leaf<A> : BinaryTree<A> {}
\end{Code}

However in absence of of generics support in the current Framework release
type qualifiers are stored as attributes alongside the type declarations.

Of course we can use regular ML-like matching over variants:

\begin{Code}
'a count (t : BinaryTree ('a)) : int {
  match (t) {
    | Node (l, _, r) => count (l) + 1 + count (r)
    | Leaf => 1
  }
}
\end{Code}

Which can be shortened to:

\begin{Code}
'a count (t : BinaryTree ('a)) : int {
  | Node (l, _, r) => count (l) + 1 + count (r)
  | Leaf => 1
}
\end{Code}

The \verb|'a| in front of \verb|head| quantifies following occurrences of
\verb|'a|.

There is one tricky thing about the second line of our example. It could have
been written in any of the following ways:

\begin{Code}
  | (Node) as n => count (n.left) + 1 + count (n.right)
  | Node (l, _, r) => count (l) + 1 + count (r)
  | Node { left = l; right = r } => count (l) + 1 + count (r)
  | Node { left = l; val = _; right = r } => count (l) + 1 + count (r)
\end{Code}

In fact when the compiler sees a tuple pattern and expects a record pattern,
the tuple is transformed into a record. It is therefore not as painful
to require variant members to be named.

It is also possible to have deep patterns like \verb,Foo (Bar (Baz)),
to match constants and to match real tuples.


\subsection{Variant inheritance}

The subtyping model allows the variants to carry slightly more
information then their ML counterparts. In particular it is possible to
make the variant base class have some fields, methods or even derive
from some other class.  This way all variant options can have some
common part. Example (taken from \nem\ compiler, which is written in
\nem\ itself):

\begin{Code}
class Located {
  file : string;
  line : int;
}

variant Expr extends Located {
  | E_call { fn : Expr; parms : list (Expr); }
  | E_ref { name : string; }
}

public static dump (e : Expr) : void {
  print ("// " + e.file + ": " + e.line.ToString ());
  match (e) {
    | E_ref (name) => print (name)
    | E_call (fn, parms) =>
      dump (fn);
      List.iter (dump, parms)
  }
}
\end{Code}


\subsection{Constrained parametric types}

Types can be parametrized over other types. Type arguments can be
constrained. This works the same way as generics do in IL. It is also 
possible to parametrize methods.

\begin{Code}
variant tree ('a) where 'a :> IComparable ('a) {
  | Node { 
      left : tree ('a); 
      data : 'a; 
      right : tree ('a); 
    }
  | Tip
}
\end{Code}

This is the \nem\ way to do things that would have been done with
functors in ML-like languages. It is not strictly as powerful, but 
seems to be good enough in practice and it integrates well with 
the \netf.


\section{Assertions}

\nem\ has several different kinds of assertions. The simplest one is much like
regular \verb,assert,\ call known from C or OCaml. It comes in two flavors:

\begin{itemize}
  \item \kw{require}\ that can come anywhere within a block
  \item \kw{ensure}\ that need to come at the end of a block and can
    use \kw{value}\ keyword to refer to the value of given block
\end{itemize}

\begin{Code}
public static factorial (x : int) : int {
  require { x >= 1 };
  
  def loop (acc : int, x : int) {
    require { x >= 1 }
    if (x <= 1) 
      acc
    else 
      loop (acc * x, x - 1)
  };
  
  loop (1, x);
  ensure { value >= x;
           x >= 3 == (value % 3 == 0) }
}
\end{Code}


\subsection{Assertions for mutables}

As we have a good support for mutable values, we also have special
assertions for mutables to express invariants. These also come in two
flavors:

\begin{itemize}
  \item mutable values \kw{guarded}\ with assertions -- update of this very 
        value triggers associated assertion
  \item \kw{guard} assertions that are checked after update of any value 
        directly referenced from the assertion body; checks are performed 
        until the end of the current block
\end{itemize}

It is possible to attach the \kw{guard}\ assertions to local values, instance
fields, and static fields (global values).

We sometimes want assertions like \verb,x + y == 5, to hold, with mutable
\verb,x, and \verb,y,. To allow update of \verb,x, immediately followed
by update of \verb,y, \kw{transaction} block is introduced. Assertions to
be triggered during the \kw{transaction} block are stacked, and executed
when control leaves it.

It is to be reconsidered when exactly we check assertions. Enforcing
check after each update can be hard in presence of parameters passed
by \kw{ref}.


\section{Macros}

Macros in \nem\ have much more to do with Meta Haskell~\cite{MetaHaskell}, 
CamlP4~\cite{CamlP4} or Scheme Lisp code-generating macros, than with macros 
in languages like C. Macros are essentially compiler plugins -- pieces 
of \nem\ code that take type or expression abstract syntax trees (AST) 
and return some other expressions or types (also as AST).

Macros are by definition Turing-complete\footnote{It is not by accident
like in some other languages :-)}. Macros can access external files,
can extract typing information from a running database and generally
do whatever you can imagine.

Macros are executed at the compilation time. The code they generate is later
statically type checked. Macros are thus safe. There is always risk that
macro will crash (or loop) during the compilation, but there is no way
to avoid that while retaining its expressiveness.

As said before macros are written in Nemerle itself. In principle it 
would be possible to use any other \net\ language, but \nem\ provides special
code quotation syntax to construct and walk its own AST. It provides clear
separation of meta-language from object language it is describing.

Macros can be also executed at the run time, taking advantage of dynamic
aspects of the \netf. This can be used for example to develop programming
language interpreters, or to specialize code for efficiency.

Our meta-system is closely interleaved with compilation process. 
It can perform guided by user partial typing of program's AST. Compiler's 
internal typing procedures are executed by macro's code in arbitrary order
and their result can be analyzed giving much more information about program.

\subsection{Usage}

Example uses of macros:

\begin{itemize}
  \item extending syntax of language
  \item embedding special purpose sublanguages in \nem:
  \begin{itemize}
    \item \verb,printf,\ and \verb,scanf,\ like functions
    \item binding optional and named groups in regular expression to local 
          variables
    \item \verb,$,-interpolation like in Bourne shell or Perl   %$
    \item binding results of SQL queries to local variables in type safe way
    \item special syntax for XPath or some other XML-matching constructions
  \end{itemize}

  \item generation of AST from external files
  \begin{itemize}
    \item Yacc and Burg-like tools
    \item generating types from XML schema or DTD
  \end{itemize}

  \item generation of external files based on AST
  \begin{itemize}
    \item pretty printing generated or original code
  \end{itemize}

  \item generation of AST based on other AST
  \begin{itemize}
    \item generating XML serialization methods
    \item specialization of code at the source language level
    \item support for Aspects-Oriented Programming by adding 
          cross-cutting ``concerns'' to program in algorithmic
          and arbitrarily flexible way   
  \end{itemize}
\end{itemize}

\subsection{Example: regular expression macro}

\begin{Code}
regexp match (s) {
  | "a*.+" => printf ("a\n");
  | @"(?<num : int>\d+)-\w+" => printf ("%d\n", num + 3);
  | "(?<name>(Ala|Kasia))? ma kota" =>
    match (name) {
      | None => printf ("noname?\n")
      | Some (n) => printf ("%s\n", n)
    }
  | _ => printf ("default\n");
}
\end{Code}

\noindent is transformed into following code:

\begin{Code}
def gen1 = System.Text.RegularExpressions.Regex (
  "(?<gen2>^a*.+$)|(?<gen3>^(?<num>\d+)-\w+$)|" + 
  "(?<gen4>^(?<name>(Ala|Kasia))? ma kota$)", 
  System.Text.RegularExpressions.RegexOptions.ExplicitCapture);
def gen5 = gen1.Match (s);
if (gen5.Success)
  if (gen5.Groups[1].Success) 
    printf ("a\n")
  else if (gen5.Groups[2]) {
    def num = System.Int32.Parse (gen5.Groups[3].ToString ());
    printf ("%d\n", num + 3)
  }
  else if (gen5.Groups[4].Success) {
    def name = 
      if (gen5.Groups[5].Success) Some (gen5.Groups[5].ToString ())
      else None ();
    match (name) {
      | None => printf ("noname?\n")
      | Some (n) => printf ("%s\n", n)
    }
  }
  else raise Match_failure ()
else
  printf ("default\n");
\end{Code}


\subsection{Example: SQL queries macro}

This macro requires an SQL parser, and access to database we are working on,
so that the types of table columns and stored functions can be determined. 
It is needed to determine types of SQL expressions, which can be later used
to produce source language bindings for values returned by SQL queries.

\begin{Code}
  sql_loop (conn, "SELECT salary, LOWER (name) AS lname"
                  "  FROM employees"
                  "  WHERE salary > $(min_salary * 3)")
    sql_print ("$lname : $salary\n")
\end{Code}

And the result:

\begin{Code}
  def cmd = SqlCommand ("SELECT salary, LOWER (name)"
                        "  FROM employees"
                        "  WHERE salary > @parm1", conn);
  cmd.Parameters.Add ("@parm1", min_salary * 3);
  def r = cmd.ExecuteReader ();
  while (r.Read ()) {
    def salary = r.GetInt32 (0);
    def lname = r.GetString (1);
    sql_print ("$lname : $salary\n")
  }
\end{Code}

In fact in the 9th line of output we see another extension, that is translated to:

\begin{Code}
  System.Console.Write (lname.ToString ());
  System.Console.Write (" : ");
  System.Console.Write (salary.ToString ());
  System.Console.Write ("\n")
\end{Code}


\subsection{Example: A sample macro implementation}

This is a sample implementation of a macro that adds \cs -like
\verb,foreach, loop to language (together with special syntax
for this construct). 
This code comes directly from the compiler implementation 
(consult the file \verb,extensions.n,).

\begin{Code}
  macro @foreach (iter : funparm, collection, body) 
  syntax ("foreach", "(", iter, "in", collection, ")", body)
  {
    match (iter) {
      | <[ funparm: $(iname : var) : $ty ]> =>
        <[ def enumerator = $collection.GetEnumerator ();
           while (enumerator.NextMove ()) {
             mutable $(iname : var) <- (enumerator.Current : $ty);
             $body;
           }
        ]>        
      | _ =>
        Message.fatal_error ("iterator in foreach must be identifier" + 
                             "with optional type")
    }
  }
\end{Code}

The code generated by the presented macro is constructed by 
the quotation construct in lines 6--13. Note that it creates code,
which uses another syntax-extending macro, the \verb,while, loop.

\section{Code generation}

The typed abstract syntax tree of expressions is converted into 
an intermediate functional description of a stack machine which
is later used to build the compiler output using the 
\verb,System.Reflection.Emit, API. 

Optimizations are performed on different level. Semantic optimizations
are executed on the typed AST, while low level optimizations (like tail
call elimination, inlining or matching automata generation) are performed
on the functional stack machine code level.


\subsection{Tail call elimination}

We have implemented tail calls using the \verb,tail., prefix available in IL.
However it did not bring any improvements to the execution speed, it even slowed
things down by a factor of 15\%.

For tail calls to the current function, we have implemented simple
transformation to argument assignment and goto. It brought little speed improvement (over
version without tail calls), but reduced memory usage by about 20\% (compared to the same version). 


\subsection{Matching optimizations}

We are working on good matching code generation using hashing function
and binary search automates. This is however in very early stage.


\section{Summary}

We have shown the key points of a new functional language for the \netf.
The language combines well-known concepts in a unique fashion. We believe 
that it could be used to teach the basics of functional programming and 
the \net. We also hope it can be used outside academia as a real life, 
industry language.

\newcommand{\bibent}[3]{\bibitem{#1} #2: {\it #3}.}
\newcommand{\bibweb}[2]{\bibitem{#1} {\tt #2}}

\begin{thebibliography}{9}
\bibent{Generics}{Andrew Kennedy, Don Syme}{Design and Implementation of Generics for 
the .NET Common Language Runtime}
\bibent{SML}{Robin Milner, Mads Tofte, Robert Harper}{The Definition of Standard ML}
\bibent{Haskell}{Simon Peyton Jones, John Hughes}{Report on the Programming Language Haskell 98}
\bibent{MetaHaskell}{Tim Sheard, Simon Peyton Jones}{Template metaprogramming for Haskell}
\bibent{CS}{International Organization for Standardization}{C\# Language Specification,
ISO/IEC 23270:2003}
\bibent{CLI}{International Organization for Standardization}{Common Language Infrastructure,
ISO/IEC 23271:2003}
\bibweb{CamlP4}{http://caml.inria.fr/camlp4/}
\end{thebibliography}

\end{document}
