(*
 * Copyright (c) 2003 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *)

open Nemerle.Compiler;
open Nemerle.Collections;
open Nemerle.Compiler.Parsetree;

namespace Nemerle.Compiler {

module Parser {
  class ParenCallback {
    public opening_paren : string;
    public closing_paren : string;
    public parsing_function : CTX -> Expr;
  }

  public class KeywordCallback {
    public name : string;
    public parsing_function : CTX -> Expr;
  }

  public class CTX {
    public mutable lexer : ILexer;
    public mutable last_token1 : Token; // most recent token
    public mutable last_token2 : Token; // one token before
    public mutable push_back : int; // position in last_token{1,2} or 0
    public mutable in_pattern : bool;
    public parens : Hashtable (string, ParenCallback);
    public closing_parens : Hashtable (string, int);
    public keywords : Hashtable (string, KeywordCallback);
  }

  'a where 'a :> Located 
  opt_locate (ctx : CTX, f : void -> option ('a)) : option ('a) {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    match (ret) {
      | Some (x) => x.loc <- loc
      | None => ()
    };
    ret
  }

  (** executes given function and returns its result enriched
      by location at the beginning of parsing *)
  'a where 'a :> Located 
  locate (ctx : CTX, f : void -> 'a) : 'a {
    def loc = ctx.lexer.get_location ();
    def ret = Util.locate (loc, f);
    ret.loc <- loc;
    ret
  }

  get_token (ctx : CTX) : Token {
    match (ctx.push_back) {
      | 1 =>
        ctx.push_back <- 0;
        ctx.last_token1
      | 2 =>
        ctx.push_back <- 1;
        ctx.last_token2
      | _ =>
        def get_token () {
          try
            ctx.lexer.get_token ()
          with { e : Lexer.Error =>
            Message.error ("lexing problem: " + e.name);
            get_token ()
          }
        };
        ctx.last_token2 <- ctx.last_token1;
        ctx.last_token1 <- get_token ();
        ctx.last_token1
    }
  }

  peek_token (ctx : CTX) : Token {
    def tok = get_token (ctx);
    push_back (ctx);
    tok
  }
  
  push_back (ctx : CTX) : void {
    match (ctx.push_back) {
      | 1 => ctx.push_back <- 2
      | 2 => Util.ice ()
      | _ => ctx.push_back <- 1
    }
  }
  
  shift (ctx : CTX) : void {
    ignore (get_token (ctx)) 
  }

  location_here (ctx : CTX) : Location {
    ignore (peek_token (ctx));
    location (ctx)
  }

  location (ctx : CTX) : Location {
    ctx.lexer.get_location ()
  }

  public token_name (t : Token) : string {
    match (t) {
      | Tok_keyword (x) => "keyword `" + x + "'"
      | Tok_identifier (x) => "identifier `" + x + "'"
      | Tok_operator (x, _) => "operator `" + x + "'"
      | Tok_tyvar (x) => "type variable `" + x + "'"
      | Tok_string_literal => "string literal"
      | Tok_number_literal => "number literal"
      | Tok_char_literal => "character literal"
      | Tok_EOF => "end of file"
    }
  }

  describe (ctx : CTX) : string {
    when (ctx.push_back != 2) {
      push_back (ctx)
    };
    def name = token_name (peek_token (ctx));
    "parse error near " + name + ": "
  }

  'a fatal_error (ctx : CTX, msg : string) : 'a {
    Message.fatal_error (location (ctx), describe (ctx) + msg)
  }

  error (ctx : CTX, msg : string) : void {
    Message.error (location (ctx), describe (ctx) + msg)
  }

  get_qid (ctx : CTX) : string {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (".", _) =>
          match (get_token (ctx)) {
            | Tok_identifier (x) => loop (acc + "." + x)
            | _ => fatal_error (ctx, "expecting identifier after dot in qualified ID")
          }
        | _ =>
          push_back (ctx);
          acc
      }
    };

    match (get_token (ctx)) {
      | Tok_identifier (x) =>
        loop (x)
      | _ =>
        fatal_error (ctx, "expecting qualified identifier")
    }
  }
  
  get_id (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_identifier (x) => x
      | _ =>
        fatal_error (ctx, "expecting identifier")
    }
  }
  
  get_id_or_dummy (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_identifier (x) => x
      | Tok_keyword ("_") => Util.tmpname ("u")
      | _ =>
        fatal_error (ctx, "expecting identifier")
    }
  }
  
  get_splicable_id (ctx : CTX) : Splicable_string {
    def loc = location_here (ctx);
    match (get_token (ctx)) {
      | Tok_identifier (n) => SS_string (loc, n)
      | Tok_operator ("$", _) =>
        match (get_token (ctx)) {
          | Tok_identifier (id) =>
            SS_spliced_expr (loc, E_ref (location (ctx), id))
          | Tok_operator ("(", _) =>
            def expr = parse_expr (ctx);
            match (peek_token (ctx)) {
              | Tok_operator (":", _) =>
                shift(ctx);
                match (get_token (ctx)) {
                  | Tok_identifier (ty) =>
                    match (ty) {
                      | "var" | "int" | "string" | "bool" | "float" 
                      | "char" =>
                        expect_operator (ctx, ")");
                        SS_spliced_expr (loc, E_spliced_special (ty, expr))
                      | _ =>
                        fatal_error (ctx, "wrong splicing type after ':'")
                    }
                  | _ =>
                    fatal_error (ctx, "expecting splicing type (var) after ':'")
                }
              | _ =>
                expect_operator (ctx, ")");
                SS_spliced_expr (loc, expr)
            }
          | _ =>
            fatal_error (ctx, "expecting identifier or '(' after '$'")
        }
      | Tok_keyword ("_") => 
        SS_string (loc, Util.tmpname ("u"))
      | _ => fatal_error (ctx, "expecting identifier")
    }
  }

  get_tyvar (ctx : CTX) : string {
    match (get_token (ctx)) {
      | Tok_tyvar (tv) => tv
      | _ => fatal_error (ctx, "expecting type variable")
    }
  }

  expect_operator (ctx : CTX, op : string) : void {
    match (get_token (ctx)) {
      | Tok_operator (o, _) when op == o => ()
      | Tok_operator (o, _) =>
        match (peek_token (ctx)) {
          | Tok_operator (o', _) when op == o + o' => shift (ctx); ()
          | _ => fatal_error (ctx, "expecting operator `" + op + "'");
        }
      | _ =>
        fatal_error (ctx, "expecting operator `" + op + "'");
    }
  }

  expect_keyword (ctx : CTX, op : string) : void {
    match (get_token (ctx)) {
      | Tok_keyword (o) when op == o => ()
      | _ =>
        fatal_error (ctx, "expecting keyword `" + op + "'");
    }
  }

  flag_keyword (ctx : CTX, kw : string) : bool {
    match (get_token (ctx)) {
      | Tok_keyword (n) when n == kw => true
      | _ => push_back (ctx); false
    }
  }

  parse_funparm (ctx : CTX, allow_inference : bool) : Fun_parm {
    def is_params = 
      match (peek_token (ctx)) {
        | Tok_keyword ("params") => shift (ctx); true
        | _ => false
      };
    def id = get_splicable_id (ctx);
    def loc = location (ctx);
    def t =
      match (get_token (ctx)) {
        | Tok_operator (":", _) => parse_type (ctx)
        | _ when allow_inference => push_back (ctx); T_infer ()
        | _ => fatal_error (ctx, "expecting typing constraint after parameter name")
      };
    def defl = 
      match (peek_token (ctx)) {
        | Tok_operator ("=", _) => 
          shift (ctx); 
          if (is_params) 
            fatal_error (ctx, "variable number of arguments and default value")
          else
            FP_default (parse_expr (ctx))
        | _ => if (is_params) FP_params () else FP_normal ()
      };
    Fun_parm (loc = loc, name = id, ty = t, att = defl)
  }

  (** eats exactly header with [name], [(parameters)] and inferencable [: type] *)
  parse_fun_header (ctx : CTX, 
                    allow_inference : bool, 
                    allow_ctor : bool,
                    is_lambda : bool, knownname : option (Splicable_string)) : Fun_header
  {
    locate (ctx, fun () {
      mutable is_ctor <- false;
      def (typarms, name) = 
        match (knownname) {
          | None =>
            def tparms =
              match (peek_token (ctx)) {
                | Tok_tyvar =>
                  def tyvars = operator_separated_list (ctx, ",", get_tyvar);
                  parse_where_constraints (ctx, tyvars);
                | _ => 
                  Typarms ([], [])
              };
            def nam =
              match (peek_token (ctx)) {
                | Tok_keyword ("this") when allow_ctor => 
                  shift (ctx);
                  is_ctor <- true; SS_string (".ctor")
                | Tok_keyword ("fun") when is_lambda => shift (ctx); SS_string ("")
                | _ when is_lambda => fatal_error (ctx, "expecting `fun'")
                | Tok_identifier  
                | Tok_operator ("$", _) => get_splicable_id (ctx)
                | _ => fatal_error (ctx, "expecting function name")
              };
            (tparms, nam)
          | Some (n) => (Typarms ([], []), n)
        };
      expect_operator (ctx, "(");
      def parse_parm (_) { parse_funparm (ctx, allow_inference) };
      def parms =
        match (peek_token (ctx)) {
          | Tok_operator (")", _) => []
          | Tok_operator (".", _) =>
            shift (ctx);
            expect_operator (ctx, ".");
            def loc = location (ctx);
            [Fun_parm (loc, SS_string (""), <[ type: void ]>, FP_default (parse_expr (ctx)))]
          | _ => operator_separated_list (ctx, ",", parse_parm)
        };
      expect_operator (ctx, ")");
      def ret_type =
        match (get_token (ctx)) {
          | _ when is_ctor => push_back (ctx); T_void ()
          | Tok_operator (":", _) => parse_type (ctx)
          | _ when allow_inference => push_back (ctx); T_infer ()
          | _ => fatal_error (ctx, "expecting typing constraint on function return value")
        };
      Fun_header (name = name,
                  ret_type = ret_type, 
                  parms = parms, 
                  typarms = typarms)
    })
  }

  parse_literal (ctx : CTX) : option (Literal) {
    match (get_token (ctx)) {
      | Tok_keyword ("null") => Some (L_null ())
      | Tok_keyword ("true") => Some (L_bool (true))        
      | Tok_keyword ("false") => Some (L_bool (false))
      | Tok_operator ("(", _) =>
        match (get_token (ctx)) {
          | Tok_operator (")", _) => Some (L_void ())
          | _ => push_back (ctx); push_back (ctx); None ()
        }
      | Tok_string_literal (s) => Some (L_string (s))
      | Tok_number_literal (n) => Some (L_int (n))
      | Tok_char_literal (c) => Some (L_char (c))
      | _ => push_back (ctx); None ()
    }
  }

  parse_closed_prim_expr (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    match (parse_literal (ctx)) {
      | Some (l) => E_literal (loc, l)
      | None =>
        def is_id (tok) { 
          match (tok) { 
            | Tok_identifier => true 
            | _ => false
          }
        };

        def problem () {
          Message.fatal_error (loc, describe (ctx) + "expecting primary expression")
        };
        
        match (get_token (ctx)) {
          | Tok_keyword ("this") => E_this (loc)
          | Tok_keyword ("base") => E_base (loc)
          | Tok_keyword ("typeof") => 
            expect_operator (ctx, "(");
            def type_expr = parse_type (ctx);
            expect_operator (ctx, ")");
            E_typeof (loc, type_expr)
            
          | Tok_identifier (n) => E_ref (loc, n)
          | Tok_operator ("(", _) =>
            def expr = parse_expr (ctx);
            match (get_token (ctx)) {
              | Tok_operator (":>", _) =>
                def t = parse_type (ctx);
                expect_operator (ctx, ")");
                E_type_conversion (loc, expr, t)

              | Tok_operator (":", _) =>
                def t = parse_type (ctx);
                expect_operator (ctx, ")");
                E_type_enforcement (loc, expr, t)

              | Tok_operator (",", _) =>
                def exprs = expr :: operator_separated_list (ctx, ",", parse_expr);
                expect_operator (ctx, ")");
                E_tuple (loc, exprs)
                
              | Tok_operator (")", _) => 
                match (expr) {
                  | E_expr_list => E_tuple (loc, [expr])
                  | _ => expr
                }

              | _ => Message.fatal_error (loc, "unbalanced `('")
            }

          | Tok_operator ("$", _) when is_id (peek_token (ctx)) =>
            match (get_token (ctx)) {
              | Tok_identifier (n) =>
                if (ctx.in_pattern)
                  E_spliced_patt (loc, P_variable (location (ctx), n))
                else
                  E_spliced (loc, E_ref (location (ctx), n))
              | _ => Util.ice ()
            }

          | Tok_operator (o, _) =>
            def parse_paren (p : ParenCallback) {
              def problem () {
                Message.error (loc, "unbalanced `" + p.opening_paren + "'");
                fatal_error (ctx, "expecting `" + p.closing_paren + "' here")
              };
              def expr = p.parsing_function (ctx);
              match (get_token (ctx)) {
                | Tok_operator (o, _) =>
                  if (p.closing_paren == o)
                    expr
                  else
                    match (get_token (ctx)) {
                      | Tok_operator (o', _) when p.closing_paren == o + o' => expr
                      | _ => push_back (ctx); problem ()
                    }
                | _ => problem ()
              } 
            };
            
            match (ctx.parens.Get (o)) {
              | Some (p) => parse_paren (p)
              | None =>
                match (get_token (ctx)) {
                  | Tok_operator (o', _) =>
                    match (ctx.parens.Get (o + o')) {
                      | Some (p) => parse_paren (p)
                      | None => push_back (ctx); problem ()
                    }
                  | _ => push_back (ctx); problem ()
                }
            }
            
          | _ => problem ()
        }
    }
  }

  parse_call_parm (ctx : CTX) : Parm {
    def is_ref = flag_keyword (ctx, "ref");
    def maybe_name_expr = parse_expr (ctx);
    match (peek_token (ctx)) {
      | Tok_operator ("=", _) =>
        def name = 
          match (maybe_name_expr) {
            | E_spliced (e) => SS_spliced_expr (e)
            | E_ref (n) => SS_string (n)
            | E_spliced_special
            | E_spliced_patt => SS_spliced_expr (maybe_name_expr)
            | _ =>
              fatal_error (ctx, "expected parameter name before '=' in call parm")
          };
        shift (ctx);
        Parm (is_ref, parse_expr (ctx), name)
      | _ =>
        Parm (is_ref, maybe_name_expr, SS_string (""))
    }
  }
    
  parse_prim_expr (ctx : CTX) : Expr {
    def loop (expr : Expr) {
      match (get_token (ctx)) {
        | Tok_operator ("[", _) =>
          def exprs = operator_separated_list (ctx, ",", parse_expr);
          expect_operator (ctx, "]");
          loop (E_indexer (expr.loc, expr, exprs))
          
        | Tok_operator (".", _) => 
          def id = get_splicable_id (ctx);
          loop (E_member (expr.loc, expr, id))
          
        | Tok_operator ("(", _) =>
          def parms =
            match (peek_token (ctx)) {
              | Tok_operator (")", _) => shift (ctx); []
              | _ => 
                def parms = operator_separated_list (ctx, ",", parse_call_parm);
                expect_operator (ctx, ")");
                parms
            };
          loop (E_call (expr.loc, expr, parms))

        | _ => push_back (ctx); expr
      }
    };

    loop (parse_closed_prim_expr (ctx))
  }

  parse_unary_expr (ctx : CTX) : Expr {
    match (peek_token (ctx)) {
      | Tok_operator ("(", _)
      | Tok_operator ("$", _) => parse_prim_expr (ctx)

      | Tok_operator (".", _) =>
        shift (ctx);
        match (get_token (ctx)) {
          | Tok_operator (".", _) => 
            def loc = location (ctx);
            E_expr_list (loc, parse_expr (ctx))
          | _ => fatal_error (ctx, "expecting second dot (in unary expression context)")
        }

      | Tok_operator (o, pri) =>
        def loc = location (ctx);
        def unary () {
          when (pri == 0) {
            fatal_error (ctx, "operator `" + o + "' cannot be used in unary context")
          };
          shift (ctx);
          E_call (loc, E_ref (loc, o), [Parm (parse_unary_expr (ctx))])
        };
        
        if (ctx.parens.Contains (o))
          parse_prim_expr (ctx)
        else {
          shift (ctx);
          def tok = peek_token (ctx);
          push_back (ctx);
          match (tok) {
            | Tok_operator (o', _) =>
              if (ctx.parens.Contains (o + o'))
                parse_prim_expr (ctx)
              else unary ()
            | _ => unary ()
          }
        }
      | _ => parse_prim_expr (ctx)
    }
  }

  parse_pattern (ctx : CTX) : Pattern {
    def loop () {
      def loc = location_here (ctx);
      def pat = parse_closed_pattern (ctx);
      match (peek_token (ctx)) {
        | Tok_operator ("::", _) => 
          shift (ctx); 
          P_cons (loc, SS_string ("Cons"), P_tuple (loc, [pat; loop ()]))
        | _ => pat
      }
    };

    loop ()
  }

  parse_pattern_after_id (ctx : CTX, id : Splicable_string) : Pattern {
    def id = 
      match (peek_token (ctx)) {
        | Tok_operator (".", _) =>
          shift (ctx);
          def qid = get_qid (ctx);
          match (id) {
            | SS_string (n) => 
              SS_string (n + "." + qid)
            | _ =>
              fatal_error (ctx, "mixing spliced names with regular ids isn't allowed")
          }
        | _ => id;
      };
    def loc = location (ctx);
    match (peek_token (ctx)) {
      | Tok_operator ("{", _)
      | Tok_operator ("(", _) => 
        P_cons (loc, id, tuple_or_record (ctx)) 
      | Tok_keyword ("_") => 
        shift (ctx);
        P_cons (loc, id, P_underscore (loc))
      | _ =>
        match (id) {
          | SS_string => P_cons (loc, id, P_underscore (loc))
          | SS_spliced_expr (E_spliced_special (ty, expr)) =>
            match (ty) {
              | "var" | "int" | "string" | "bool" | "float" 
              | "char" =>
                P_spliced_special (loc, ty, expr)
              | _ =>
                fatal_error (ctx, "wrong splicing type after ':'")
            }
          | SS_spliced_expr (expr) =>
            P_spliced (loc, expr)
        }
    }
  }

  (** this function expects first '{' to be already shifted, starting
      its scanning routine from inside of record;
      but it shifts the ending '}'
   *)
  parse_record (ctx : CTX) : Pattern {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator ("}", _) => List.rev (acc)
        | Tok_identifier (n) =>
          expect_operator (ctx, "=");
          def pat = parse_pattern (ctx);
          def res = (n, pat);
          match (get_token (ctx)) {
            | Tok_operator (";", _) => ()
            | Tok_operator ("}", _) => push_back (ctx)
            | _ => fatal_error (ctx, "found junk after pattern in record")
          };
          loop (res :: acc)
        | _ => fatal_error (ctx, "expecting named pattern")
      }
    };
    def loc = location (ctx);
    match (peek_token (ctx)) {
      | Tok_operator (".", _) =>
        shift (ctx);
        match (get_token (ctx)) {
          | Tok_operator (".", _) => 
            def res = P_record ([("", P_patt_list (loc, parse_pattern (ctx)))]);
            expect_operator (ctx, "}");
            res
          | _ => fatal_error (ctx, "expecting second dot in pattern context")              
        }
      | _ =>
        P_record (loc, loop ([]))
    }
  }

  tuple_or_record (ctx : CTX) : Pattern {
    match (get_token (ctx)) {
      | Tok_operator ("(", _) =>
        def pats = operator_separated_list (ctx, ",", parse_pattern);
        expect_operator (ctx, ")");
        P_tuple (location_here (ctx), pats)
      | Tok_operator ("{", _) => parse_record (ctx)
      | _ => fatal_error (ctx, "expecting tuple or record pattern")
    }
  }
    
  parse_closed_pattern (ctx : CTX) : Pattern {
    def loc = location_here (ctx);
  
    match (parse_literal (ctx)) {
      | Some (l) => P_literal (loc, l)
      | None =>
        match (get_token (ctx)) {
          | Tok_operator ("-", _) =>
            match (parse_literal (ctx)) {
              | Some (L_int (v)) => P_literal (loc, L_int (-v))
              | _ => 
                fatal_error (ctx, "expecting integer literal")
            }
            
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            push_back (ctx);
            def id = get_splicable_id (ctx);
            parse_pattern_after_id (ctx, id)
            
          | Tok_operator ("{", _) =>
            parse_record (ctx)

          | Tok_operator (".", _) =>
            match (get_token (ctx)) {
              | Tok_operator (".", _) => P_patt_list (loc, parse_pattern (ctx))
              | _ => fatal_error (ctx, "expecting second dot in pattern context")
            }
            
          | Tok_operator ("(", _) =>
            def pat = parse_pattern (ctx);
            match (get_token (ctx)) {
              | Tok_operator (",", _) =>
                def pats = pat :: operator_separated_list (ctx, ",", parse_pattern);
                expect_operator (ctx, ")");
                P_tuple (loc, pats)
              | Tok_operator (")", _) =>
                match (peek_token (ctx)) {
                  | Tok_keyword ("as") =>
                    shift (ctx);
                    def id = get_splicable_id (ctx);
                    P_as (loc, pat, id)
                    
                  | _ =>
                    P_tuple (loc, [pat])
                }
              | _ =>
                fatal_error (ctx, "expecting `,' or ')' in tuple pattern")
            }

          | Tok_keyword ("_") =>
            P_underscore (loc)

          | Tok_operator ("[", _) =>
            def loop () {
              match (get_token (ctx)) {
                | Tok_operator (";", _) =>
                  match (peek_token (ctx)) {
                    | Tok_operator ("]", _) => 
                      P_cons (SS_string ("Nil"), P_underscore ())
                    | _ => 
                      def p = parse_pattern (ctx);
                      P_cons (p.loc, SS_string ("Cons"), P_tuple (p.loc, [p; loop ()]))
                  }
                | Tok_operator ("]", _) =>
                  P_cons (SS_string ("Nil"), P_underscore ())
                | _ => fatal_error (ctx, "expecting pattern in list")
              }
            };

            match (peek_token (ctx)) {
              | Tok_operator ("]", _) => shift (ctx); 
                P_cons (SS_string ("Nil"), P_underscore ())
              | _ =>
                def p = parse_pattern (ctx);
                P_cons (p.loc, SS_string ("Cons"), P_tuple (p.loc, [p; loop ()]))
            }
            
          | Tok_operator ("<[", _) =>
            def back = ctx.in_pattern;
            ctx.in_pattern <- true;
            def expr = parse_quotation (ctx);
            expect_operator (ctx, "]>");
            ctx.in_pattern <- back;
            match (expr) {
              | E_quoted (el) => P_quoted (loc, el)
              | _ => Util.ice ("parse_quoted returned sth strange")
            }
            
          | _ => fatal_error (ctx, "expecting pattern")
        }
    }
  }

  parse_case_guard (ctx : CTX) : Pattern * option (Expr) {
    def pat = parse_pattern (ctx);
    if (flag_keyword (ctx, "when"))
      (pat, Some (parse_expr (ctx)))
    else (pat, None ());
  }

  parse_match_case (ctx : CTX) : Match_case {
    def loop2 (acc) {
      def res = parse_case_guard (ctx);
      match (get_token (ctx)) {
        | Tok_operator ("=>", _) => List.rev (res :: acc)
        | Tok_operator ("|", _) => loop2 (res :: acc)
        | _ => fatal_error (ctx, "found junk after pattern")
      }
    };
    
    // eat pattern part and '=>'
    def pats = 
      match (peek_token (ctx)) {
        | Tok_operator ("|", _) => 
          shift (ctx);
          match (peek_token (ctx)) {
            | Tok_operator (".", _) =>
              shift (ctx);
              expect_operator (ctx, ".");
              def loc = location_here (ctx);
              def pat = parse_pattern (ctx);
              expect_operator (ctx, "=>");
              [(P_patt_list (loc, pat), None ())]
            | _ => loop2 ([])
          }
        | _ => loop2 ([])
      };

    def loc' = location_here (ctx);
    def expr =
      match (parse_expr_sequence (ctx)) {
        | [x] => x
        | l => E_sequence (loc', l)
      };

    Match_case (pats, expr)
  }

  parse_semiclosed_expr (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    def tok = get_token (ctx);
    //Message.debug ("pse " + token_name (tok));
    match (tok) {
      | Tok_keyword (k) when ctx.keywords.Contains (k) =>
        def k = Option.unsome (ctx.keywords.Get (k));
        k.parsing_function (ctx)
        
      | Tok_keyword ("match") =>
        expect_operator (ctx, "(");
        def expr = parse_expr (ctx);
        expect_operator (ctx, ")");
        match (get_token (ctx)) {
          | Tok_operator ("{", _) =>
            match (peek_token (ctx)) {
              | Tok_operator (".", _) =>
                shift (ctx);
                match (get_token (ctx)) {
                  | Tok_operator (".", _) => 
                    def res = 
                      E_match (loc, expr, 
                               [Match_case ([], E_expr_list (loc, parse_expr (ctx)))]);
                    expect_operator (ctx, "}");
                    res
                  | _ => fatal_error (ctx, "expecting second dot in match context")
                }
              | _ =>
                push_back (ctx);
                def cases = collect_braced_list (ctx, parse_match_case);
                E_match (loc, expr, cases)
            }
          | _ =>
            fatal_error (ctx, "expecting '{' after 'match (e)'")
        }
      | Tok_keyword ("raise") =>
        E_raise (loc, parse_expr (ctx))

      | Tok_keyword ("try") =>
        def body = parse_expr (ctx);
        match (get_token (ctx)) {
          | Tok_keyword ("with") =>
            def parse_with (_) {
              match (peek_token (ctx)) {
                | Tok_operator ("|", _) => shift (ctx)
                | _ => ()
              };
              def id = get_splicable_id (ctx);
              expect_operator (ctx, ":");
              def t = parse_type (ctx);
              expect_operator (ctx, "=>");
              match (parse_expr_sequence (ctx)) {
                | [x] => (id, t, x)
                | l => (id, t, E_sequence (loc, l))
              }
            };

            def mktry (body, h) {
              def (id, t, handler) = h;
              E_try_with (loc, body, id, t, handler)
            };
            
            List.fold_left (mktry, body, collect_braced_list (ctx, parse_with))
            
          | Tok_keyword ("finally") =>
            def handler = parse_expr (ctx);
            E_try_finally (loc, body, handler)

          | _ => fatal_error (ctx, "expecting `with' or `finally'")
        }

      | Tok_keyword ("mkarray") =>
        match (get_token (ctx)) {
          | Tok_operator ("[", _) =>
            def exprs = parse_maybe_null_expr_sequence (ctx);
            expect_operator (ctx, "]");
            E_mkarray (loc, exprs)

          | _ => fatal_error (ctx, "expected [ ... ] after `mkarray'")
        }

      | Tok_keyword ("fun") 
      | Tok_tyvar (_) =>
        push_back (ctx);
        def h = parse_fun_header (ctx, allow_ctor = false,
                                       allow_inference = true, 
                                       is_lambda = true, knownname = None ());
        def expr = parse_block (ctx, h.parms);
        E_lambda (loc, Function_decl (h, expr))

      | Tok_keyword ("mutable") =>
        def id = get_splicable_id (ctx);
        expect_operator (ctx, "<-");
        E_let (loc, true, id, parse_expr (ctx))

      | Tok_keyword ("def") =>
        def parse_val (id) {
          expect_operator (ctx, "=");
          E_let (loc, false, id, parse_expr (ctx))
        };
        def parse_pat (idopt) {
          def pat =
            match (idopt) {
              | None => parse_pattern (ctx)
              | Some (id) =>
                parse_pattern_after_id (ctx, id);
            };
          expect_operator (ctx, "=");
          def expr = parse_expr (ctx);
          E_letpat (loc, pat, expr)
        };
        def parse_funs (acc, idopt) {
          def h = parse_fun_header (ctx, allow_ctor = false, 
                                    allow_inference = true, 
                                    is_lambda = false, knownname = idopt);
          def fd = Function_decl (h, parse_block (ctx, h.parms));
          match (peek_token (ctx)) {
            | Tok_keyword ("and") =>
              shift (ctx);
              parse_funs (fd :: acc, None ())
            | _ => E_letfun (loc, List.rev (fd :: acc))
          }
        };
        
        match (peek_token (ctx)) {
          | Tok_tyvar => parse_funs ([], None ())

          | Tok_keyword ("_")
          | Tok_operator ("$", _) 
          | Tok_identifier =>
            def id = get_splicable_id (ctx);
            match (peek_token (ctx)) {
              | Tok_operator ("(", _) => 
                parse_funs ([], Some (id))
                
              | Tok_operator ("=", _) =>
                parse_val (id)
              
              | _ => parse_pat (Some (id))
            }

          | Tok_operator (".", _) =>
            shift (ctx);
            expect_operator (ctx, ".");
            E_letfun (loc, [Function_decl (Fun_header (), 
                                           E_expr_list (parse_expr (ctx)))])

          | _ => parse_pat (None ())
        }
      
      | _ => push_back (ctx); parse_unary_expr (ctx)
    }
  }

  parse_expr (ctx : CTX) : Expr {
    def is_paren (s) {
      ctx.parens.Contains (s) || ctx.closing_parens.Contains (s)
    };

    def make_bin (loc, op, e1, e2) {
      match (op) {
        | "<-" =>
          E_assign (loc, e1, e2)
        | "::" =>
          E_call (loc, E_ref (loc, "Cons"), [Parm (e1); Parm (e2)])
        | _ =>
          E_call (loc, E_ref (loc, op), [Parm (e1); Parm (e2)])
      }
    };
    
    def parse_pri (pri) : Expr {
      //Message.debug ("pp " + string_of_int (pri));
      def loop_left (expr) {
        def loc = location_here (ctx);
        match (get_token (ctx)) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            def expr' = parse_pri (pri - 1);
            loop_left (make_bin (loc, s, expr, expr'))
          | _ => 
            //Message.debug ("miss " + string_of_int (pri) + " " + token_name (tok));
            push_back (ctx); 
            expr
        }
      };

      def loop_right () {
        def loc = location_here (ctx);
        def expr = parse_pri (pri - 1);
        match (get_token (ctx)) {
          | Tok_operator (s, p) when p == pri && !is_paren (s) =>
            make_bin (loc, s, expr, loop_right ())
          | _ => push_back (ctx); expr
        }
      };
     
      match (pri) {
        | 0 => parse_semiclosed_expr (ctx)
        | 1 | 8 => loop_right ()
        | _ => loop_left (parse_pri (pri - 1))
      }
    };

    parse_pri (9)
  }

  parse_expr_sequence (ctx : CTX) : list (Expr) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (";", _) =>
          match (peek_token (ctx)) {
            | Tok_operator ("}", _) 
            | Tok_operator ("|", _) 
            | Tok_operator ("]", _) 
              => List.rev (acc)
            | _ => loop (parse_expr (ctx) :: acc)
          }
        | Tok_operator ("}", _) 
        | Tok_operator ("|", _) 
        | Tok_operator ("]", _) 
          => push_back (ctx); List.rev (acc)
        | _ => fatal_error (ctx, "expecting expression in sequence")
      }
    };

    loop ([parse_expr (ctx)])
  }

  parse_maybe_null_expr_sequence (ctx : CTX) : list (Expr) {
    match (peek_token (ctx)) {
      | Tok_operator ("}", _) 
      | Tok_operator ("]", _) => []
      | _ => parse_expr_sequence (ctx)
    }
  }

  parse_block (ctx : CTX, parms : list (Fun_parm)) : Expr {
    def parms_to_tupl (prs : list (Fun_parm), acc) {
      match (prs) {
        | [] => E_tuple (List.rev (acc))
        | {name = SS_string (x)} :: xs => parms_to_tupl (xs, E_ref (x) :: acc)
        | _ => fatal_error (ctx, "illegal spliced parameter?")
      }
    };

    expect_operator (ctx, "{");
    def loc = location (ctx);
    match (peek_token (ctx)) {
      | Tok_operator ("}", _) => shift (ctx); E_sequence (location (ctx), [])
      | Tok_operator ("|", _) =>
        push_back (ctx);
        def cases = collect_braced_list (ctx, parse_match_case);
        match (parms) {
          | [{name = SS_string (x)}] => E_match (loc, E_ref (x), cases)
          | _::_::_ => E_match (loc, parms_to_tupl (parms, []), cases)
          | [] =>             
            fatal_error (ctx, "functions with direct matching must have parameters")
          | _ => fatal_error (ctx, "illegal spliced parameter?")
        }
      | _ => 
        def loc = location (ctx);
        def r = E_sequence (loc, parse_expr_sequence (ctx));
        expect_operator (ctx, "}");
        r
    }
  }
  
  parse_type (ctx : CTX) : Type {
    def prim_type () {
      def get_args () {
        match (get_token (ctx)) {
          | Tok_operator ("(", _) =>
            def args = operator_separated_list (ctx, ",", parse_type);
            expect_operator (ctx, ")");
            args
          | _ =>
            push_back (ctx);
            []
        }
      };
      match (get_token (ctx)) {
        | Tok_identifier
        | Tok_operator ("$", _) =>
          push_back (ctx);
          def id = get_splicable_id (ctx);
          def id = 
            match (peek_token (ctx)) {
              | Tok_operator (".", _) =>
                shift (ctx);
                def qid = get_qid (ctx);
                match (id) {
                  | SS_string (n) => 
                    SS_string (n + "." + qid)
                  | _ =>
                    fatal_error (ctx, "mixing spliced names with regular ids isn't allowed")
                }
              | _ => id;
            };
          match (peek_token (ctx)) {
            | Tok_operator ("(", _) => 
              T_app (id, get_args ())
            | _ =>
              match (id) {
                | SS_string => T_app (id, [])
                | SS_spliced_expr (E_spliced_special (ty, expr)) =>
                  match (ty) {
                    | "var" =>
                      T_spliced_special (ty, expr)
                    | _ =>
                      fatal_error (ctx, "wrong splicing type after ':'")
                  }
                | SS_spliced_expr (expr) =>
                  T_spliced (expr)
              }
          }

        | Tok_operator (".", _) =>
          match (get_token (ctx)) {
            | Tok_operator (".", _) => T_type_list (prod_type ())
            | _ => fatal_error (ctx, "expecting second dot")
          }
          
        | Tok_keyword ("array") => T_array (prim_type ())
        
        | Tok_keyword ("ref") => T_ref (prim_type ())
        
        | Tok_keyword ("out") => T_out (prim_type ())

        | Tok_keyword ("void") => T_void ()

        | Tok_tyvar (tv) => T_var (tv)

        | Tok_operator ("(", _) =>
          def t = parse_type (ctx);
          expect_operator (ctx, ")");
          t

        | _ =>
          fatal_error (ctx, "expecting type expression")
      }
    }

    and prod_type () {
      def loop (acc) {
        match (get_token (ctx)) {
          | Tok_operator ("*", _) =>
            loop (prim_type () :: acc)
          | _ => 
            push_back (ctx);
            match (acc) {
              | [x] => x
              | acc => T_prod (List.rev (acc))
            }
        }
      };

      loop ([prim_type ()])
    };

    def fun_type () {
      def t = prod_type ();
      match (get_token (ctx)) {
        | Tok_operator ("->", _) =>
          T_fun (t, fun_type ())
        | _ => 
          push_back (ctx);
          t
      }
    };

    fun_type ()
  }

  get_attrs (ctx : CTX) : list (Modifier) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_keyword ("new") => loop (Mod_new () :: acc)
        | Tok_keyword ("public") => loop (Mod_public () :: acc)
        | Tok_keyword ("protected") => loop (Mod_protected () :: acc)
        | Tok_keyword ("internal") => loop (Mod_internal () :: acc)
        | Tok_keyword ("private") => loop (Mod_private () :: acc)
        | Tok_keyword ("abstract") => loop (Mod_abstract () :: acc)
        | Tok_keyword ("sealed") => loop (Mod_sealed () :: acc)
        | Tok_keyword ("override") => loop (Mod_override () :: acc)
        | Tok_keyword ("static") => loop (Mod_static () :: acc)
        | Tok_keyword ("virtual") => loop (Mod_virtual () :: acc)
        | Tok_operator ("[", _) => 
          def exps = operator_separated_list (ctx, ",", parse_expr);
          expect_operator (ctx, "]");
          loop (Mod_attribute (exps) :: acc)          
        | _ =>
          push_back (ctx);
          List.rev (acc)
      }
    };
    loop ([])
  }
  
  'a operator_separated_list (ctx : CTX, op : string, f : CTX -> 'a) : list ('a) {
    def loop (acc) {
      match (get_token (ctx)) {
        | Tok_operator (o, _) when o == op => loop (f (ctx) :: acc)
        | _ => push_back (ctx); List.rev (acc)
      }
    };

    loop ([f (ctx)])
  }

  parse_tyvars (ctx : CTX) : list (string) {
    operator_separated_list (ctx, ",", get_tyvar)
  }

  parse_where_constraints (ctx : CTX, tyvars : list (string)) : Typarms {
    def constraints =
      if (flag_keyword (ctx, "where")) {
        def parse_constraint (_) {
          def tv = get_tyvar (ctx);
          expect_operator (ctx, ":>");
          def t = parse_type (ctx);
          Constraint (tv, t)
        };
        operator_separated_list (ctx, ",", parse_constraint)
      } else [];
    Typarms (tyvars, constraints)
  }

  parse_type_member (ctx : CTX) : Class_member {
    def loc = location_here (ctx);
    def attrs = get_attrs (ctx);

    def parse_extern () {
      match (get_token (ctx)) {
        | Tok_keyword ("extern") =>
          match (get_token (ctx)) {
            | Tok_string_literal (s) => 
              expect_operator (ctx, ";");
              s
            | _ => fatal_error (ctx, "found some junk after extern (expecting string)")
          }
        | _ => fatal_error (ctx, "found some junk after `=' (expecting extern)")
      }
    };

    def parse_fun (h : Fun_header) {
      def hname = Macros.unsstring (h.name);
      def impl =
        match (get_token (ctx)) {
          | Tok_keyword ("implements") when hname != ".ctor" =>
            operator_separated_list (ctx, ",", get_qid)
          | _ => push_back (ctx); []
        };
      def body =
        match (peek_token (ctx)) {
          | Tok_operator ("=", _) =>
            shift (ctx);
            FB_extern (parse_extern ())
          | Tok_operator ("{", _) =>
            FB_parsed_expr (parse_block (ctx, h.parms))
          | Tok_operator (";", _) =>
            shift (ctx);
            FB_abstract ()
          | _ => fatal_error (ctx, "expecting method body")
        };
      
      M_function (header = h, 
                  name = hname, 
                  modifiers = attrs, 
                  loc = loc, 
                  body = body, 
                  kind = if (hname == ".ctor") FK_ctor () else FK_method (impl))
    };
    
    def parse_field (is_ref, name) {
      expect_operator (ctx, ":");
      def t = parse_type (ctx);
      def valkind = 
        match (get_token (ctx)) {
          | Tok_operator (";", _) => Val_normal ()
          | Tok_operator ("=", _) => Val_extern (parse_extern ())
          | _ => fatal_error (ctx, "found some junk after field")
        };
      
      M_field (loc = loc,
               name = name, 
               modifiers = attrs, 
               ty = t, 
               is_ref = is_ref, 
               kind = valkind);
    };

    match (get_token (ctx)) {
      | Tok_tyvar =>
        push_back (ctx);
        def h = parse_fun_header (ctx, 
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false, knownname = None ());
        parse_fun (h)
        
      | Tok_keyword ("mutable") =>
        match (get_token (ctx)) {
          | Tok_identifier (name) => parse_field (true, name)
          | _ => fatal_error (ctx, "expecting field name")
        }
        
      | Tok_identifier (name) =>
        match (peek_token (ctx)) {
          | Tok_operator ("(", _) => 
            push_back (ctx);
            def h = parse_fun_header (ctx, 
                                      allow_ctor = false, 
                                      allow_inference = false,
                                      is_lambda = false, knownname = None ());
            parse_fun (h)
          | _ => parse_field (false, name)
        }
        
      | Tok_keyword ("this") =>
        push_back (ctx);
        def h = parse_fun_header (ctx, 
                                  allow_ctor = true, 
                                  allow_inference = false,
                                  is_lambda = false, knownname = None ());
        parse_fun (h)

      | _ =>
        push_back (ctx);
        def td = parse_type_decl (ctx);
        td.modifiers <- List.append (td.modifiers, attrs);
        M_type (loc = loc, 
                name = td.name, 
                modifiers = td.modifiers, 
                td = td)
    }
  }
  
  parse_type_decl (ctx : CTX) : Type_decl {
    def parse_header () {
      match (get_token (ctx)) {
        | Tok_identifier (name) =>
          def typarms =
            match (get_token (ctx)) {
              | Tok_operator ("(", _) =>
                def tyvars = parse_tyvars (ctx);
                expect_operator (ctx, ")");
                parse_where_constraints (ctx, tyvars);
              | _ => 
                push_back (ctx); 
                Typarms ([], [])
            };
            
          def t_extends =
            match (get_token (ctx)) {
              | Tok_keyword ("extends") =>
                Some (parse_type (ctx))
              | _ => 
                push_back (ctx); 
                None ()
            };
            
          def t_implements =
            match (get_token (ctx)) {
              | Tok_keyword ("implements") =>
                operator_separated_list (ctx, ",", parse_type)
              | _ => 
                push_back (ctx); 
                []
            };
          
          (name, typarms, t_extends, t_implements)
          
        | _ => fatal_error (ctx, "expecting type name")
      }
    };
    
    def parse_variant_member (ctx) {
      def tok = get_token (ctx);
      locate (ctx, fun () {
        match (tok) {
          | Tok_operator ("|", _) =>
            def id = get_id (ctx);
            def members =
              match (peek_token (ctx)) {
                | Tok_operator ("{", _) =>
                  def parse_field (ctx) {
                    ignore (peek_token (ctx));
                    locate (ctx, fun () {
                      def attrs = get_attrs (ctx);
                      def is_ref = flag_keyword (ctx, "mutable");
                      def id = get_id (ctx);
                      expect_operator (ctx, ":");
                      def ty = parse_type (ctx);
                      expect_operator (ctx, ";");
                      M_field (name = id,
                               modifiers = attrs,
                               ty = ty, 
                               is_ref = is_ref, 
                               kind = Val_normal ())
                    })
                  };
                  collect_braced_list (ctx, parse_field)
                | _ => []
              };
            TD_variant_option (name = id, 
                               modifiers = [], 
                               t_extends = None (),
                               t_implements = [],
                               typarms = Typarms ([], []),
                               decls = members)
          | _ => fatal_error (ctx, "expecting variant option")
        }
      })
    };
    
    def parse_iface_member (ctx) {
      ignore (peek_token (ctx));
      locate (ctx, fun () {
        def is_new = flag_keyword (ctx, "new");
        def h = parse_fun_header (ctx, allow_ctor = false, allow_inference = false,
                                  is_lambda = false, knownname = None ());
        expect_operator (ctx, ";");
        M_function (name = Macros.unsstring (h.name), 
                    modifiers = Mod_public () :: if (is_new) [Mod_new ()] else [],
                    header = h, 
                    kind = FK_iface_method (is_new), 
                    body = FB_abstract ())
      })
    };
    
    def parse_members () {
      collect_braced_list (ctx, parse_type_member)
    };
    
    def attrs = get_attrs (ctx);
    def tok = get_token (ctx);
    locate (ctx, fun () {
      match (tok) {
        | Tok_keyword ("type")
        | Tok_keyword ("class")
        | Tok_keyword ("struct")
        | Tok_keyword ("module")
        | Tok_keyword ("interface")
        | Tok_keyword ("variant") =>
          def (name, typarms, t_extends, t_implements) = parse_header ();
          def (attrs, td) =
            match (tok) {
              | Tok_keyword ("class") =>
                (attrs, TD_class (parse_members ()))
              | Tok_keyword ("struct") =>
                (Mod_struct () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("module") =>
                (Mod_module () :: attrs, TD_class (parse_members ()))
              | Tok_keyword ("type") =>
                expect_operator (ctx, "=");
                def t = parse_type (ctx);
                expect_operator (ctx, ";");
                (attrs, TD_alias (t))
                
              | Tok_keyword ("interface") =>
                def decls = collect_braced_list (ctx, parse_iface_member);
                (attrs, TD_interface (decls))
                
              | Tok_keyword ("variant") =>
                expect_operator (ctx, "{");
                def decls = collect_list (ctx, parse_variant_member);
                expect_operator (ctx, "}");
                (attrs, TD_variant (decls))
             
              | _ => Util.ice ()
            };
            
          td.modifiers <- attrs;
          
          td.name <- name;
          td.typarms <- typarms;
          td.t_extends <- t_extends;
          td.t_implements <- t_implements;
          
          td
          
        | Tok_keyword ("macro") => 
          def header = parse_fun_header (ctx, true, false, false, None ());
          def synt = 
            match (peek_token (ctx)) {
              | Tok_keyword ("syntax") =>
                shift (ctx);
                expect_operator (ctx, "(");
                def parse_elems (acc) {
                  match (peek_token (ctx)) {
                    | Tok_operator (")", _) =>
                      shift (ctx);
                      List.rev (acc)
                    | Tok_operator (",", _) =>
                      shift (ctx);
                      parse_elems (parse_closed_prim_expr (ctx) :: acc)
                    | _ =>
                      fatal_error (ctx, "expected comma separated expressions in "
                                   + "syntax description")
                  }
                };
                parse_elems ([parse_closed_prim_expr (ctx)])
              | _ => []
            };
          def expr = parse_block (ctx, []);
          Macros.GenerateMacroClass (ctx, attrs, header, synt, expr)
        
        | _ => fatal_error (ctx, "expecting type declaration")
      }
    })
  }
  
  parse_topdecl (ctx : CTX) : Top_decl {
    def tok = get_token (ctx);
    locate (ctx, fun () {
      match (tok) {
        | Tok_keyword ("open") 
        | Tok_keyword ("using") =>
          def id = get_qid (ctx);
          expect_operator (ctx, ";");
          TD_open (id)
          
        | Tok_keyword ("namespace") =>
          def id = get_qid (ctx);
          match (get_token (ctx)) {
            | Tok_operator ("=", _) =>
              when (id.IndexOf ('.') != -1) {
                Message.error ("namespace alias cannot contain dots")
              };
              def id' = get_qid (ctx);
              expect_operator (ctx, ";");
              TD_namespace_alias (id, id')
              
            | Tok_operator ("{", _) =>
              push_back (ctx);
              def decls = collect_braced_list (ctx, parse_topdecl);
              TD_namespace (id, decls)

            | _ =>
              fatal_error (ctx, "expecting '}' or '='")
          }

        | _ =>
          push_back (ctx);
          TD_type (parse_type_decl (ctx))
      }
    })
  }

  parse_quotation (ctx : CTX) : Expr {
    def tok = get_token (ctx);
    def loc = location (ctx);
    
    E_quoted (loc,
      match (get_token (ctx)) {
        | Tok_operator (":", _) =>
          match (tok) {
            | Tok_keyword ("type") =>
              SyntaxType (parse_type (ctx))
            
            | Tok_identifier ("pattern") =>
              SyntaxPattern (parse_pattern (ctx))

            | Tok_identifier ("parameter") =>
              SyntaxParm (parse_call_parm (ctx))

            | Tok_identifier ("case") =>
              SyntaxCase (parse_match_case (ctx))

            | Tok_identifier ("caseguard") =>
//              SyntaxCaseGuard (parse_case_guard (ctx))
// workaround for compiler bug
              def (a,b) = parse_case_guard (ctx);
              SyntaxCaseGuard (a,b)

            | Tok_identifier ("fundecl") =>
              def h = parse_fun_header (ctx, allow_ctor = false, 
                                        allow_inference = true, 
                                        is_lambda = false, knownname = None ());
              SyntaxFunDecl (Function_decl (h, parse_block (ctx, h.parms)))

            | Tok_identifier ("funparm") =>
              SyntaxFunParm (parse_funparm (ctx, allow_inference = true))

            | _ =>
              fatal_error (ctx, "bad quotation type")
          }
        | _ =>
          push_back (ctx); 
          push_back (ctx);
          SyntaxExpr (parse_expr (ctx))
      }
    )
  }
  
  parse_spliced (ctx : CTX) : Expr {
    def loc = location_here (ctx);
    def expr = if (ctx.in_pattern)
      E_spliced_patt (loc, parse_pattern (ctx))
    else
      E_spliced (loc, parse_expr (ctx));

    match (peek_token (ctx)) {
      | Tok_operator (":", _) =>
        shift(ctx);
        match (get_token (ctx)) {
          | Tok_identifier (ty) =>
            match (ty) {
              | "var" | "int" | "string" | "bool" | "float" | "char" | "typed" 
              | "name" =>
                match (expr) {
                  | E_spliced_patt => E_spliced_special (loc, ty, expr)
                  | E_spliced (e) => E_spliced_special (loc, ty, e)
                  | _ => Util.ice ("not possible")
                }
              | _ =>
                fatal_error (ctx, "wrong splicing type after ':'")
            }
          | _ =>
            fatal_error (ctx, "expecting splicing type (var, int, string...) after ':'")
        }
      | _ =>
        expr
    }
  }

  'a collect_braced_list (ctx : CTX, f : CTX -> 'a) : list ('a) {
    expect_operator (ctx, "{");
    def r = collect_list (ctx, f);
    expect_operator (ctx, "}");
    r
  }
  
  'a collect_list (ctx : CTX, f : CTX -> 'a) : list ('a) {
    def loop (acc) {
      match (peek_token (ctx)) {
        | Tok_operator ("}", _) | Tok_EOF => List.rev (acc)
        | _ =>
          loop (f (ctx) :: acc)
      }
    };
    loop ([])
  }

  public variant GrammarElement {
    | GE_operator { name : string; }
    | GE_keyword { name : string; }
    | GE_expression
    | GE_block
    | GE_expression_list { sep : string; }
    | GE_parm_list { sep : string; }
  }

  parse_wrt_rule (ctx : CTX, rule : list (GrammarElement)) : list (Parm) {
    def loop (acc, lst) {
      match (lst) {
        | GE_operator (n) :: xs =>
          expect_operator (ctx, n);
          loop (acc, xs)

        | GE_keyword (n) :: xs =>
          expect_keyword (ctx, n);
          loop (acc, xs)

        | GE_expression :: xs =>
          def expr = parse_expr (ctx);
          loop (Parm (expr) :: acc, xs)

        | GE_block :: xs =>
          def expr = parse_block (ctx, []);
          loop (Parm (expr) :: acc, xs)

        | GE_expression_list (sep) :: xs =>
          def exprs = operator_separated_list (ctx, sep, parse_expr);
          loop (List.rev_append (List.map (fun (e) { Parm (e) }, exprs), acc), xs)

        | GE_parm_list (sep) :: xs =>
          def exprs = operator_separated_list (ctx, sep, parse_call_parm);
          loop (List.rev_append (exprs, acc), xs)

        | [] => List.rev (acc)
      }
    };

    loop ([], rule)
  }

  public make_parsing_function (macro_name : string, rule : list (GrammarElement), 
                         perm : list (Parm) -> list (Parm)) : CTX -> Expr {
    fun (ctx) {
      def loc = location (ctx);
      def parms = parse_wrt_rule (ctx, rule);
      E_call (loc, E_ref (loc, macro_name), perm (parms))
    }
  }

  init_parens (ctx : CTX) : void {
    def add (o, c, f) {
      ctx.parens.Add (o, ParenCallback (o, c, f));
      ctx.closing_parens.Add (c, 0);
    };
    add ("<[", "]>", parse_quotation);
    add ("$(", ")", parse_spliced);
    
    add ("[", "]", fun (ctx) {
      def loc = location (ctx);
      def make_list (exps : list (Expr)) {
        match (exps) {
          | [] => E_call (loc, E_ref (loc, "Nil"), [])
          | x :: xs => E_call (x.loc, E_ref (x.loc, "Cons"), 
                               [Parm (x); Parm (make_list (xs))])
        }
      };
      make_list (parse_maybe_null_expr_sequence (ctx))
    });
    
    add ("{", "}", fun (ctx) {
      def loc = location (ctx);
      E_sequence (loc, parse_maybe_null_expr_sequence (ctx))
    });
  }

  init_keywords (ctx : CTX) : void {
    def add_macro (name, rule) {
      ctx.keywords.Add (name, KeywordCallback (name, 
        make_parsing_function ("_N_" + name + "macro_call", rule, fun (x) { x})))
    };

    def while_rule = [GE_operator ("("); GE_expression (); GE_operator (")");
                        GE_expression ()];

    add_macro ("while", while_rule);
    add_macro ("when", while_rule);
    add_macro ("unless", while_rule);

    add_macro ("regexp", [GE_operator ("("); GE_expression (); GE_operator (")")]);
    
    add_macro ("using", [GE_operator ("(");
                           GE_parm_list (",");
                         GE_operator (")");
                         GE_expression ()]);

    add_macro ("for", [GE_operator ("(");
                         GE_expression (); GE_operator (";");
                         GE_expression (); GE_operator (";");
                         GE_expression (); GE_operator (")");
                       GE_expression ()]);
                       
    add_macro ("if", [GE_operator ("("); GE_expression (); GE_operator (")");
                         GE_expression (); 
                      GE_keyword ("else");
                         GE_expression ()]);
  }

  public init_context () : CTX
  {
    def ctx = CTX (lexer = null,
                   last_token1 = null, 
                   last_token2 = null, 
                   push_back = 0,
                   in_pattern = false,
                   keywords = Hashtable (),
                   parens = Hashtable (),
                   closing_parens = Hashtable ());
    init_parens (ctx);
    // HACK: if we had syntax extensions in library we wouldn't need this
    unless (Flags.self_boot) init_keywords (ctx);

    ctx
  }

  public parse (ctx : CTX, lexer : Lexer) : list (Top_decl)
  {
    ctx.lexer <- lexer;
    ctx.last_token1 <- null;
    ctx.last_token2 <- null;
    ctx.push_back <- 0;
    ctx.in_pattern <- false;
    def r = collect_list (ctx, parse_topdecl);
    match (peek_token (ctx)) {
      | Tok_EOF => r
      | _ => fatal_error (ctx, "expecting EOF")
    }
  }

} // end module
} // end namespace
