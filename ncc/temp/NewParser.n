/*
 * Copyright (c) 2003-2005 The University of Wroclaw.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *    1. Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *    2. Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in the
 *       documentation and/or other materials provided with the distribution.
 *    3. The name of the University may not be used to endorse or promote
 *       products derived from this software without specific prior
 *       written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY THE UNIVERSITY ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN
 * NO EVENT SHALL THE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
#if NEWPARSER
 
using Nemerle.Compiler;
using Nemerle.Collections;
using Nemerle.Compiler.Parsetree;

namespace Nemerle.Compiler
{
  public enum TokenSeparator {
    | None 
    | Comma
    | Semicolon
/*
    public override ToString () : string {
      match (this) {
        | None => " "
        | Comma => ", "
        | Semicolon => "; "
      }
    }
*/    
  }

  class PreParserException : System.Exception { }

  /** Transforms stream of tokens from given LexerBase to token tree
      with matched brackets.
   */
  public class PreParser
  {
    lexer : LexerBase;
    mutable last_token : Token = null;

    mutable finished : bool = false;
    
    /** Parent stream is the stack of processed token nodes,
        which are already assigned to be in currently build sequence.
        For example:
          a; b; c (); d e _we_are_here_
        'a, b, c()', are alredy known to be in parent sequence,
        while 'd e' are in current temporary sequence, which might
        get added to parent_stream if separator (e.g. ';') occurs
     */
    mutable parent_stream : array [Token] = array (1000);
    mutable parent_pos : int;

    /** Currently builded stream of token nodes is an array of
        loose tokens, which have occured after last separator.
        It will probably form LooseGroup as an element of parent
        sequence or all elements will constitue parent
     */
    mutable current_stream : array [Token] = array (200);
    mutable current_pos : int;

    public this (lex : LexerBase) {
      lexer = lex;
    }

    /** Fetch next token (from one token buffer or lexer if it's empty */
    get_token () : Token {
      if (last_token != null) {
        def result = last_token;
        last_token = null;
        result;
      }
      else
        lexer.GetToken ()
    }

    /** Store token in our mini one token buffer */
    push_back (tok : Token) : void {
      assert (last_token == null);
      last_token = tok;
    }

    static store (tokens : ref array [Token], idx : ref int, tok : Token) : void
    {
      tokens [idx] = tok;
      ++idx;
    }

    /** links Tokens from specified subarray to form a list and return its head */
    static make_list (tokens : array [Token], start : int, end : int) : Token
    {
      for (mutable i = end - 2; i >= start; --i) 
        tokens [i].Next = tokens [i + 1];
      tokens [start]
    }

    
    public static Dump (tok : Token, ident : string) : string {
      def (open, close, sepstr, elements) =
        match (tok) {
          | Token.RoundGroup (separator, elements) =>    // ( ... )
            ("(", ")", separator.ToString (), elements)
          | Token.BracesGroup (elements) =>
            ("{\n" + ident, "}", ";\n" + ident, elements)
          | Token.SquareGroup (elements) =>
            ("[", "]", ", ", elements)
          | Token.QuoteGroup (elements) =>
            ("<[\n", "]>", "; ", elements)
          | Token.LooseGroup (elements)   =>
            ("", "", " ", elements)

          | _ => ("", tok.ToString (false), "", null)
        }
      def builder = System.Text.StringBuilder (open);
      when (elements != null)
        foreach (e : Token in elements) 
          _ = builder.Append (Dump (e, ident + "  ")).Append (sepstr);
      builder.Append (close).ToString ()
    }

    /** Closes both currently created LooseGroup and parent group.
        Returns list of tokens composing parent group */
    finish_parent (parent_begin : int, current_begin : int) : Token {
      finish_current (current_begin);
      def parent_group = 
        if (parent_begin == parent_pos)
          Token.EndOfFile () // case of `(` `)`
        else
          make_list (parent_stream, parent_begin, parent_pos);
      parent_pos = parent_begin;
      parent_group
    }

    /** Closes currently created LooseGroup and adds it at the end of the
        parent group. After that we are ready to make another LooseGroup.

        It is called mainly when separator token occurs.
     */   
    finish_current (current_begin : int) : void {
      unless (current_begin == current_pos) {
        def loose_group = make_list (current_stream, current_begin, current_pos);
        store (ref parent_stream, ref parent_pos, Token.LooseGroup (loose_group));
        current_pos = current_begin;
      }
    }

    /** Handle standard situations when new bracket group is beginning
        or there is erronous situation. Any non bracket token is
        appended to current LooseGroup.

        Throws PreParserException when there is unmatched end bracket.
     */
    handle_default_token (current_begin : int, tok : Token) : void {
      match (tok) {
        | Token.BeginBrace =>
          def brace_group = parse_brace_group (tok.Location, parent_pos, current_pos);
          if (current_begin == current_pos)
            store (ref parent_stream, ref parent_pos, brace_group)
          else {
            store (ref current_stream, ref current_pos, brace_group);
            finish_current (current_begin);
          }

        | Token.BeginRound =>
          def round_group = parse_round_group (tok.Location, parent_pos, current_pos);
          store (ref current_stream, ref current_pos, round_group);

        | Token.BeginSquare =>
          def square_group = parse_square_group (tok.Location, parent_pos, current_pos);
          store (ref current_stream, ref current_pos, square_group);

        | Token.BeginQuote =>
          def quote_group = parse_quote_group (tok.Location, parent_pos, current_pos);
          store (ref current_stream, ref current_pos, quote_group);

        | Token.EndRound | Token.EndSquare | Token.EndQuote | Token.EndBrace =>
          push_back (tok);
          Message.error (tok.Location, "unexpected closing bracket: " + tok.ToString ());
          throw PreParserException ();

        | Token.EndOfFile =>
          Message.error (tok.Location, "unexpected end of file");
          throw PreParserException ();

        | _ => store (ref current_stream, ref current_pos, tok);
      }
    }
    
    parse_brace_group (loc : Location, parent_begin : int, current_begin : int) : Token.BracesGroup
    {
      def loop () {
        def tok = get_token ();
        match (tok) {
          // finish entire brace group
          | Token.EndBrace =>
            def brace_group = finish_parent (parent_begin, current_begin);
            Token.BracesGroup (loc + tok.Location, brace_group);

          // finish current loose group
          | Token.Semicolon => finish_current (current_begin); loop ()

          | Token.EndOfFile when parent_begin == 0 =>
            def brace_group = finish_parent (parent_begin, current_begin);
            finished = true;
            Token.BracesGroup (loc + tok.Location, brace_group);
            
          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () :> Token.BracesGroup }
      catch { _ : PreParserException =>
        def group = finish_parent (parent_begin, current_begin);
        Token.BracesGroup (loc, group) :> Token.BracesGroup;
      }
    }

    parse_round_group (loc : Location, parent_begin : int, current_begin : int) : Token.RoundGroup
    {
      mutable separator = TokenSeparator.None;
      
      def loop () {
        def tok = get_token ();
        match (tok) {
          // finish entire round group
          | Token.EndRound =>
            def round_group = finish_parent (parent_begin, current_begin);
            Token.RoundGroup (loc + tok.Location, separator, round_group);

          // finish current loose group
          | Token.Comma =>
            match (separator) {
              | TokenSeparator.None => separator = TokenSeparator.Comma;
              | TokenSeparator.Comma => finish_current (current_begin);
              | TokenSeparator.Semicolon =>
                Message.error (tok.Location, "inconsistent `,' separator (expected `;')");
                finish_current (current_begin); 
            }
            loop ()

          | Token.Semicolon =>
            match (separator) {
              | TokenSeparator.None => separator = TokenSeparator.Semicolon;
              | TokenSeparator.Semicolon => finish_current (current_begin);
              | TokenSeparator.Comma =>
                Message.error (tok.Location, "inconsistent `;' separator (expected `,')");
                finish_current (current_begin); 
            }
            loop ()

          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () :> Token.RoundGroup }
      catch { _ : PreParserException =>
        def group = finish_parent (parent_begin, current_begin);
        Token.RoundGroup (loc, separator, group) :> Token.RoundGroup;
      }
    }

    parse_square_group (loc : Location, parent_begin : int, current_begin : int) : Token.SquareGroup
    {
      def loop () {
        def tok = get_token ();
        match (tok) {
          // finish entire brace group
          | Token.EndSquare =>
            def group = finish_parent (parent_begin, current_begin);
            Token.SquareGroup (loc + tok.Location, group);

          // finish current loose group
          | Token.Comma => finish_current (current_begin); loop ()

          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () :> Token.SquareGroup }
      catch { _ : PreParserException =>
        def group = finish_parent (parent_begin, current_begin);
        Token.SquareGroup (loc, group) :> Token.SquareGroup;
      }
    }

    parse_quote_group (loc : Location, parent_begin : int, current_begin : int) : Token.QuoteGroup
    {
      def loop () {
        def tok = get_token ();
        match (tok) {
          // finish entire brace group
          | Token.EndQuote =>
            def group = finish_parent (parent_begin, current_begin);
            Token.QuoteGroup (loc + tok.Location, group) :> Token.QuoteGroup;

          // finish current loose group
          | Token.Semicolon => finish_current (current_begin); loop ()

          | _ => handle_default_token (current_begin, tok); loop ()
        }
      }
      try { loop () :> Token.QuoteGroup }
      catch { _ : PreParserException =>
        def group = finish_parent (parent_begin, current_begin);
        Token.QuoteGroup (loc, group) :> Token.QuoteGroup;
      }
    }
    
    public PreParse () : Token {
      def top = parse_brace_group (Location.Default, 0, 0);
      unless (finished) Message.error (lexer.Location, "expected end of file, encountered finishing token");
      top.Child
    }
  }


  public class MainParser
  {
    mutable env : GlobalEnv;
    mutable stream : Token;
    mutable last_tok : Token;

    mutable streams_stack : array [Token] = array (200);
    mutable stack_pos : int = 0;

    public this (env : GlobalEnv) {
      this.env = env;
    }
    
    public Parse (_toptokens : list [Token]) : void
    {
      MacroRegistry.RemoveSyntaxExtensions ();
    }

    public ParseExpr (expr : string) : PExpr
    {
      def lexer = LexerString (expr, Location_stack.top ());
      MacroRegistry.RemoveSyntaxExtensions ();
      def preparser = PreParser (lexer);
      def _tokens = preparser.PreParse ();
      null
    }

    push_stream (newstream : Token) : void {
      streams_stack [stack_pos] = stream;
      ++stack_pos;
      stream = newstream;
    }

    pop_stream () : void {
      --stack_pos;
      stream = streams_stack [stack_pos];
    }
    
    Error (tok : Token, msg : string) : void {
      Message.error (tok.Location, "parse error near " + tok.ToString (true) + ": " + msg)
    }

    get_token () : Token {
      if (stream != null) {
        last_tok = stream;
        stream = stream.Next;
        last_tok
      }
      else {
        Error (last_tok, "unexpected end of token sequence");
        Token.EndOfFile (last_tok.Location)
      }
    } 

    peek_token () : Token {
      if (stream != null) stream
      else Token.EndOfFile (last_tok.Location)
    }

    peek_second_token () : Token {
      if (stream != null)
        if (stream.Next != null) stream.Next
        else Token.EndOfFile (stream.Location)
      else Token.EndOfFile (last_tok.Location)
    }

    
    shift () : void {
      if (stream != null) {
        last_tok = stream;
        stream = stream.Next;
      }
      else Error (last_tok, "unexpected end of token sequence");
    }
    
    get_splicable_id () : Splicable {
      def tok = get_token ();
      def loc = tok.Location;
      match (tok) {
        | Token.Identifier (n) => Splicable.Name (loc, Name ([n]))
          
        | Token.Operator ("$", _) =>
          def second = get_token ();
          match (second) {
            | Token.Identifier (id)  =>
              Splicable.Expression (loc + second.Location,
                                    PExpr.Ref (second.Location, Name ([id])))

            | Token.RoundGroup (_, expr) =>
              def loc = loc + second.Location;
              def expr = parse_expr (expr);
              match (expr) {
                | PExpr.TypeEnforcement =>
                  Splicable.Expression (loc, PExpr.Spliced (second.Location, expr))

                | x => Splicable.Expression (loc, x); 
              }

            | Token.Keyword ("_") =>
              Splicable.Expression (loc + second.Location, PExpr.Wildcard (second.Location))

            | _ =>
              Error (second, "expecting expression after `$' operator");
              Splicable.Name (Name (["error"]))
          }
              
        | Token.Keyword ("_") =>
          Splicable.Name (loc, Name ([Util.tmpname ("u")]))
          
        | _ =>
          Error (tok, "expecting identifier");
          Splicable.Name (Name (["error"]))
      }
    }
    
    GetQid () : list [string]
    {
      match (get_token ()) {
        | Token.Identifier (x) =>
          match (peek_token ()) {
            | Token.Operator (".", _) =>
              shift ();
              x :: GetQid ()

            | _ => [x]
          }

        | t => Error (t, "expected qualified identifier"); []
      }
    }

    expect_empty (msg : string) : void {
      expect_empty (stream, msg);
    }

    expect_empty (tok : Token, msg : string) : void {
      when (tok != null)
        Error (tok, "unexpected tokens after " + msg)
    }

    expect_operator (op : string) : void {
      match (get_token ()) {
        | Token.Operator (o, _) when o == op => ()
        | x => Error (x, $"expecting operator `$(op)'")
      }
    }
    

    TokenMap ['a] (tokens : Token, f : Token -> 'a) : list ['a] {
      mutable result = [];
      foreach (tok : Token in tokens) 
        result = f (tok) :: result;
      List.Rev (result);
    }
    
    /** This function parses top level group updating global environment
        when entering into new namespace, using directive, class, etc.
     */
    ParseTopLevel (tok : Token) : void
    {
      | Token.LooseGroup (tokens) =>
        push_stream (tokens);
        match (get_token ()) {
          | Token.Keyword ("namespace") =>
            // get name of namespace
            def name = GetQid ();

            // body of namespace must be { ... } 
            match (get_token ()) {
              | Token.BracesGroup (children) =>
                def begin_env = env;
                // update current environment
                env = env.EnterIntoNamespace (name);
                // parse elements of namespace with new environment enabled
                foreach (child : Token in children)
                  ParseTopLevel (child);

                // bring env from outside of namespace
                env = begin_env;

              | x => Error (x, "expected `{ }' as body of namespace")
            }

          | Token.Keyword ("using") =>
            def name = GetQid ();

            match (peek_token ()) {
              // using ID = Q.ID; 
              | Token.Operator ("=", _) =>
                def fullname = GetQid ();
                match (name) {
                  | [name] => env = env.AddNamespaceAlias (name, fullname, tok.Location);
                  | _ => Error (tok, "using alias must be simple name without dots")
                }
                
              // using Q.ID;
              | Token.EndOfFile => env = env.AddOpenNamespace (name, tok.Location);
              | _ => expect_empty ("using specification")
            }

          // assembly attribute
          | Token.SquareGroup (Token.LooseGroup (Token.Identifier ("assembly"))) as square =>
            mutable assembly_custom = [square];
            def customs = take_attributes_out (ref assembly_custom, System.AttributeTargets.Assembly, true);      

            foreach (cust in customs)
              AttributeCompiler.AddAssemblyAttribute (env, cust);

          | _ =>
            def _tydecl = ParseType (tokens);
            ()
//            handle_type (None (), None (), env, d);            
        }
        def continuation = stream;
        pop_stream ();
        
        // executed only in case of [assembly: .. ] [ .. ]
        when (continuation != null) ParseTopLevel (Token.LooseGroup (continuation.Location, continuation))        

      | Token.EndOfFile => ()
      | _ => Util.ice ("wrong token group at toplevel")
    }

    /** Parses toplevel type (like class, interface, etc.).
        Expects [toks] to be first token in type declaration.
     */
    ParseType (toks : Token) : TopDeclaration
    {
      push_stream (toks);
      mutable customs_token = get_customs ();
      def customs = take_attributes_out (ref customs_token, System.AttributeTargets.Class, true);      
      def mods = Modifiers (get_modifiers (), customs);

      def tok = get_token ();
      def res =
        match (tok) {
          | Token.Keyword (key) =>
            match (key) {
              | "type" | "class" | "struct" | "module" | "interface" | "enum"
              | "variant" =>
                /// first get name of this declartion
                def name = get_splicable_id ();
                // now generic type parameters
                def tyvars = parse_tyvars ();                  
                def t_extends =
                  match (peek_token ()) {
                    | Token.Operator (":", _) =>
                      shift ();
                      match (peek_token ()) {
                        | Token.Operator (".", _) =>
                          shift ();
                          expect_operator (".");
                          match (get_splicable_id ()) {
                            | Splicable.Expression (e) =>
                              [PExpr.Ellipsis (PExpr.Spliced (e))]
                              
                            | x => Message.error (x.Location, "expected spliced expression"); []
                          }

                        | _ =>
                          // parse , separated sequence as one expression
                          match (parse_expr ()) {
                            | PExpr.Call (PExpr.Ref ({ idl = [","] }), parms) => parms
                            | e => [e]
                          }
                      }
                    | _ => []
                  };
                // where constraints for specified generic type parameters
                def typarms = parse_where_constraints (tyvars);

                def members =
                  if (key == "type") []
                  else
                    match (get_token ()) {
                      | Token.BracesGroup (children) =>
                        TokenMap (children, parse_class_member);
                        
                      | x => Error (x, "expecting type body"); []
                    }

                def td =
                  match (key) {
                    | "class" => TopDeclaration.Class (typarms, t_extends, members)
                    | "struct" =>
                      mods.mods |= NemerleAttributes.Struct;
                      TopDeclaration.Class (typarms, t_extends, members)

                    | "module" =>
                      mods.mods |= NemerleAttributes.Static;
                      TopDeclaration.Class (typarms, t_extends, members)

                    | "type" =>
                      expect_operator ("=");
                      def t = parse_expr ();
                      expect_empty ("type alias declaration");
                      TopDeclaration.Alias (typarms, t)

                    | "interface" => TopDeclaration.Interface (typarms, t_extends, members)
                    | "variant" => TopDeclaration.Variant (typarms, t_extends, members)
                    | "enum" => TopDeclaration.Enum (t_extends, members)

                    | _ => Util.ice ()
                  };
                td.name = name;
                td.loc = tok.Location + name.Location;                
                td

              | "delegate" =>
                def h = parse_fun_header ();
                def td = TopDeclaration.Delegate (h);
                expect_empty ("delegate declaraion");
                td.loc = tok.Location + h.Location;
                td

              | "macro" => 
                def header = parse_fun_header ();
                def synt = 
                  match (peek_token ()) {
                    | Token.Keyword ("syntax") =>
                      shift ();
                      match (get_token ()) {
                        | Token.RoundGroup (TokenSeparator.Comma, syns) =>
                          // FIXME: use parse_expr directly
                          TokenMap (syns, fun (x) { parse_expr (x) });

                        | t => Error (t, "expecting comma sperated list of syntax specifiers in `()'"); []
                      }
                    | _ => []
                  }
                def expr = parse_block ([]);
                def res = TopDeclaration.Macro (header, synt, expr);
                res.loc = tok.Location + header.Location;
                res

              | _ => Error (tok, "expecting type declaration"); TopDeclaration.Delegate (null);
            }
          | x => Error (x, "expecting type declaration"); TopDeclaration.Delegate (null);
        };
      pop_stream ();
        
      res.modifiers = mods;
      res
    }

    get_customs () : list [Token.SquareGroup] {
      def loop (acc) {
        match (peek_token ()) {
          | Token.SquareGroup as gr =>
            shift ();
            loop (gr :: acc)

          | _ => List.Rev (acc)
        }
      }
      loop ([])
    }

    get_modifiers () : NemerleAttributes
    {
      def loop (acc) {
        def tok = peek_token ();
        match (tok) {
          | Token.Keyword (key) =>
            def add_and_loop (attr : NemerleAttributes) {
              shift ();              
              when (attr %&& acc)
                Message.error (tok.Location, "attribute '" + key + "' specified more than once");
              loop (attr %| acc)
            }
            match (key) {
              | "mutable" => add_and_loop (NemerleAttributes.Mutable)
              | "public" => add_and_loop (NemerleAttributes.Public)
              | "private" => add_and_loop (NemerleAttributes.Private)
              | "static" => add_and_loop (NemerleAttributes.Static)
              | "new" => add_and_loop (NemerleAttributes.New)
              | "protected" => add_and_loop (NemerleAttributes.Protected)
              | "internal" => add_and_loop (NemerleAttributes.Internal)
              | "abstract" => add_and_loop (NemerleAttributes.Abstract)
              | "sealed" => add_and_loop (NemerleAttributes.Sealed)
              | "override" => add_and_loop (NemerleAttributes.Override)
              | "virtual" => add_and_loop (NemerleAttributes.Virtual)
              | "volatile" => add_and_loop (NemerleAttributes.Volatile)
              | "partial" => add_and_loop (NemerleAttributes.Partial)
              | _ => acc
            }
          | _ =>
            // perform some sanity checks on the declared attributes
            when (acc %&& NemerleAttributes.Virtual &&
                  acc %&& NemerleAttributes.Override)
              Message.warning ("the `virtual' attribute is redundant, `override' implies `virtual'");
            acc
        }
      }
      loop (NemerleAttributes.None)
    }

    /** Parse expression from current stream of tokens */
    [Nemerle.NotImplemented]
    parse_expr () : PExpr;

    [Nemerle.NotImplemented]
    /** Parse expression beginning in given LooseGroup */
    parse_expr (group_token : Token) : PExpr;

    [Nemerle.NotImplemented]
    parse_tyvars () : list [string * int];

    [Nemerle.NotImplemented]    
    parse_where_constraints (tyvars : list [string * int]) : Typarms;

    [Nemerle.NotImplemented]
    parse_class_member (tok : Token) : ClassMember;

    /** Parse function parameter definition from given LooseGroup */
    parse_parameter (_ : Token) : Fun_parm {
      | Token.LooseGroup (tok) =>
        push_stream (tok);
        mutable customs_token = get_customs ();
        def customs = take_attributes_out (ref customs_token, System.AttributeTargets.Parameter, true);      
        def mods = Modifiers (get_modifiers (), customs);

        match (peek_token ()) {
          | Token.Keyword ("params") =>
            shift ();
            mods.custom_attrs = <[ System.ParamArrayAttribute ]> :: mods.custom_attrs;
          | _ => ()
        };
        def id = get_splicable_id ();
        def t =
          match (peek_token ()) {
            | Token.Operator (":", _) => shift (); parse_expr ()
            | _ => PExpr.Wildcard (id.Location)
          };
        match (peek_token ()) {
          | Token.Operator ("=", _) => 
            shift ();
            def e = parse_expr ();
            mods.custom_attrs = <[ System.ComponentModel.DefaultValueAttribute ($e)
                                ]> :: mods.custom_attrs;
          | _ => ()
        };
        expect_empty ("function parameter");
        pop_stream ();
        Fun_parm (loc = id.loc, name = id, ty = t, modifiers = mods)
      | _ => Util.ice ("non loose group in parameter parsing")
    }

    /**
     *  Parse plain functional header (with optional '[..]' generic parameters
     *                                 and '(..)' fun parameters)
     */
    parse_fun_header () : Fun_header
    {
      mutable is_indexer = false;
      parse_header (false, false, ref is_indexer);
    }

    /** Parse function like header. Allowed declarations are following:
          lambda (beginning with 'fun' keyword),
          constructor (beginning with 'this' keyword),
          function (with '(..)' parameters) with optional generic parameters ('[]' before '()')
          indexer (with '[..]' parameters) with optional generic parameters
        Types of parameters and return values are inferencable.

        [allow_ctor] states that this can be constructor (if name is 'this')
        [is_lambda] requires that this is lambda ('fun' must occur as name)
        [is_indexer] forbids '[]' indexer parms if false, but if true it queries
                     if header is really an indexer header
      */
    parse_header (allow_ctor : bool, is_lambda : bool, is_indexer : ref bool) : Fun_header
    {
      mutable is_ctor = false;
      def tok = peek_token ();
      def name = 
        match (tok) {
          | Token.Keyword ("this") when allow_ctor =>
            shift (); is_ctor = true;
            Splicable.Name (tok.Location, Name ([".ctor"]))
            
          | Token.Keyword ("fun") when is_lambda =>
            shift (); Splicable.Name (tok.Location, Name ([]))
            
          | _ when is_lambda => Util.ice ("expecting `fun'")
          | Token.Identifier  
          | Token.Operator ("$", _) => get_splicable_id ()
          | t => Error (t, "expecting function name"); null
        };

      def parse_parameters (first) {
        | Token.EndOfFile => []
        | Token.LooseGroup (Token.Operator (".", _)) =>
          expect_operator ("..");
          match (get_splicable_id ()) {
            | Splicable.Expression (e) =>
              [Fun_parm (e.loc, Splicable.Name (Name ([])), PExpr.Void (), 
                         Modifiers (NemerleAttributes.None, [PExpr.Spliced (e)]))]
            | Splicable.Name | Splicable.Int =>
              Error (first, "expecting spliced expression"); []
          }
        | _ => TokenMap (first, parse_parameter);
      }
        
      def (tyvars, parms) =
        match ((peek_token (), peek_second_token ())) {
          | (Token.SquareGroup, Token.SquareGroup (parms)) =>
            when (is_indexer == false) Error (parms, "indexer parameter not allowed here");
            def tyvars = parse_tyvars ();
            shift (); // now we are after both bracket groups             
            (tyvars, parse_parameters (parms));
            
          | (Token.SquareGroup, Token.RoundGroup (TokenSeparator.Comma, parms)) =>
            is_indexer = false;
            def tyvars = parse_tyvars ();
            shift (); // now we are after both bracket groups
            (tyvars, parse_parameters (parms));            
            
          | (Token.SquareGroup (parms), _) =>
            when (is_indexer == false) Error (parms, "indexer parameter not allowed here");            
            shift ();
            ([], parse_parameters (parms));                        
            
          | (Token.RoundGroup (TokenSeparator.Comma, parms), _) =>
            is_indexer = false;            
            shift ();
            ([], parse_parameters (parms));

          | (t, _) =>
            is_indexer = false;            
            Error (t, "expecting `[ ]' generic type parameters or `( )' function parameters");
            ([], [])
        }
  
      def ret_type =
        match (peek_token ()) {
          | _ when is_ctor => PExpr.Void (last_tok.Location)
          | Token.Operator (":", _) => shift (); parse_expr ()
          | _ => PExpr.Wildcard (last_tok.Location)
        };

      def typarms = parse_where_constraints (tyvars);

      Fun_header (tok.Location + ret_type.Location,
                  name = name,
                  ret_type = ret_type, 
                  parms = parms, 
                  typarms = typarms)
    }

    [Nemerle.NotImplemented]
    parse_block (parms : list [Fun_parm]) : PExpr;                    
                    
    take_attributes_out (from : ref list [Token.SquareGroup], 
                         what : System.AttributeTargets,
                         comply_on_other : bool) : list [PExpr]
    {
      mutable result = [];      
      from = List.Filter (from, fun (x : Token.SquareGroup) {
        mutable removed = false;
        match (x.Child) {
          | Token.LooseGroup (first) =>
            push_stream (first);
            def target = 
              match (first) {
                | Token.Identifier ("assembly") => System.AttributeTargets.Assembly
                | Token.Identifier ("field") => System.AttributeTargets.Field
                | Token.Keyword ("event") => System.AttributeTargets.Event
                | Token.Identifier ("method") => System.AttributeTargets.Method
                | Token.Keyword ("module") => System.AttributeTargets.Module
                | Token.Identifier ("param") => System.AttributeTargets.Parameter
                | Token.Identifier ("property") => System.AttributeTargets.Property
                | Token.Identifier ("return") => System.AttributeTargets.ReturnValue
                | Token.Keyword ("type") => System.AttributeTargets.Class
                | _ => System.AttributeTargets.All
              }
            when (target != System.AttributeTargets.All) {
              shift (); // ignore target token
              expect_operator (":");
            }
            if (target %&& what || target == System.AttributeTargets.All) {
              removed = true;
              // parse body of first element in this [ , , ]
              result = parse_expr () :: result;
              // parse all remaining in current bracket group [ , , , ]
              match (x.Child.Next) {
                | null => ()
                | rest =>
                  foreach (group : Token in rest)
                    result = parse_expr (group) :: result;
              }
            }
            else  
              when (comply_on_other)
                Error (first, $"unexpected attribute target `$(first)'");
            pop_stream ();
              
          | Token.EndOfFile => Error (x, "empty cutom attribute")
          | _ => Util.ice ("broken brackets in attribute")
        }
        removed;
      });
      List.Rev (result);
    }

  } // end MainParser
} // end namespace

 

#endif NEWPARSER
